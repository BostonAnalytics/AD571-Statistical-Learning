@inproceedings{heatonEmpiricalAnalysisFeature2016,
  title = {An Empirical Analysis of Feature Engineering for Predictive Modeling},
  booktitle = {{{SoutheastCon}} 2016},
  author = {Heaton, Jeff},
  date = {2016-03},
  pages = {1--6},
  publisher = {{IEEE}},
  location = {{Norfolk, VA, USA}},
  doi = {10.1109/SECON.2016.7506650},
  url = {http://ieeexplore.ieee.org/document/7506650/},
  urldate = {2023-09-30},
  abstract = {Machine learning models, such as neural networks, decision trees, random forests and gradient boosting machines accept a feature vector and provide a prediction. These models learn in a supervised fashion where a set of feature vectors with expected output is provided. It is very common practice to engineer new features from the provided feature set. Such engineered features will either augment, or replace portions of the existing feature vector. These engineered features are essentially calculated fields, based on the values of the other features.},
  eventtitle = {{{SoutheastCon}} 2016},
  isbn = {978-1-5090-2246-5},
  langid = {english},
  file = {C:\Users\Nakul\Zotero\storage\FPBSULWI\Heaton - 2016 - An empirical analysis of feature engineering for p.pdf}
}
