[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Statistical Learning Lecture Notes",
    "section": "",
    "text": "library(tidyverse)\nlibrary(kableExtra)\n\ntbl &lt;- tribble(\n  ~\"pos_neg\",  ~\"&lt;8\", ~\"8-10\", ~\"&gt;10\",\n  \"Negative\", 95, 23, 45,\n  \"Positive\", 49, 22, 25,\n  )\n\n\ntbl %&gt;% \n  janitor::adorn_totals(where = c(\"row\", \"col\")) %&gt;%\n  kable(\n    longtable = TRUE,\n    booktabs = TRUE,\n    linesep = \"\",\n    align = c(\"l\", \"c\", \"c\", \"c\", \"c\"),\n    col.names = c(\"\", names(.)[-1]),\n  ) %&gt;%\n  add_header_above(c(\" \" = 1, \"Inoculum volume (mL)\" = 3, \" \" = 1), bold = TRUE) %&gt;%\n  row_spec(0, bold = TRUE) %&gt;%\n  column_spec(1, bold = TRUE) %&gt;%\n  column_spec(2:4, width = \"3em\")\n\n\n\nTable 1: Test\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInoculum volume (mL)\n\n\n\n\n\n&lt;8\n8-10\n&gt;10\nTotal\n\n\n\n\nNegative\n95\n23\n45\n163\n\n\nPositive\n49\n22\n25\n96\n\n\nTotal\n144\n45\n70\n259"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "index.html#example-table",
    "href": "index.html#example-table",
    "title": "Statistical Learning Lecture Notes",
    "section": "",
    "text": "library(tidyverse)\nlibrary(kableExtra)\n\ntbl &lt;- tribble(\n  ~\"pos_neg\",  ~\"&lt;8\", ~\"8-10\", ~\"&gt;10\",\n  \"Negative\", 95, 23, 45,\n  \"Positive\", 49, 22, 25,\n  )\n\n\ntbl %&gt;% \n  janitor::adorn_totals(where = c(\"row\", \"col\")) %&gt;%\n  kable(\n    longtable = TRUE,\n    booktabs = TRUE,\n    linesep = \"\",\n    align = c(\"l\", \"c\", \"c\", \"c\", \"c\"),\n    col.names = c(\"\", names(.)[-1]),\n  ) %&gt;%\n  add_header_above(c(\" \" = 1, \"Inoculum volume (mL)\" = 3, \" \" = 1), bold = TRUE) %&gt;%\n  row_spec(0, bold = TRUE) %&gt;%\n  column_spec(1, bold = TRUE) %&gt;%\n  column_spec(2:4, width = \"3em\")\n\n\n\nTable 1: Test\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInoculum volume (mL)\n\n\n\n\n\n&lt;8\n8-10\n&gt;10\nTotal\n\n\n\n\nNegative\n95\n23\n45\n163\n\n\nPositive\n49\n22\n25\n96\n\n\nTotal\n144\n45\n70\n259"
  },
  {
    "objectID": "M1/M1LN1.html",
    "href": "M1/M1LN1.html",
    "title": "Data Partitioning and Feature Engineering",
    "section": "",
    "text": "The dplyr package is used for data manipulation and the ggplot2 package is used for data visualization. These are frequently used packages in machine learning and have a rich code library available on their website.\n\n# Helper packages\nlibrary(dplyr)     # for data manipulation\nlibrary(ggplot2)   # for awesome graphics\nlibrary(gt)\n\n\n\n\nlibrary(rsample)  # for resampling procedures\nlibrary(caret)    # for resampling and model training\nlibrary(h2o)      # for resampling and model training\n\n\n\nH2O is a fully open-source, distributed in-memory machine-learning platform with linear scalability. H2O supports the most widely used statistical & machine learning algorithms including gradient-boosted machines, generalized linear models, deep learning and more. H2O also has an industry-leading AutoML functionality that automatically runs through all the algorithms and their hyperparameters to produce a leaderboard of the best models. The H2O platform is used by over 18,000 organizations globally and is extremely popular in both the R & Python communities.\n\n# h20 set up\n\nh2o.no_progress() # turn off h20\nh2o.init()        # launch h20\n\n\nH2O is not running yet, starting it now...\n\nNote:  In case of errors look at the following log files:\n    C:\\Users\\NAKULP~1\\AppData\\Local\\Temp\\Rtmp2FlOF9\\file2bb44aab6d58/h2o_nakulpadalkar_started_from_r.out\n    C:\\Users\\NAKULP~1\\AppData\\Local\\Temp\\Rtmp2FlOF9\\file2bb41a5810f0/h2o_nakulpadalkar_started_from_r.err\n\n\nStarting H2O JVM and connecting:  Connection successful!\n\nR is connected to the H2O cluster: \n    H2O cluster uptime:         3 seconds 72 milliseconds \n    H2O cluster timezone:       America/New_York \n    H2O data parsing timezone:  UTC \n    H2O cluster version:        3.44.0.3 \n    H2O cluster version age:    1 year, 10 months and 22 days \n    H2O cluster name:           H2O_started_from_R_nakulpadalkar_xwc036 \n    H2O cluster total nodes:    1 \n    H2O cluster total memory:   15.98 GB \n    H2O cluster total cores:    24 \n    H2O cluster allowed cores:  24 \n    H2O cluster healthy:        TRUE \n    H2O Connection ip:          localhost \n    H2O Connection port:        54321 \n    H2O Connection proxy:       NA \n    H2O Internal Security:      FALSE \n    R Version:                  R version 4.5.2 (2025-10-31 ucrt) \n\n\nWarning in h2o.clusterInfo(): \nYour H2O cluster version is (1 year, 10 months and 22 days) old. There may be a newer version available.\nPlease download and install the latest version from: https://h2o-release.s3.amazonaws.com/h2o/latest_stable.html\n\n\n\n\n\n\nWe first need to load the dataset from csv. In real world scenario, this will be a database connection.\n\n# Read your dataset\names &lt;-read.csv(\"../data/AmesHousing2.csv\")\n# ames &lt;- AmesHousing::make_ames()\n\nwe need to convert the original dataset into an H20 object (to run the models)\n\names.h2o0 &lt;-as.h2o(ames)\n\nhead(ames$SalePrice)  # response variable\n\n[1] 171000 139000 159000 136000 230000 190000\n\ntarget &lt;- 'SalePrice'\npredictors &lt;- setdiff(colnames(ames), target)\n\nLet’s see what the data looks like by looking at the first few rows of the dataset.\n\nlibrary(kableExtra)\n\n\nAttaching package: 'kableExtra'\n\n\nThe following object is masked from 'package:dplyr':\n\n    group_rows\n\nkable(head(ames), \"html\") %&gt;% kable_styling(\"striped\") %&gt;% scroll_box(width = \"100%\")\n\n\n\n\n\nOrder\nLot.Frontage\nLot.Area\nLot.Shape\nUtilities\nLot.Config\nLand.Slope\nNeighborhood\nBldg.Type\nHouse.Style\nOverall.Qual\nOverall.Cond\nYear.Built\nYear.Remod.Add\nFoundation\nBsmt.Unf.SF\nTotal.Bsmt.SF\nBaseLivArea\nCentral.Air\nX1st.Flr.SF\nX2nd.Flr.SF\nGr.Liv.Area\nFull.Bath\nHalf.Bath\nBathrooms\nBedroom.AbvGr\nKitchen.AbvGr\nKitchen.Qual\nTotRms.AbvGrd\nFireplaces\nGarage.Type\nGarage.Area\nWood.Deck.SF\nOpen.Porch.SF\nEnclosed.Porch\nX3Ssn.Porch\nScreen.Porch\nMo.Sold\nYr.Sold\nSale.Condition\nSalePrice\n\n\n\n\n117\n80\n9600\nReg\nAllPub\nInside\nGtl\nNWAmes\n1Fam\n2Story\n6\n6\n1971\n1971\nCBlock\n386\n715\n329\nY\n930\n715\n1645\n1\n2\n2\n4\n1\nTA\n7\n0\nAttchd\n441\n0\n78\n0\n0\n0\n6\n2010\nNormal\n171000\n\n\n325\n94\n9400\nReg\nAllPub\nCorner\nGtl\nMitchel\nDuplex\n2Story\n6\n5\n1971\n1971\nCBlock\n912\n912\n0\nY\n912\n912\n1824\n2\n2\n3\n4\n2\nTA\n8\n0\nNA\n0\n128\n0\n0\n0\n0\n4\n2010\nNormal\n139000\n\n\n337\n70\n7700\nReg\nAllPub\nInside\nGtl\nMitchel\nDuplex\n2Story\n5\n2\n1985\n1986\nPConc\n1216\n1216\n0\nY\n1216\n1216\n2432\n4\n2\n5\n4\n2\nTA\n10\n0\nAttchd\n616\n200\n0\n0\n0\n0\n2\n2010\nNormal\n159000\n\n\n393\n60\n9000\nReg\nAllPub\nFR2\nGtl\nNAmes\nDuplex\n2Story\n5\n5\n1974\n1974\nCBlock\n896\n896\n0\nY\n896\n896\n1792\n2\n2\n3\n4\n2\nTA\n8\n0\nNA\n0\n32\n45\n0\n0\n0\n9\n2009\nNormal\n136000\n\n\n590\nNA\n13774\nIR1\nAllPub\nInside\nGtl\nNWAmes\n1Fam\n2Story\n7\n7\n1977\n1992\nPConc\n476\n908\n432\nY\n1316\n972\n2288\n1\n2\n2\n4\n1\nGd\n8\n2\nAttchd\n520\n321\n72\n0\n0\n156\n11\n2009\nNormal\n230000\n\n\n667\n81\n9671\nReg\nAllPub\nCorner\nGtl\nNAmes\nDuplex\n2Story\n6\n5\n1969\n1969\nCBlock\n1248\n1248\n0\nY\n1248\n1296\n2544\n2\n2\n3\n6\n2\nTA\n12\n0\nAttchd\n907\n0\n0\n0\n0\n0\n8\n2009\nNormal\n190000\n\n\n\n\n\n# head(ames)\n\nNow let the summary of the dataset\n\nlibrary(gtsummary)\nsummary(ames)\n\n     Order         Lot.Frontage       Lot.Area       Lot.Shape        \n Min.   :   1.0   Min.   : 21.00   Min.   :  1300   Length:2930       \n 1st Qu.: 733.2   1st Qu.: 58.00   1st Qu.:  7440   Class :character  \n Median :1465.5   Median : 68.00   Median :  9436   Mode  :character  \n Mean   :1465.5   Mean   : 69.22   Mean   : 10148                     \n 3rd Qu.:2197.8   3rd Qu.: 80.00   3rd Qu.: 11555                     \n Max.   :2930.0   Max.   :313.00   Max.   :215245                     \n                  NA's   :490                                         \n  Utilities          Lot.Config         Land.Slope        Neighborhood      \n Length:2930        Length:2930        Length:2930        Length:2930       \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n                                                                            \n  Bldg.Type         House.Style         Overall.Qual     Overall.Cond  \n Length:2930        Length:2930        Min.   : 1.000   Min.   :1.000  \n Class :character   Class :character   1st Qu.: 5.000   1st Qu.:5.000  \n Mode  :character   Mode  :character   Median : 6.000   Median :5.000  \n                                       Mean   : 6.095   Mean   :5.563  \n                                       3rd Qu.: 7.000   3rd Qu.:6.000  \n                                       Max.   :10.000   Max.   :9.000  \n                                                                       \n   Year.Built   Year.Remod.Add  Foundation         Bsmt.Unf.SF    \n Min.   :1872   Min.   :1950   Length:2930        Min.   :   0.0  \n 1st Qu.:1954   1st Qu.:1965   Class :character   1st Qu.: 219.0  \n Median :1973   Median :1993   Mode  :character   Median : 466.0  \n Mean   :1971   Mean   :1984                      Mean   : 559.3  \n 3rd Qu.:2001   3rd Qu.:2004                      3rd Qu.: 802.0  \n Max.   :2010   Max.   :2010                      Max.   :2336.0  \n                                                  NA's   :1       \n Total.Bsmt.SF   BaseLivArea     Central.Air         X1st.Flr.SF    \n Min.   :   0   Min.   :   0.0   Length:2930        Min.   : 334.0  \n 1st Qu.: 793   1st Qu.:   0.0   Class :character   1st Qu.: 876.2  \n Median : 990   Median : 459.5   Mode  :character   Median :1084.0  \n Mean   :1052   Mean   : 492.2                      Mean   :1159.6  \n 3rd Qu.:1302   3rd Qu.: 808.0                      3rd Qu.:1384.0  \n Max.   :6110   Max.   :5644.0                      Max.   :5095.0  \n NA's   :1                                                          \n  X2nd.Flr.SF      Gr.Liv.Area     Full.Bath       Half.Bath     \n Min.   :   0.0   Min.   : 334   Min.   :0.000   Min.   :0.0000  \n 1st Qu.:   0.0   1st Qu.:1126   1st Qu.:1.000   1st Qu.:0.0000  \n Median :   0.0   Median :1442   Median :2.000   Median :0.0000  \n Mean   : 335.5   Mean   :1500   Mean   :1.567   Mean   :0.3795  \n 3rd Qu.: 703.8   3rd Qu.:1743   3rd Qu.:2.000   3rd Qu.:1.0000  \n Max.   :2065.0   Max.   :5642   Max.   :4.000   Max.   :2.0000  \n                                                                 \n   Bathrooms     Bedroom.AbvGr   Kitchen.AbvGr   Kitchen.Qual      \n Min.   :0.000   Min.   :0.000   Min.   :0.000   Length:2930       \n 1st Qu.:1.000   1st Qu.:2.000   1st Qu.:1.000   Class :character  \n Median :2.000   Median :3.000   Median :1.000   Mode  :character  \n Mean   :1.756   Mean   :2.854   Mean   :1.044                     \n 3rd Qu.:2.500   3rd Qu.:3.000   3rd Qu.:1.000                     \n Max.   :5.000   Max.   :8.000   Max.   :3.000                     \n                                                                   \n TotRms.AbvGrd      Fireplaces     Garage.Type         Garage.Area    \n Min.   : 2.000   Min.   :0.0000   Length:2930        Min.   :   0.0  \n 1st Qu.: 5.000   1st Qu.:0.0000   Class :character   1st Qu.: 320.0  \n Median : 6.000   Median :1.0000   Mode  :character   Median : 480.0  \n Mean   : 6.443   Mean   :0.5993                      Mean   : 472.8  \n 3rd Qu.: 7.000   3rd Qu.:1.0000                      3rd Qu.: 576.0  \n Max.   :15.000   Max.   :4.0000                      Max.   :1488.0  \n                                                      NA's   :1       \n  Wood.Deck.SF     Open.Porch.SF    Enclosed.Porch     X3Ssn.Porch     \n Min.   :   0.00   Min.   :  0.00   Min.   :   0.00   Min.   :  0.000  \n 1st Qu.:   0.00   1st Qu.:  0.00   1st Qu.:   0.00   1st Qu.:  0.000  \n Median :   0.00   Median : 27.00   Median :   0.00   Median :  0.000  \n Mean   :  93.75   Mean   : 47.53   Mean   :  23.01   Mean   :  2.592  \n 3rd Qu.: 168.00   3rd Qu.: 70.00   3rd Qu.:   0.00   3rd Qu.:  0.000  \n Max.   :1424.00   Max.   :742.00   Max.   :1012.00   Max.   :508.000  \n                                                                       \n  Screen.Porch    Mo.Sold          Yr.Sold     Sale.Condition    \n Min.   :  0   Min.   : 1.000   Min.   :2006   Length:2930       \n 1st Qu.:  0   1st Qu.: 4.000   1st Qu.:2007   Class :character  \n Median :  0   Median : 6.000   Median :2008   Mode  :character  \n Mean   : 16   Mean   : 6.216   Mean   :2008                     \n 3rd Qu.:  0   3rd Qu.: 8.000   3rd Qu.:2009                     \n Max.   :576   Max.   :12.000   Max.   :2010                     \n                                                                 \n   SalePrice     \n Min.   : 12789  \n 1st Qu.:129500  \n Median :160000  \n Mean   :180796  \n 3rd Qu.:213500  \n Max.   :755000  \n                 \n\n\nLet’s see a better table for the summary\n\n ames %&gt;% \n gtsummary::tbl_summary(\n  ) %&gt;% \n  gtsummary::bold_labels() %&gt;% \n  gtsummary::as_kable_extra(\n    format = \"html\",\n    longtable = TRUE,\n    linesep = \"\"\n    ) %&gt;%\n  kableExtra::kable_styling(\n      position = \"left\",\n      latex_options = c(\"striped\", \"repeat_header\"),\n      stripe_color = \"gray!15\"\n    )\n\n\n\n\nCharacteristic\nN = 2,930\n\n\n\n\nOrder\n1,466 (733, 2,198)\n\n\nLot.Frontage\n68 (58, 80)\n\n\nUnknown\n490\n\n\nLot.Area\n9,437 (7,440, 11,556)\n\n\nLot.Shape\n\n\n\nIR1\n979 (33%)\n\n\nIR2\n76 (2.6%)\n\n\nIR3\n16 (0.5%)\n\n\nReg\n1,859 (63%)\n\n\nUtilities\n\n\n\nAllPub\n2,927 (100%)\n\n\nNoSeWa\n1 (&lt;0.1%)\n\n\nNoSewr\n2 (&lt;0.1%)\n\n\nLot.Config\n\n\n\nCorner\n511 (17%)\n\n\nCulDSac\n180 (6.1%)\n\n\nFR2\n85 (2.9%)\n\n\nFR3\n14 (0.5%)\n\n\nInside\n2,140 (73%)\n\n\nLand.Slope\n\n\n\nGtl\n2,789 (95%)\n\n\nMod\n125 (4.3%)\n\n\nSev\n16 (0.5%)\n\n\nNeighborhood\n\n\n\nBlmngtn\n28 (1.0%)\n\n\nBlueste\n10 (0.3%)\n\n\nBrDale\n30 (1.0%)\n\n\nBrkSide\n108 (3.7%)\n\n\nClearCr\n44 (1.5%)\n\n\nCollgCr\n267 (9.1%)\n\n\nCrawfor\n103 (3.5%)\n\n\nEdwards\n194 (6.6%)\n\n\nGilbert\n165 (5.6%)\n\n\nGreens\n8 (0.3%)\n\n\nGrnHill\n2 (&lt;0.1%)\n\n\nIDOTRR\n93 (3.2%)\n\n\nLandmrk\n1 (&lt;0.1%)\n\n\nMeadowV\n37 (1.3%)\n\n\nMitchel\n114 (3.9%)\n\n\nNAmes\n443 (15%)\n\n\nNoRidge\n71 (2.4%)\n\n\nNPkVill\n23 (0.8%)\n\n\nNridgHt\n166 (5.7%)\n\n\nNWAmes\n131 (4.5%)\n\n\nOldTown\n239 (8.2%)\n\n\nSawyer\n151 (5.2%)\n\n\nSawyerW\n125 (4.3%)\n\n\nSomerst\n182 (6.2%)\n\n\nStoneBr\n51 (1.7%)\n\n\nSWISU\n48 (1.6%)\n\n\nTimber\n72 (2.5%)\n\n\nVeenker\n24 (0.8%)\n\n\nBldg.Type\n\n\n\n1Fam\n2,425 (83%)\n\n\n2fmCon\n62 (2.1%)\n\n\nDuplex\n109 (3.7%)\n\n\nTwnhs\n101 (3.4%)\n\n\nTwnhsE\n233 (8.0%)\n\n\nHouse.Style\n\n\n\n1.5Fin\n314 (11%)\n\n\n1.5Unf\n19 (0.6%)\n\n\n1Story\n1,481 (51%)\n\n\n2.5Fin\n8 (0.3%)\n\n\n2.5Unf\n24 (0.8%)\n\n\n2Story\n873 (30%)\n\n\nSFoyer\n83 (2.8%)\n\n\nSLvl\n128 (4.4%)\n\n\nOverall.Qual\n6 (5, 7)\n\n\nOverall.Cond\n\n\n\n1\n7 (0.2%)\n\n\n2\n10 (0.3%)\n\n\n3\n50 (1.7%)\n\n\n4\n101 (3.4%)\n\n\n5\n1,654 (56%)\n\n\n6\n533 (18%)\n\n\n7\n390 (13%)\n\n\n8\n144 (4.9%)\n\n\n9\n41 (1.4%)\n\n\nYear.Built\n1,973 (1,954, 2,001)\n\n\nYear.Remod.Add\n1,993 (1,965, 2,004)\n\n\nFoundation\n\n\n\nBrkTil\n311 (11%)\n\n\nCBlock\n1,244 (42%)\n\n\nPConc\n1,310 (45%)\n\n\nSlab\n49 (1.7%)\n\n\nStone\n11 (0.4%)\n\n\nWood\n5 (0.2%)\n\n\nBsmt.Unf.SF\n466 (219, 802)\n\n\nUnknown\n1\n\n\nTotal.Bsmt.SF\n990 (793, 1,302)\n\n\nUnknown\n1\n\n\nBaseLivArea\n460 (0, 808)\n\n\nCentral.Air\n\n\n\nN\n196 (6.7%)\n\n\nY\n2,734 (93%)\n\n\nX1st.Flr.SF\n1,084 (876, 1,384)\n\n\nX2nd.Flr.SF\n0 (0, 704)\n\n\nGr.Liv.Area\n1,442 (1,126, 1,743)\n\n\nFull.Bath\n\n\n\n0\n12 (0.4%)\n\n\n1\n1,318 (45%)\n\n\n2\n1,532 (52%)\n\n\n3\n64 (2.2%)\n\n\n4\n4 (0.1%)\n\n\nHalf.Bath\n\n\n\n0\n1,843 (63%)\n\n\n1\n1,062 (36%)\n\n\n2\n25 (0.9%)\n\n\nBathrooms\n2.00 (1.00, 2.50)\n\n\nBedroom.AbvGr\n\n\n\n0\n8 (0.3%)\n\n\n1\n112 (3.8%)\n\n\n2\n743 (25%)\n\n\n3\n1,597 (55%)\n\n\n4\n400 (14%)\n\n\n5\n48 (1.6%)\n\n\n6\n21 (0.7%)\n\n\n8\n1 (&lt;0.1%)\n\n\nKitchen.AbvGr\n\n\n\n0\n3 (0.1%)\n\n\n1\n2,796 (95%)\n\n\n2\n129 (4.4%)\n\n\n3\n2 (&lt;0.1%)\n\n\nKitchen.Qual\n\n\n\nEx\n205 (7.0%)\n\n\nFa\n70 (2.4%)\n\n\nGd\n1,160 (40%)\n\n\nPo\n1 (&lt;0.1%)\n\n\nTA\n1,494 (51%)\n\n\nTotRms.AbvGrd\n6 (5, 7)\n\n\nFireplaces\n\n\n\n0\n1,422 (49%)\n\n\n1\n1,274 (43%)\n\n\n2\n221 (7.5%)\n\n\n3\n12 (0.4%)\n\n\n4\n1 (&lt;0.1%)\n\n\nGarage.Type\n\n\n\n2Types\n23 (0.8%)\n\n\nAttchd\n1,731 (62%)\n\n\nBasment\n36 (1.3%)\n\n\nBuiltIn\n186 (6.7%)\n\n\nCarPort\n15 (0.5%)\n\n\nDetchd\n782 (28%)\n\n\nUnknown\n157\n\n\nGarage.Area\n480 (320, 576)\n\n\nUnknown\n1\n\n\nWood.Deck.SF\n0 (0, 168)\n\n\nOpen.Porch.SF\n27 (0, 70)\n\n\nEnclosed.Porch\n0 (0, 0)\n\n\nX3Ssn.Porch\n0 (0, 0)\n\n\nScreen.Porch\n0 (0, 0)\n\n\nMo.Sold\n6 (4, 8)\n\n\nYr.Sold\n\n\n\n2006\n625 (21%)\n\n\n2007\n694 (24%)\n\n\n2008\n622 (21%)\n\n\n2009\n648 (22%)\n\n\n2010\n341 (12%)\n\n\nSale.Condition\n\n\n\nAbnorml\n190 (6.5%)\n\n\nAdjLand\n12 (0.4%)\n\n\nAlloca\n24 (0.8%)\n\n\nFamily\n46 (1.6%)\n\n\nNormal\n2,413 (82%)\n\n\nPartial\n245 (8.4%)\n\n\nSalePrice\n160,000 (129,500, 213,500)\n\n\n\n1 Median (Q1, Q3); n (%)\n\n\n\n\n\n\n\n\n\n\nThe dataset contains both numeric and categorical variables. We need to separate them for further analysis. This is especially important for feature engineering.\n\nnum_vars&lt;-colnames(ames[sapply(ames, is.numeric) == TRUE])\ncat_vars&lt;-colnames(ames[sapply(ames, is.character) == TRUE])\n\n\n\n\nThere are two ways we can use the variables from the r code in the text. The first one is by using stmt output using print and the other is using r output.\n\n\n\nstmt &lt;- paste(\"There are\", length(num_vars), \"numerical features and\", length(cat_vars), \"categorical features\" )\nprint(stmt, na.print = NULL)\n\n[1] \"There are 29 numerical features and 12 categorical features\"\n\n\n\n\n\nThere are 29 numerical features and 12 categorical features in this dataset."
  },
  {
    "objectID": "M1/M1LN1.html#modeling-process-packages",
    "href": "M1/M1LN1.html#modeling-process-packages",
    "title": "Data Partitioning and Feature Engineering",
    "section": "",
    "text": "library(rsample)  # for resampling procedures\nlibrary(caret)    # for resampling and model training\nlibrary(h2o)      # for resampling and model training\n\n\n\nH2O is a fully open-source, distributed in-memory machine-learning platform with linear scalability. H2O supports the most widely used statistical & machine learning algorithms including gradient-boosted machines, generalized linear models, deep learning and more. H2O also has an industry-leading AutoML functionality that automatically runs through all the algorithms and their hyperparameters to produce a leaderboard of the best models. The H2O platform is used by over 18,000 organizations globally and is extremely popular in both the R & Python communities.\n\n# h20 set up\n\nh2o.no_progress() # turn off h20\nh2o.init()        # launch h20\n\n\nH2O is not running yet, starting it now...\n\nNote:  In case of errors look at the following log files:\n    C:\\Users\\NAKULP~1\\AppData\\Local\\Temp\\Rtmp2FlOF9\\file2bb44aab6d58/h2o_nakulpadalkar_started_from_r.out\n    C:\\Users\\NAKULP~1\\AppData\\Local\\Temp\\Rtmp2FlOF9\\file2bb41a5810f0/h2o_nakulpadalkar_started_from_r.err\n\n\nStarting H2O JVM and connecting:  Connection successful!\n\nR is connected to the H2O cluster: \n    H2O cluster uptime:         3 seconds 72 milliseconds \n    H2O cluster timezone:       America/New_York \n    H2O data parsing timezone:  UTC \n    H2O cluster version:        3.44.0.3 \n    H2O cluster version age:    1 year, 10 months and 22 days \n    H2O cluster name:           H2O_started_from_R_nakulpadalkar_xwc036 \n    H2O cluster total nodes:    1 \n    H2O cluster total memory:   15.98 GB \n    H2O cluster total cores:    24 \n    H2O cluster allowed cores:  24 \n    H2O cluster healthy:        TRUE \n    H2O Connection ip:          localhost \n    H2O Connection port:        54321 \n    H2O Connection proxy:       NA \n    H2O Internal Security:      FALSE \n    R Version:                  R version 4.5.2 (2025-10-31 ucrt) \n\n\nWarning in h2o.clusterInfo(): \nYour H2O cluster version is (1 year, 10 months and 22 days) old. There may be a newer version available.\nPlease download and install the latest version from: https://h2o-release.s3.amazonaws.com/h2o/latest_stable.html"
  },
  {
    "objectID": "M1/M1LN1.html#loading-and-importing-data",
    "href": "M1/M1LN1.html#loading-and-importing-data",
    "title": "Data Partitioning and Feature Engineering",
    "section": "",
    "text": "We first need to load the dataset from csv. In real world scenario, this will be a database connection.\n\n# Read your dataset\names &lt;-read.csv(\"../data/AmesHousing2.csv\")\n# ames &lt;- AmesHousing::make_ames()\n\nwe need to convert the original dataset into an H20 object (to run the models)\n\names.h2o0 &lt;-as.h2o(ames)\n\nhead(ames$SalePrice)  # response variable\n\n[1] 171000 139000 159000 136000 230000 190000\n\ntarget &lt;- 'SalePrice'\npredictors &lt;- setdiff(colnames(ames), target)\n\nLet’s see what the data looks like by looking at the first few rows of the dataset.\n\nlibrary(kableExtra)\n\n\nAttaching package: 'kableExtra'\n\n\nThe following object is masked from 'package:dplyr':\n\n    group_rows\n\nkable(head(ames), \"html\") %&gt;% kable_styling(\"striped\") %&gt;% scroll_box(width = \"100%\")\n\n\n\n\n\nOrder\nLot.Frontage\nLot.Area\nLot.Shape\nUtilities\nLot.Config\nLand.Slope\nNeighborhood\nBldg.Type\nHouse.Style\nOverall.Qual\nOverall.Cond\nYear.Built\nYear.Remod.Add\nFoundation\nBsmt.Unf.SF\nTotal.Bsmt.SF\nBaseLivArea\nCentral.Air\nX1st.Flr.SF\nX2nd.Flr.SF\nGr.Liv.Area\nFull.Bath\nHalf.Bath\nBathrooms\nBedroom.AbvGr\nKitchen.AbvGr\nKitchen.Qual\nTotRms.AbvGrd\nFireplaces\nGarage.Type\nGarage.Area\nWood.Deck.SF\nOpen.Porch.SF\nEnclosed.Porch\nX3Ssn.Porch\nScreen.Porch\nMo.Sold\nYr.Sold\nSale.Condition\nSalePrice\n\n\n\n\n117\n80\n9600\nReg\nAllPub\nInside\nGtl\nNWAmes\n1Fam\n2Story\n6\n6\n1971\n1971\nCBlock\n386\n715\n329\nY\n930\n715\n1645\n1\n2\n2\n4\n1\nTA\n7\n0\nAttchd\n441\n0\n78\n0\n0\n0\n6\n2010\nNormal\n171000\n\n\n325\n94\n9400\nReg\nAllPub\nCorner\nGtl\nMitchel\nDuplex\n2Story\n6\n5\n1971\n1971\nCBlock\n912\n912\n0\nY\n912\n912\n1824\n2\n2\n3\n4\n2\nTA\n8\n0\nNA\n0\n128\n0\n0\n0\n0\n4\n2010\nNormal\n139000\n\n\n337\n70\n7700\nReg\nAllPub\nInside\nGtl\nMitchel\nDuplex\n2Story\n5\n2\n1985\n1986\nPConc\n1216\n1216\n0\nY\n1216\n1216\n2432\n4\n2\n5\n4\n2\nTA\n10\n0\nAttchd\n616\n200\n0\n0\n0\n0\n2\n2010\nNormal\n159000\n\n\n393\n60\n9000\nReg\nAllPub\nFR2\nGtl\nNAmes\nDuplex\n2Story\n5\n5\n1974\n1974\nCBlock\n896\n896\n0\nY\n896\n896\n1792\n2\n2\n3\n4\n2\nTA\n8\n0\nNA\n0\n32\n45\n0\n0\n0\n9\n2009\nNormal\n136000\n\n\n590\nNA\n13774\nIR1\nAllPub\nInside\nGtl\nNWAmes\n1Fam\n2Story\n7\n7\n1977\n1992\nPConc\n476\n908\n432\nY\n1316\n972\n2288\n1\n2\n2\n4\n1\nGd\n8\n2\nAttchd\n520\n321\n72\n0\n0\n156\n11\n2009\nNormal\n230000\n\n\n667\n81\n9671\nReg\nAllPub\nCorner\nGtl\nNAmes\nDuplex\n2Story\n6\n5\n1969\n1969\nCBlock\n1248\n1248\n0\nY\n1248\n1296\n2544\n2\n2\n3\n6\n2\nTA\n12\n0\nAttchd\n907\n0\n0\n0\n0\n0\n8\n2009\nNormal\n190000\n\n\n\n\n\n# head(ames)\n\nNow let the summary of the dataset\n\nlibrary(gtsummary)\nsummary(ames)\n\n     Order         Lot.Frontage       Lot.Area       Lot.Shape        \n Min.   :   1.0   Min.   : 21.00   Min.   :  1300   Length:2930       \n 1st Qu.: 733.2   1st Qu.: 58.00   1st Qu.:  7440   Class :character  \n Median :1465.5   Median : 68.00   Median :  9436   Mode  :character  \n Mean   :1465.5   Mean   : 69.22   Mean   : 10148                     \n 3rd Qu.:2197.8   3rd Qu.: 80.00   3rd Qu.: 11555                     \n Max.   :2930.0   Max.   :313.00   Max.   :215245                     \n                  NA's   :490                                         \n  Utilities          Lot.Config         Land.Slope        Neighborhood      \n Length:2930        Length:2930        Length:2930        Length:2930       \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n                                                                            \n  Bldg.Type         House.Style         Overall.Qual     Overall.Cond  \n Length:2930        Length:2930        Min.   : 1.000   Min.   :1.000  \n Class :character   Class :character   1st Qu.: 5.000   1st Qu.:5.000  \n Mode  :character   Mode  :character   Median : 6.000   Median :5.000  \n                                       Mean   : 6.095   Mean   :5.563  \n                                       3rd Qu.: 7.000   3rd Qu.:6.000  \n                                       Max.   :10.000   Max.   :9.000  \n                                                                       \n   Year.Built   Year.Remod.Add  Foundation         Bsmt.Unf.SF    \n Min.   :1872   Min.   :1950   Length:2930        Min.   :   0.0  \n 1st Qu.:1954   1st Qu.:1965   Class :character   1st Qu.: 219.0  \n Median :1973   Median :1993   Mode  :character   Median : 466.0  \n Mean   :1971   Mean   :1984                      Mean   : 559.3  \n 3rd Qu.:2001   3rd Qu.:2004                      3rd Qu.: 802.0  \n Max.   :2010   Max.   :2010                      Max.   :2336.0  \n                                                  NA's   :1       \n Total.Bsmt.SF   BaseLivArea     Central.Air         X1st.Flr.SF    \n Min.   :   0   Min.   :   0.0   Length:2930        Min.   : 334.0  \n 1st Qu.: 793   1st Qu.:   0.0   Class :character   1st Qu.: 876.2  \n Median : 990   Median : 459.5   Mode  :character   Median :1084.0  \n Mean   :1052   Mean   : 492.2                      Mean   :1159.6  \n 3rd Qu.:1302   3rd Qu.: 808.0                      3rd Qu.:1384.0  \n Max.   :6110   Max.   :5644.0                      Max.   :5095.0  \n NA's   :1                                                          \n  X2nd.Flr.SF      Gr.Liv.Area     Full.Bath       Half.Bath     \n Min.   :   0.0   Min.   : 334   Min.   :0.000   Min.   :0.0000  \n 1st Qu.:   0.0   1st Qu.:1126   1st Qu.:1.000   1st Qu.:0.0000  \n Median :   0.0   Median :1442   Median :2.000   Median :0.0000  \n Mean   : 335.5   Mean   :1500   Mean   :1.567   Mean   :0.3795  \n 3rd Qu.: 703.8   3rd Qu.:1743   3rd Qu.:2.000   3rd Qu.:1.0000  \n Max.   :2065.0   Max.   :5642   Max.   :4.000   Max.   :2.0000  \n                                                                 \n   Bathrooms     Bedroom.AbvGr   Kitchen.AbvGr   Kitchen.Qual      \n Min.   :0.000   Min.   :0.000   Min.   :0.000   Length:2930       \n 1st Qu.:1.000   1st Qu.:2.000   1st Qu.:1.000   Class :character  \n Median :2.000   Median :3.000   Median :1.000   Mode  :character  \n Mean   :1.756   Mean   :2.854   Mean   :1.044                     \n 3rd Qu.:2.500   3rd Qu.:3.000   3rd Qu.:1.000                     \n Max.   :5.000   Max.   :8.000   Max.   :3.000                     \n                                                                   \n TotRms.AbvGrd      Fireplaces     Garage.Type         Garage.Area    \n Min.   : 2.000   Min.   :0.0000   Length:2930        Min.   :   0.0  \n 1st Qu.: 5.000   1st Qu.:0.0000   Class :character   1st Qu.: 320.0  \n Median : 6.000   Median :1.0000   Mode  :character   Median : 480.0  \n Mean   : 6.443   Mean   :0.5993                      Mean   : 472.8  \n 3rd Qu.: 7.000   3rd Qu.:1.0000                      3rd Qu.: 576.0  \n Max.   :15.000   Max.   :4.0000                      Max.   :1488.0  \n                                                      NA's   :1       \n  Wood.Deck.SF     Open.Porch.SF    Enclosed.Porch     X3Ssn.Porch     \n Min.   :   0.00   Min.   :  0.00   Min.   :   0.00   Min.   :  0.000  \n 1st Qu.:   0.00   1st Qu.:  0.00   1st Qu.:   0.00   1st Qu.:  0.000  \n Median :   0.00   Median : 27.00   Median :   0.00   Median :  0.000  \n Mean   :  93.75   Mean   : 47.53   Mean   :  23.01   Mean   :  2.592  \n 3rd Qu.: 168.00   3rd Qu.: 70.00   3rd Qu.:   0.00   3rd Qu.:  0.000  \n Max.   :1424.00   Max.   :742.00   Max.   :1012.00   Max.   :508.000  \n                                                                       \n  Screen.Porch    Mo.Sold          Yr.Sold     Sale.Condition    \n Min.   :  0   Min.   : 1.000   Min.   :2006   Length:2930       \n 1st Qu.:  0   1st Qu.: 4.000   1st Qu.:2007   Class :character  \n Median :  0   Median : 6.000   Median :2008   Mode  :character  \n Mean   : 16   Mean   : 6.216   Mean   :2008                     \n 3rd Qu.:  0   3rd Qu.: 8.000   3rd Qu.:2009                     \n Max.   :576   Max.   :12.000   Max.   :2010                     \n                                                                 \n   SalePrice     \n Min.   : 12789  \n 1st Qu.:129500  \n Median :160000  \n Mean   :180796  \n 3rd Qu.:213500  \n Max.   :755000  \n                 \n\n\nLet’s see a better table for the summary\n\n ames %&gt;% \n gtsummary::tbl_summary(\n  ) %&gt;% \n  gtsummary::bold_labels() %&gt;% \n  gtsummary::as_kable_extra(\n    format = \"html\",\n    longtable = TRUE,\n    linesep = \"\"\n    ) %&gt;%\n  kableExtra::kable_styling(\n      position = \"left\",\n      latex_options = c(\"striped\", \"repeat_header\"),\n      stripe_color = \"gray!15\"\n    )\n\n\n\n\nCharacteristic\nN = 2,930\n\n\n\n\nOrder\n1,466 (733, 2,198)\n\n\nLot.Frontage\n68 (58, 80)\n\n\nUnknown\n490\n\n\nLot.Area\n9,437 (7,440, 11,556)\n\n\nLot.Shape\n\n\n\nIR1\n979 (33%)\n\n\nIR2\n76 (2.6%)\n\n\nIR3\n16 (0.5%)\n\n\nReg\n1,859 (63%)\n\n\nUtilities\n\n\n\nAllPub\n2,927 (100%)\n\n\nNoSeWa\n1 (&lt;0.1%)\n\n\nNoSewr\n2 (&lt;0.1%)\n\n\nLot.Config\n\n\n\nCorner\n511 (17%)\n\n\nCulDSac\n180 (6.1%)\n\n\nFR2\n85 (2.9%)\n\n\nFR3\n14 (0.5%)\n\n\nInside\n2,140 (73%)\n\n\nLand.Slope\n\n\n\nGtl\n2,789 (95%)\n\n\nMod\n125 (4.3%)\n\n\nSev\n16 (0.5%)\n\n\nNeighborhood\n\n\n\nBlmngtn\n28 (1.0%)\n\n\nBlueste\n10 (0.3%)\n\n\nBrDale\n30 (1.0%)\n\n\nBrkSide\n108 (3.7%)\n\n\nClearCr\n44 (1.5%)\n\n\nCollgCr\n267 (9.1%)\n\n\nCrawfor\n103 (3.5%)\n\n\nEdwards\n194 (6.6%)\n\n\nGilbert\n165 (5.6%)\n\n\nGreens\n8 (0.3%)\n\n\nGrnHill\n2 (&lt;0.1%)\n\n\nIDOTRR\n93 (3.2%)\n\n\nLandmrk\n1 (&lt;0.1%)\n\n\nMeadowV\n37 (1.3%)\n\n\nMitchel\n114 (3.9%)\n\n\nNAmes\n443 (15%)\n\n\nNoRidge\n71 (2.4%)\n\n\nNPkVill\n23 (0.8%)\n\n\nNridgHt\n166 (5.7%)\n\n\nNWAmes\n131 (4.5%)\n\n\nOldTown\n239 (8.2%)\n\n\nSawyer\n151 (5.2%)\n\n\nSawyerW\n125 (4.3%)\n\n\nSomerst\n182 (6.2%)\n\n\nStoneBr\n51 (1.7%)\n\n\nSWISU\n48 (1.6%)\n\n\nTimber\n72 (2.5%)\n\n\nVeenker\n24 (0.8%)\n\n\nBldg.Type\n\n\n\n1Fam\n2,425 (83%)\n\n\n2fmCon\n62 (2.1%)\n\n\nDuplex\n109 (3.7%)\n\n\nTwnhs\n101 (3.4%)\n\n\nTwnhsE\n233 (8.0%)\n\n\nHouse.Style\n\n\n\n1.5Fin\n314 (11%)\n\n\n1.5Unf\n19 (0.6%)\n\n\n1Story\n1,481 (51%)\n\n\n2.5Fin\n8 (0.3%)\n\n\n2.5Unf\n24 (0.8%)\n\n\n2Story\n873 (30%)\n\n\nSFoyer\n83 (2.8%)\n\n\nSLvl\n128 (4.4%)\n\n\nOverall.Qual\n6 (5, 7)\n\n\nOverall.Cond\n\n\n\n1\n7 (0.2%)\n\n\n2\n10 (0.3%)\n\n\n3\n50 (1.7%)\n\n\n4\n101 (3.4%)\n\n\n5\n1,654 (56%)\n\n\n6\n533 (18%)\n\n\n7\n390 (13%)\n\n\n8\n144 (4.9%)\n\n\n9\n41 (1.4%)\n\n\nYear.Built\n1,973 (1,954, 2,001)\n\n\nYear.Remod.Add\n1,993 (1,965, 2,004)\n\n\nFoundation\n\n\n\nBrkTil\n311 (11%)\n\n\nCBlock\n1,244 (42%)\n\n\nPConc\n1,310 (45%)\n\n\nSlab\n49 (1.7%)\n\n\nStone\n11 (0.4%)\n\n\nWood\n5 (0.2%)\n\n\nBsmt.Unf.SF\n466 (219, 802)\n\n\nUnknown\n1\n\n\nTotal.Bsmt.SF\n990 (793, 1,302)\n\n\nUnknown\n1\n\n\nBaseLivArea\n460 (0, 808)\n\n\nCentral.Air\n\n\n\nN\n196 (6.7%)\n\n\nY\n2,734 (93%)\n\n\nX1st.Flr.SF\n1,084 (876, 1,384)\n\n\nX2nd.Flr.SF\n0 (0, 704)\n\n\nGr.Liv.Area\n1,442 (1,126, 1,743)\n\n\nFull.Bath\n\n\n\n0\n12 (0.4%)\n\n\n1\n1,318 (45%)\n\n\n2\n1,532 (52%)\n\n\n3\n64 (2.2%)\n\n\n4\n4 (0.1%)\n\n\nHalf.Bath\n\n\n\n0\n1,843 (63%)\n\n\n1\n1,062 (36%)\n\n\n2\n25 (0.9%)\n\n\nBathrooms\n2.00 (1.00, 2.50)\n\n\nBedroom.AbvGr\n\n\n\n0\n8 (0.3%)\n\n\n1\n112 (3.8%)\n\n\n2\n743 (25%)\n\n\n3\n1,597 (55%)\n\n\n4\n400 (14%)\n\n\n5\n48 (1.6%)\n\n\n6\n21 (0.7%)\n\n\n8\n1 (&lt;0.1%)\n\n\nKitchen.AbvGr\n\n\n\n0\n3 (0.1%)\n\n\n1\n2,796 (95%)\n\n\n2\n129 (4.4%)\n\n\n3\n2 (&lt;0.1%)\n\n\nKitchen.Qual\n\n\n\nEx\n205 (7.0%)\n\n\nFa\n70 (2.4%)\n\n\nGd\n1,160 (40%)\n\n\nPo\n1 (&lt;0.1%)\n\n\nTA\n1,494 (51%)\n\n\nTotRms.AbvGrd\n6 (5, 7)\n\n\nFireplaces\n\n\n\n0\n1,422 (49%)\n\n\n1\n1,274 (43%)\n\n\n2\n221 (7.5%)\n\n\n3\n12 (0.4%)\n\n\n4\n1 (&lt;0.1%)\n\n\nGarage.Type\n\n\n\n2Types\n23 (0.8%)\n\n\nAttchd\n1,731 (62%)\n\n\nBasment\n36 (1.3%)\n\n\nBuiltIn\n186 (6.7%)\n\n\nCarPort\n15 (0.5%)\n\n\nDetchd\n782 (28%)\n\n\nUnknown\n157\n\n\nGarage.Area\n480 (320, 576)\n\n\nUnknown\n1\n\n\nWood.Deck.SF\n0 (0, 168)\n\n\nOpen.Porch.SF\n27 (0, 70)\n\n\nEnclosed.Porch\n0 (0, 0)\n\n\nX3Ssn.Porch\n0 (0, 0)\n\n\nScreen.Porch\n0 (0, 0)\n\n\nMo.Sold\n6 (4, 8)\n\n\nYr.Sold\n\n\n\n2006\n625 (21%)\n\n\n2007\n694 (24%)\n\n\n2008\n622 (21%)\n\n\n2009\n648 (22%)\n\n\n2010\n341 (12%)\n\n\nSale.Condition\n\n\n\nAbnorml\n190 (6.5%)\n\n\nAdjLand\n12 (0.4%)\n\n\nAlloca\n24 (0.8%)\n\n\nFamily\n46 (1.6%)\n\n\nNormal\n2,413 (82%)\n\n\nPartial\n245 (8.4%)\n\n\nSalePrice\n160,000 (129,500, 213,500)\n\n\n\n1 Median (Q1, Q3); n (%)"
  },
  {
    "objectID": "M1/M1LN1.html#variable-separation",
    "href": "M1/M1LN1.html#variable-separation",
    "title": "Data Partitioning and Feature Engineering",
    "section": "",
    "text": "The dataset contains both numeric and categorical variables. We need to separate them for further analysis. This is especially important for feature engineering.\n\nnum_vars&lt;-colnames(ames[sapply(ames, is.numeric) == TRUE])\ncat_vars&lt;-colnames(ames[sapply(ames, is.character) == TRUE])"
  },
  {
    "objectID": "M1/M1LN1.html#side-note-on-text-and-variable-outputs",
    "href": "M1/M1LN1.html#side-note-on-text-and-variable-outputs",
    "title": "Data Partitioning and Feature Engineering",
    "section": "",
    "text": "There are two ways we can use the variables from the r code in the text. The first one is by using stmt output using print and the other is using r output.\n\n\n\nstmt &lt;- paste(\"There are\", length(num_vars), \"numerical features and\", length(cat_vars), \"categorical features\" )\nprint(stmt, na.print = NULL)\n\n[1] \"There are 29 numerical features and 12 categorical features\"\n\n\n\n\n\nThere are 29 numerical features and 12 categorical features in this dataset."
  },
  {
    "objectID": "M1/M1LN1.html#test-set-approach",
    "href": "M1/M1LN1.html#test-set-approach",
    "title": "Data Partitioning and Feature Engineering",
    "section": "2.1 Test Set Approach",
    "text": "2.1 Test Set Approach\nThere are multiple ways to split your data in R (four ways shown below)Simple Random Sampling is one of them.\n\n2.1.1 Using base R\n\nset.seed(123)  # for reproducibility\nindex_1 &lt;- sample(1:nrow(ames), round(nrow(ames) * 0.8))\ntrain_1 &lt;- ames[index_1, ]\ntest_1  &lt;- ames[-index_1, ]\n\n# kable(head(train), \"html\") %&gt;% kable_styling(\"striped\") %&gt;% scroll_box(width = \"100%\")\nprint(dim(train_1))\n\n[1] 2344   41\n\nprint(dim(test_1))\n\n[1] 586  41\n\n\n\n\n2.1.2 Using caret package\n\nset.seed(123)  # for reproducibility\nindex_2 &lt;- createDataPartition(ames$SalePrice, p = 0.7, \n                               list = FALSE)\ntrain_2 &lt;- ames[index_2, ]\ntest_2  &lt;- ames[-index_2, ]\n\n\n\n2.1.3 Using rsample package\n\nset.seed(123)  # for reproducibility\nsplit_1  &lt;- initial_split(ames, prop = 0.7)\ntrain_3  &lt;- training(split_1)\ntest_3   &lt;- testing(split_1)\n\n\n\n2.1.4 Using h2o package\n\nsplit_2 &lt;- h2o.splitFrame(ames.h2o0, ratios = 0.7, \n                          seed = 123)\ntrain_4 &lt;- split_2[[1]]\ntest_4  &lt;- split_2[[2]]"
  },
  {
    "objectID": "M1/M1LN1.html#the-validation-set-approach",
    "href": "M1/M1LN1.html#the-validation-set-approach",
    "title": "Data Partitioning and Feature Engineering",
    "section": "2.2 The Validation Set Approach",
    "text": "2.2 The Validation Set Approach\nDraw a sample of size nrow(ames) from the numbers 1 to 3 (with replacement). You want approximately 70% of the sample to be 1 and the remaining 30% to be equally split between 2 and 3.\n\nset.seed(123)\npart &lt;-sample(1:3, size=nrow(ames), prob=c(0.7, 0.15, 0.15), replace=TRUE)\n\nWe can also create training, validation, and testing sets from the original data frame directly.\n\ntrain_5 &lt;-ames[part == 1, ] #subset ames to training indices only\nvalid_5 &lt;-ames[part == 2, ]\ntest_5 &lt;-ames[part == 3, ]"
  },
  {
    "objectID": "M1/M1LN1.html#stratified-random-sampling",
    "href": "M1/M1LN1.html#stratified-random-sampling",
    "title": "Data Partitioning and Feature Engineering",
    "section": "2.3 Stratified Random Sampling",
    "text": "2.3 Stratified Random Sampling\nThe easiest way to perform stratified sampling on a response variable is to use the rsample package, where you specify the response variable to strata. The following illustrates that in our original employee attrition data we have an imbalanced response (No: 84%, Yes: 16%). By enforcing stratified sampling, both our training and testing sets have approximately equal response distributions.\nLet’s import Job Attrition data from the rsample package.\n\n# Job attrition data\nlibrary(rsample)\nlibrary(modeldata)\nchurn &lt;- attrition %&gt;% \n  mutate_if(is.ordered, .funs = factor, ordered = FALSE)\nchurn.h2o &lt;- as.h2o(churn)\n\n\n2.3.1 Original response distribution\n\nt(table(churn$Attrition)) %&gt;% prop.table() %&gt;% round(4) %&gt;% kbl(format = \"html\",table.attr = \"style='width:30%;'\") %&gt;% kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"),full_width = F, position = \"center\") \n\n\n\n\n\nNo\nYes\n\n\n\n\n0.8388\n0.1612\n\n\n\n\n\n\n\n\n2.3.2 Stratified sampling with the rsample package\n\nset.seed(123)\nsplit_strat  &lt;- initial_split(churn, prop = 0.7, \n                              strata = \"Attrition\")\ntrain_strat  &lt;- training(split_strat)\ntest_strat   &lt;- testing(split_strat)\n\nsplit &lt;- initial_split(ames, prop = 0.7, \n                       strata = \"SalePrice\")\names_train  &lt;- training(split)\names_test   &lt;- testing(split)\n\n\n\n2.3.3 Consistent response ratio between train & test\n\nlibrary(dplyr)\nlibrary(kableExtra)\n\ntrain_strat$Attrition %&gt;%\n  table() %&gt;%\n  t() %&gt;%\n  prop.table() %&gt;%\n  round(4) %&gt;%\n  knitr::kable(format = \"html\", table.attr = \"style='width:30%;'\") %&gt;%\n  kableExtra::kable_styling(\n    bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"),\n    full_width = F, \n    position = \"center\"\n  )\n\n\n\n\n\nNo\nYes\n\n\n\n\n0.8395\n0.1605\n\n\n\n\n\n\nNow Test Dataframe\n\nt(table(test_strat$Attrition)) %&gt;% prop.table() %&gt;% round(4) %&gt;% knitr::kable(format = \"html\", table.attr = \"style='width:30%;'\") %&gt;% kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"),full_width = F, position = \"center\") \n\n\n\n\n\nNo\nYes\n\n\n\n\n0.8371\n0.1629"
  },
  {
    "objectID": "M1/M1LN1.html#loading-packages",
    "href": "M1/M1LN1.html#loading-packages",
    "title": "Data Partitioning and Feature Engineering",
    "section": "3.1 Loading packages",
    "text": "3.1 Loading packages\n\nlibrary(dplyr)    # for data manipulation\nlibrary(ggplot2)  # for awesome graphics\nlibrary(visdat)   # for additional visualizations\n\n# Feature engineering packages\nlibrary(caret)    # for various ML tasks\nlibrary(recipes)  # for feature engineering tasks"
  },
  {
    "objectID": "M1/M1LN1.html#transformation",
    "href": "M1/M1LN1.html#transformation",
    "title": "Data Partitioning and Feature Engineering",
    "section": "3.2 Transformation",
    "text": "3.2 Transformation\nLet’s create a histogram of the SalePrice variable to understand the distribution of the variable.\n\nhist(ames$SalePrice, col ='blue')\n\n\n\n\n\n\n\n\nIt seems like the variable is skewed. We can apply a transformation to normalize the data to stick to the normality assumption. Let’s also calculate the moments of the variable to understand how much data is skewed. Also, this looks ugly; can we make it look better?\n\nlibrary(ggplot2)\n# color =  color of the histogram border\nlibrary(ggplot2)\nlibrary(scales)\n\nggplot(ames, aes(x = SalePrice)) +\n  geom_histogram(aes(y = after_stat(density)), fill = \"#336699\", color = \"black\", alpha = 0.65, bins = 25) + \n  labs(x = \"Sale Price\", y = \"Density\", title=\"Histogram of Sale Price\") +\n  scale_x_continuous(labels = label_comma(accuracy = 1)) +\n  # scale_y_continuous(labels = label_comma(accuracy = 1)) +\n  theme_light() +\n  theme(\n    plot.title = element_text(hjust = 0, face = \"bold\", size = 14),  # Left-align (hjust = 0) and bold the title\n    axis.title.x = element_text(size = 10, color = \"black\", face=\"bold\"),\n    axis.title.y = element_text(size = 10, color = \"black\", face=\"bold\"),\n    axis.text.x = element_text(size = 8, color = \"black\"),\n    axis.text.y = element_text(size = 8, color = \"black\")\n  )\n\n\n\n\n\n\n\n\n\n# install.packages(\"moments\")\nlibrary(moments)\nsaleprice_skew &lt;- skewness(ames$SalePrice)\n\nSkewness is 1.7426074 (&gt;1), which indicates that data is positively or right skewed."
  },
  {
    "objectID": "M1/M1LN1.html#variable-transformation",
    "href": "M1/M1LN1.html#variable-transformation",
    "title": "Data Partitioning and Feature Engineering",
    "section": "3.3 Variable Transformation",
    "text": "3.3 Variable Transformation\n\n3.3.1 Log Transformation\nTransform the variable to a log transformation (natural log of variable)\n\nln_sales &lt;-log(ames$SalePrice)\n\nhist(ln_sales, col='blue', breaks = 40, main = \"Histogram of Log Sale Price\", xlab = \"Log Sale Price\", ylab = \"Frequency\")\n\n\n\n\n\n\n\nlog_sales = skewness(ln_sales)\n\nThe distribution appears to conform to a normal distribution. The skewness value is -0.0147859. The transformation has caused the distribution to become slightly negatively skewed. However, the variable’s distribution (output) is now closer to 0.\n\n\n3.3.2 Square Root Transformation\n\nsqt_sales &lt;- sqrt(ames$SalePrice)\nhist(sqt_sales, col='blue')\n\n\n\n\n\n\n\nsq_skewness&lt;- skewness(sqt_sales)\n\nThe distribution is not as normal as that of log transformation. The skewness value is 0.8843168, which means data is moderately positively skewed and performs worse than log transformation.\n\n\n3.3.3 Cube-Root Transformation\n\ncbt_sales &lt;- (ames$SalePrice)^(1/3)\nhist(cbt_sales, col='blue')\n\n\n\n\n\n\n\ncbt_skewnes &lt;- skewness(cbt_sales)\n\nThe data distribution is worse than log transformation but better than square root. The skewness value is 0.6069153, meaning data is positively skewed and performs better than square root (you may use log transformation).\n\n\n3.3.4 Box-Cox Transformation\n\n# | message: false\n# load package\nlibrary(sjPlot)\n\n\nAttaching package: 'sjPlot'\n\n\nThe following object is masked from 'package:ggplot2':\n\n    set_theme\n\nlibrary(sjmisc)\nlibrary(sjlabelled)\n\n\nAttaching package: 'sjlabelled'\n\n\nThe following object is masked from 'package:ggplot2':\n\n    as_label\n\n\nThe following object is masked from 'package:dplyr':\n\n    as_label\n\nm.ols &lt;- lm(SalePrice ~ Gr.Liv.Area, data=ames)\nols_summ &lt;- summary(m.ols)\n\ntab_model(m.ols)\n\n\n\n\n \nSale Price\n\n\nPredictors\nEstimates\nCI\np\n\n\n(Intercept)\n13289.63\n6878.48 – 19700.78\n&lt;0.001\n\n\nGr Liv Area\n111.69\n107.64 – 115.75\n&lt;0.001\n\n\nObservations\n2930\n\n\nR2 / R2 adjusted\n0.500 / 0.499\n\n\n\n\n\n\nlibrary(MASS)\n\n\nAttaching package: 'MASS'\n\n\nThe following object is masked from 'package:gtsummary':\n\n    select\n\n\nThe following object is masked from 'package:dplyr':\n\n    select\n\nbc &lt;- boxcox(m.ols)\n\n\n\n\n\n\n\nstr(bc)\n\nList of 2\n $ x: num [1:100] -2 -1.96 -1.92 -1.88 -1.84 ...\n $ y: num [1:100] -14038 -13806 -13577 -13351 -13127 ...\n\n(bc.power &lt;- bc$x[which.max(bc$y)])\n\n[1] 0.1818182\n\n\n\ny_{transform}= (y^{\\lambda}-1)/\\lambda\n We need to transform the response variable accordingly and re-compute the linear model with this transformed variable. We can write a function corresponding to the formula:\n\nBCTransform &lt;- function(y, lambda=0) {\n  if (lambda == 0L) { log(y) }\n  else { (y^lambda - 1) / lambda }\n}\n\n#Reverse Transformation\nBCTransformInverse &lt;- function(yt, lambda=0) {\n  if (lambda == 0L) { exp(yt) }\n  else { exp(log(1 + lambda * yt)/lambda) }\n}\n\names$SalePrice.bc &lt;- BCTransform(ames$SalePrice, bc.power)\nhist(ames$SalePrice.bc, breaks=30); rug(ames$SalePrice.bc)\n\n\n\n\n\n\n\nSPbc_skewness &lt;- skewness(ames$SalePrice.bc)\n\nsummary(m.ols.bc &lt;- lm(SalePrice.bc ~ Gr.Liv.Area, data=ames))\n\n\nCall:\nlm(formula = SalePrice.bc ~ Gr.Liv.Area, data = ames)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-21.5363  -1.3894   0.1928   1.4254   8.5499 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 3.594e+01  1.497e-01  240.14   &lt;2e-16 ***\nGr.Liv.Area 5.085e-03  9.456e-05   53.78   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.587 on 2928 degrees of freedom\nMultiple R-squared:  0.4969,    Adjusted R-squared:  0.4967 \nF-statistic:  2892 on 1 and 2928 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "M1/M1LN1.html#feature-scaling",
    "href": "M1/M1LN1.html#feature-scaling",
    "title": "Data Partitioning and Feature Engineering",
    "section": "3.4 Feature Scaling",
    "text": "3.4 Feature Scaling\nLet’s look at one of the continuous variables, Living Area. We want to scale the feature. In general, feature scaling refers to the process of standardizing the range of data features. Since the content of raw data values varies widely, in some machine learning algorithms, objective functions will not work properly without normalization.\nWe can perform Min-Max scaling or Z-score scaling. Min-Max Scaling transforms the data to a range between 0 and 1. Z-score scaling transforms the data into a mean of 0 and a standard deviation of 1.\nThe formula for Min-Max scaling is:\n\n\\begin{align}\nx_{scaled} = \\frac{x - x_{min}}{x_{max} - x_{min}}\n\\end{align}\n\nThe formula for Z-score scaling is:\n\n\\begin{align}\nz = \\frac{x - \\mu}{\\sigma}\n\\end{align}\n\nwhere x is the original feature vector, \\mu is the mean of that feature vector, and \\sigma is its standard deviation.\n\nG &lt;-ames$Gr.Liv.Area\nA &lt;-ames$Lot.Area\nmax_A &lt;- max(A)\nmin_A &lt;- min(A)\nmax_G &lt;- max(G)\nmin_G &lt;- min(G)\n\nThe range of Gr.Liv.Area is 334 to 5642. The range of Lot.Area is 1300 to 215245.\n\n3.4.1 Min-Max Scaling\n\nGr.Liv.Area_N = (G-min_G)/(max_G-min_G)\nLot.Area_N = (A-min_A)/(max_A-min_A)\n\nminmaxscaler &lt;-cbind.data.frame(ames, Gr.Liv.Area_N, Lot.Area_N)\nhead(minmaxscaler)\n\n  Order Lot.Frontage Lot.Area Lot.Shape Utilities Lot.Config Land.Slope\n1   117           80     9600       Reg    AllPub     Inside        Gtl\n2   325           94     9400       Reg    AllPub     Corner        Gtl\n3   337           70     7700       Reg    AllPub     Inside        Gtl\n4   393           60     9000       Reg    AllPub        FR2        Gtl\n5   590           NA    13774       IR1    AllPub     Inside        Gtl\n6   667           81     9671       Reg    AllPub     Corner        Gtl\n  Neighborhood Bldg.Type House.Style Overall.Qual Overall.Cond Year.Built\n1       NWAmes      1Fam      2Story            6            6       1971\n2      Mitchel    Duplex      2Story            6            5       1971\n3      Mitchel    Duplex      2Story            5            2       1985\n4        NAmes    Duplex      2Story            5            5       1974\n5       NWAmes      1Fam      2Story            7            7       1977\n6        NAmes    Duplex      2Story            6            5       1969\n  Year.Remod.Add Foundation Bsmt.Unf.SF Total.Bsmt.SF BaseLivArea Central.Air\n1           1971     CBlock         386           715         329           Y\n2           1971     CBlock         912           912           0           Y\n3           1986      PConc        1216          1216           0           Y\n4           1974     CBlock         896           896           0           Y\n5           1992      PConc         476           908         432           Y\n6           1969     CBlock        1248          1248           0           Y\n  X1st.Flr.SF X2nd.Flr.SF Gr.Liv.Area Full.Bath Half.Bath Bathrooms\n1         930         715        1645         1         2         2\n2         912         912        1824         2         2         3\n3        1216        1216        2432         4         2         5\n4         896         896        1792         2         2         3\n5        1316         972        2288         1         2         2\n6        1248        1296        2544         2         2         3\n  Bedroom.AbvGr Kitchen.AbvGr Kitchen.Qual TotRms.AbvGrd Fireplaces Garage.Type\n1             4             1           TA             7          0      Attchd\n2             4             2           TA             8          0        &lt;NA&gt;\n3             4             2           TA            10          0      Attchd\n4             4             2           TA             8          0        &lt;NA&gt;\n5             4             1           Gd             8          2      Attchd\n6             6             2           TA            12          0      Attchd\n  Garage.Area Wood.Deck.SF Open.Porch.SF Enclosed.Porch X3Ssn.Porch\n1         441            0            78              0           0\n2           0          128             0              0           0\n3         616          200             0              0           0\n4           0           32            45              0           0\n5         520          321            72              0           0\n6         907            0             0              0           0\n  Screen.Porch Mo.Sold Yr.Sold Sale.Condition SalePrice SalePrice.bc\n1            0       6    2010         Normal    171000     43.68317\n2            0       4    2010         Normal    139000     41.86486\n3            0       2    2010         Normal    159000     43.03681\n4            0       9    2009         Normal    136000     41.67733\n5          156      11    2009         Normal    230000     46.40657\n6            0       8    2009         Normal    190000     44.63443\n  Gr.Liv.Area_N Lot.Area_N\n1     0.2469857 0.03879502\n2     0.2807084 0.03786020\n3     0.3952524 0.02991423\n4     0.2746797 0.03599056\n5     0.3681236 0.05830470\n6     0.4163527 0.03912688\n\n\n\n\n3.4.2 Standardize (z scores)\n\nz_Gr.Liv.Area &lt;- (ames$Gr.Liv.Area -mean(ames$Gr.Liv.Area))/sd(ames$Gr.Liv.Area)\nz_Lot.Area &lt;-(ames$Lot.Area -mean(ames$Lot.Area))/sd(ames$Lot.Area)\n\nzscore &lt;-cbind.data.frame(ames, z_Gr.Liv.Area, z_Lot.Area)\nhead(zscore)\n\n  Order Lot.Frontage Lot.Area Lot.Shape Utilities Lot.Config Land.Slope\n1   117           80     9600       Reg    AllPub     Inside        Gtl\n2   325           94     9400       Reg    AllPub     Corner        Gtl\n3   337           70     7700       Reg    AllPub     Inside        Gtl\n4   393           60     9000       Reg    AllPub        FR2        Gtl\n5   590           NA    13774       IR1    AllPub     Inside        Gtl\n6   667           81     9671       Reg    AllPub     Corner        Gtl\n  Neighborhood Bldg.Type House.Style Overall.Qual Overall.Cond Year.Built\n1       NWAmes      1Fam      2Story            6            6       1971\n2      Mitchel    Duplex      2Story            6            5       1971\n3      Mitchel    Duplex      2Story            5            2       1985\n4        NAmes    Duplex      2Story            5            5       1974\n5       NWAmes      1Fam      2Story            7            7       1977\n6        NAmes    Duplex      2Story            6            5       1969\n  Year.Remod.Add Foundation Bsmt.Unf.SF Total.Bsmt.SF BaseLivArea Central.Air\n1           1971     CBlock         386           715         329           Y\n2           1971     CBlock         912           912           0           Y\n3           1986      PConc        1216          1216           0           Y\n4           1974     CBlock         896           896           0           Y\n5           1992      PConc         476           908         432           Y\n6           1969     CBlock        1248          1248           0           Y\n  X1st.Flr.SF X2nd.Flr.SF Gr.Liv.Area Full.Bath Half.Bath Bathrooms\n1         930         715        1645         1         2         2\n2         912         912        1824         2         2         3\n3        1216        1216        2432         4         2         5\n4         896         896        1792         2         2         3\n5        1316         972        2288         1         2         2\n6        1248        1296        2544         2         2         3\n  Bedroom.AbvGr Kitchen.AbvGr Kitchen.Qual TotRms.AbvGrd Fireplaces Garage.Type\n1             4             1           TA             7          0      Attchd\n2             4             2           TA             8          0        &lt;NA&gt;\n3             4             2           TA            10          0      Attchd\n4             4             2           TA             8          0        &lt;NA&gt;\n5             4             1           Gd             8          2      Attchd\n6             6             2           TA            12          0      Attchd\n  Garage.Area Wood.Deck.SF Open.Porch.SF Enclosed.Porch X3Ssn.Porch\n1         441            0            78              0           0\n2           0          128             0              0           0\n3         616          200             0              0           0\n4           0           32            45              0           0\n5         520          321            72              0           0\n6         907            0             0              0           0\n  Screen.Porch Mo.Sold Yr.Sold Sale.Condition SalePrice SalePrice.bc\n1            0       6    2010         Normal    171000     43.68317\n2            0       4    2010         Normal    139000     41.86486\n3            0       2    2010         Normal    159000     43.03681\n4            0       9    2009         Normal    136000     41.67733\n5          156      11    2009         Normal    230000     46.40657\n6            0       8    2009         Normal    190000     44.63443\n  z_Gr.Liv.Area  z_Lot.Area\n1     0.2874520 -0.06953307\n2     0.6415507 -0.09491373\n3     1.8442990 -0.31064928\n4     0.5782481 -0.14567503\n5     1.5594376  0.46016117\n6     2.0658580 -0.06052294"
  },
  {
    "objectID": "M1/M1LN1.html#feature-construction",
    "href": "M1/M1LN1.html#feature-construction",
    "title": "Data Partitioning and Feature Engineering",
    "section": "3.5 Feature Construction",
    "text": "3.5 Feature Construction\n\n3.5.1 Unsupervised Binning\nAutomatic Binning can be used to determine the number of bins to be created. The bins are created based on the distribution of the data. The bins are created so that the data points in each bin are more similar and the data points in different bins are less similar.\n\nsummary(ames$Overall.Qual)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  1.000   5.000   6.000   6.095   7.000  10.000 \n\ncount(ames, Overall.Qual)\n\n   Overall.Qual   n\n1             1   4\n2             2  13\n3             3  40\n4             4 226\n5             5 825\n6             6 732\n7             7 602\n8             8 350\n9             9 107\n10           10  31\n\nOverall.Qual_Bin &lt;- cut(ames$Overall.Qual, breaks=4)\nhead(Overall.Qual_Bin)\n\n[1] (5.5,7.75] (5.5,7.75] (3.25,5.5] (3.25,5.5] (5.5,7.75] (5.5,7.75]\nLevels: (0.991,3.25] (3.25,5.5] (5.5,7.75] (7.75,10]\n\n\n\n\n3.5.2 Manual binning\nWe need to know the min and max values. For example, say min=1 and max=10 then the bins will be 0-5, 5-6, 6-7, 7-10.\n\nOverall.Qual_MBin &lt;- cut(ames$Overall.Qual, breaks = c(0, 5, 6, 7, 10))\nbarchart(Overall.Qual_MBin, main = \"Overall Quality Manual Binning\")\n\n\n\n\n\n\n\n\nSometimes, features will contain levels that have very few observations. For example, there are 28 unique neighborhoods represented in the Ames housing data, but several of them have fewer observations than the others.\n\ncount(train_1, Neighborhood) %&gt;% arrange(n) %&gt;% head() %&gt;% kbl() %&gt;% kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"),full_width = F, position = \"center\") \n\n\n\n\n\nNeighborhood\nn\n\n\n\n\nLandmrk\n1\n\n\nGrnHill\n2\n\n\nBlueste\n8\n\n\nGreens\n8\n\n\nNPkVill\n15\n\n\nVeenker\n21\n\n\n\n\n\n\nIn the above examples, we may want to collapse all levels observed in less than 10% of the training sample into an “other” category. We can use step_other() to do so. For example, Screen.Porch has 92% values recorded as zero (zero square footage meaning no screen porch), and the remaining 8% have unique dispersed values.\n\nlibrary(flextable)\n\n\nAttaching package: 'flextable'\n\n\nThe following object is masked from 'package:gtsummary':\n\n    continuous_summary\n\n\nThe following objects are masked from 'package:kableExtra':\n\n    as_image, footnote\n\narrange(count(train_1, Screen.Porch),n) %&gt;% flextable()\n\nScreen.Porchn4015316016316418018819019419519911041109111111131117111911211122112311261128113011351141114311451150115211541162116311641165116611781184118511901197119812011217122012211222123112341252126012631264127012711276128012871291131213421348137413851396144014901576192210821162138214021702175217621822196220422272240225522592266232221003112311531423147315331563195321032253256315541894288416051805224520062167120814481688192902,137\n\n\n\n\n3.5.3 Standardize and Normalize\n\n# Normalize all numeric columns\nrecipe(SalePrice ~ ., data = train_1) %&gt;%\n    step_YeoJohnson(all_numeric())    \n\n\n\n\n── Recipe ──────────────────────────────────────────────────────────────────────\n\n\n\n\n\n── Inputs \n\n\nNumber of variables by role\n\n\noutcome:    1\npredictor: 40\n\n\n\n\n\n── Operations \n\n\n• Yeo-Johnson transformation on: all_numeric()\n\n##standardize\n\n# train_1 %&gt;%\n#     step_center(all_numeric(), -all_outcomes()) %&gt;%\n#     step_scale(all_numeric(), -all_outcomes())\n\n\n\n3.5.4 Lump levels for two features\n\n# lumping &lt;- recipe(SalePrice ~ ., data = train_1) %&gt;%\n#   step_other(Neighborhood, threshold = 0.01, \n#              other = \"other\") %&gt;%\n#   step_other(Screen.Porch, threshold = 0.1, \n#              other = \"&gt;0\")\n\nlumping &lt;- recipe(SalePrice ~ ., data = train_1) %&gt;%\n  step_mutate(Screen.Porch = factor(ifelse(Screen.Porch &gt; 0, \"&gt;0\", \"0\"))) %&gt;%\n  step_other(Neighborhood, threshold = 0.01, other = \"other\") %&gt;%\n  step_other(Screen.Porch, threshold = 0.1, other = \"&gt;0\")\n\n\n3.5.4.1 Modified Code\n\nrecipe(Sale_Price ~ ., data = train_1):\n\nInitialization remains similar but uses Sale_Price as the outcome instead of SalePrice.\n\nstep_mutate(Screen.Porch = factor(ifelse(Screen.Porch &gt; 0, \"&gt;0\", \"0\"))):\nThis new step converts the numeric Screen.Porch variable into a binary categorical variable. If the value in Screen.Porch is greater than 0, it’s labeled as “&gt;0”, otherwise “0”.\nstep_other(Neighborhood, threshold = 0.01, other = \"other\"):\nThis step remains unchanged from the original code.\nstep_other(Screen.Porch, threshold = 0.1, other = \"&gt;0\"):\nSimilar to the original code, but applied on the newly created binary categorical Screen.Porch.\n\n\n\n\n3.5.5 Apply this blueprint\n\napply_2_training &lt;- prep(lumping, training = train_1) %&gt;%\n  bake(train_1)\n\n\n\n3.5.6 New distribution of Neighborhood\n\ncount(apply_2_training, Neighborhood) %&gt;% arrange(n) %&gt;% flextable()\n\nNeighborhoodnBrDale27MeadowV34ClearCr36StoneBr39SWISU41NoRidge54Timber58IDOTRR74other77Crawfor88BrkSide89Mitchel99NWAmes103SawyerW103Sawyer126NridgHt130Gilbert133Edwards141Somerst142OldTown183CollgCr213NAmes354\n\n\n\n\n3.5.7 New distribution of Screen.Porch\n\ncount(apply_2_training, Screen.Porch) %&gt;% arrange(n) %&gt;% flextable()\n\nScreen.Porchn&gt;020702,137\n\n\n\n\n3.5.8 Variable Encoding\nThe categorical variables are very often found in data while conducting data analysis and ML(machine learning). The Data which can be classified into categories or groups, such as colors or job titles is generally called as categorical data. The categorical variables must be encoded into numerical values in order to be used in statistical analysis or ML models.\nWarning: Dummies package is no longer available in R repository.\n\n3.5.8.1 Using fastDummies package\nWe can create dummy variables for all cat variables in the dataset\n\nlibrary(fastDummies)\names_train_dummies &lt;- dummy_cols(train_1, select_columns = NULL, remove_first_dummy = TRUE)\names_test_dummies &lt;- dummy_cols(test_1, select_columns = NULL, remove_first_dummy = TRUE)\n\n\n\n3.5.8.2 One-hot encoding (caret)\n\n# Create dummy variables transformation\ndummies &lt;- dummyVars(SalePrice ~ ., data = ames)\n\n# Apply transformation to dataset\names_dummies &lt;- data.frame(predict(dummies, newdata = ames))\n\n\n\n3.5.8.3 Label encoding (caret)\n\n# Identify columns with class 'factor'\nfactor_columns &lt;- sapply(ames, is.factor)\n\n# Apply label encoding on those columns\names[factor_columns] &lt;- lapply(ames[factor_columns], function(x) as.numeric(as.factor(x)))\n\nHere, we only had one class variable for multiple class variables, convert all into factors first. Apply the above R code to simultaneously get various categories."
  },
  {
    "objectID": "M1/M1LN1.html#missing-values",
    "href": "M1/M1LN1.html#missing-values",
    "title": "Data Partitioning and Feature Engineering",
    "section": "3.6 Missing Values",
    "text": "3.6 Missing Values\n\n3.6.1 #Missing data visualization\nLet’s look at all missingness in Ames dataset\n\nlibrary(visdat)\n\nvis_miss(AmesHousing::ames_raw, cluster = TRUE)\n\n\n\n\n\n\n\n\nMissing value imputation Features where null / missing values are less than 40% for categorical variables are replaced with mode which is value whose frequency is maximum.\n\nMode = function(x){\n  ta = table(x)\n  tam = max(ta)\n  mod = names(ta)[ta==tam]\n  return(mod)\n}\n\nIdentify numeric variables and treat them with mean value if any missing / null values exists\n\nfor (col_name in colnames(ames[sapply(ames, is.factor) == TRUE])) {\n  \n  if (sum(is.na(ames[[col_name]])) &gt; 0) {\n    ames[col_name][is.na(ames[col_name])] &lt;- Mode(ames[[col_name]])\n    stmt &lt;- paste('Null values of', col_name, ' feature has been replaced by mode value ', \n                  Mode(ames[[col_name]]))\n    print(stmt, na.print = NULL)\n  }\n}\n\n\n\\begin{align}\nlog(SalePrice) = \\beta_{o}+\\beta_{1}X_{1}\\\\\nSalePrice = e^{\\beta_{o}+\\beta_{1}X_{1}}\\\\\nSalePrice = B e^{\\beta_{1}X_{1}}\\\\\n\\end{align}"
  },
  {
    "objectID": "M2/M2LN1.html",
    "href": "M2/M2LN1.html",
    "title": "Multiple Linear Regression",
    "section": "",
    "text": "library(gdata)\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(corrplot)\nlibrary(kableExtra)\nlibrary(tidyverse)\nlibrary(stringr)\nlibrary(lubridate)\nlibrary(scales)\nlibrary(graphics)\nlibrary(caret)"
  },
  {
    "objectID": "M2/M2LN1.html#background",
    "href": "M2/M2LN1.html#background",
    "title": "Multiple Linear Regression",
    "section": "2.1 Background",
    "text": "2.1 Background\nThe Ames Housing dataset, an improvement over the well-known Boston Housing dataset, has become an essential tool for budding data scientists and researchers focusing on regression problems. Comprising 2930 observations and many explanatory variables ranging from the quality of streets to the number of fireplaces, it paints a detailed picture of the residential homes in Ames, Iowa."
  },
  {
    "objectID": "M2/M2LN1.html#objective",
    "href": "M2/M2LN1.html#objective",
    "title": "Multiple Linear Regression",
    "section": "2.2 Objective",
    "text": "2.2 Objective\nThis analysis aims to construct a predictive model that, using the various features of a home, accurately predicts its sale price. Such a model has practical applications for various stakeholders in the real estate market."
  },
  {
    "objectID": "M2/M2LN1.html#importance",
    "href": "M2/M2LN1.html#importance",
    "title": "Multiple Linear Regression",
    "section": "2.3 Importance",
    "text": "2.3 Importance\nWith a robust prediction model, potential homeowners can gauge if a listing is over or underpriced, sellers can ensure they’re placing a competitive price, and real estate professionals can provide evidence-backed advice to clients."
  },
  {
    "objectID": "M2/M2LN1.html#methodology-overview",
    "href": "M2/M2LN1.html#methodology-overview",
    "title": "Multiple Linear Regression",
    "section": "2.4 Methodology Overview",
    "text": "2.4 Methodology Overview\nOur approach is systematic:\n\nData Exploration - Getting familiar with the data’s structure.\nData Preprocessing - Preparing data for modeling.\nFeature Engineering - Optimizing representation of the predictors.\nFeature Selection - Using forward selection, backward elimination, and best subset selection.\nModel Selection & Training - Choosing an algorithm and training it.\nModel Evaluation - Validating the model’s accuracy.\nPrediction & Conclusion - Making predictions and concluding the analysis."
  },
  {
    "objectID": "M2/M2LN1.html#loading-the-data",
    "href": "M2/M2LN1.html#loading-the-data",
    "title": "Multiple Linear Regression",
    "section": "3.1 Loading the Data",
    "text": "3.1 Loading the Data\nThis section focuses on loading the necessary libraries and the dataset for our exploration.\n\n# Loading the required libraries\nlibrary(tidyverse)\nlibrary(corrplot)\n\n\n# Loading the Ames Housing dataset\names_data &lt;- read.csv(\"../data/AmesHousing2.csv\")\nggplot(data = ames_data, aes(x = Gr.Liv.Area, y = SalePrice)) +\n  geom_point(color='#336699') +\n  labs(x = \"Ground Living Area\", y = \"Sale Price\") +\n  ggtitle(\"Scatterplot of Sale Price vs. Gr.Liv.Area\")\n\n\n\n\n\n\n\n\n\n# Loading the Ames Housing dataset\nfiltered_ames_data &lt;- ames_data[ames_data$Gr.Liv.Area &lt;= 4000, ]\nggplot(data = filtered_ames_data, aes(x = Gr.Liv.Area, y = SalePrice)) +\n  geom_point(color='#336699') +\n  labs(x = \"Ground Living Area\", y = \"Sale Price\") +\n  ggtitle(\"Scatterplot of Sale Price vs. Gr.Liv.Area\")"
  },
  {
    "objectID": "M2/M2LN1.html#basic-overview",
    "href": "M2/M2LN1.html#basic-overview",
    "title": "Multiple Linear Regression",
    "section": "3.2 Basic Overview",
    "text": "3.2 Basic Overview\nBefore diving deeper into the data, it’s essential to get an overall sense of its structure, summary statistics, and a peek into the first few rows.\n\n3.2.1 View the first few rows of the dataset\n\nlibrary(knitr)\nlibrary(kableExtra)\n\n# Create a scrollable kable\nkable(ames_data[1:10, ], \"html\") %&gt;%\n  kable_styling(\"striped\", full_width = T, position = \"center\") \n\n\n\n\nOrder\nLot.Frontage\nLot.Area\nLot.Shape\nUtilities\nLot.Config\nLand.Slope\nNeighborhood\nBldg.Type\nHouse.Style\nOverall.Qual\nOverall.Cond\nYear.Built\nYear.Remod.Add\nFoundation\nBsmt.Unf.SF\nTotal.Bsmt.SF\nBaseLivArea\nCentral.Air\nX1st.Flr.SF\nX2nd.Flr.SF\nGr.Liv.Area\nFull.Bath\nHalf.Bath\nBathrooms\nBedroom.AbvGr\nKitchen.AbvGr\nKitchen.Qual\nTotRms.AbvGrd\nFireplaces\nGarage.Type\nGarage.Area\nWood.Deck.SF\nOpen.Porch.SF\nEnclosed.Porch\nX3Ssn.Porch\nScreen.Porch\nMo.Sold\nYr.Sold\nSale.Condition\nSalePrice\n\n\n\n\n117\n80\n9600\nReg\nAllPub\nInside\nGtl\nNWAmes\n1Fam\n2Story\n6\n6\n1971\n1971\nCBlock\n386\n715\n329\nY\n930\n715\n1645\n1\n2\n2\n4\n1\nTA\n7\n0\nAttchd\n441\n0\n78\n0\n0\n0\n6\n2010\nNormal\n171000\n\n\n325\n94\n9400\nReg\nAllPub\nCorner\nGtl\nMitchel\nDuplex\n2Story\n6\n5\n1971\n1971\nCBlock\n912\n912\n0\nY\n912\n912\n1824\n2\n2\n3\n4\n2\nTA\n8\n0\nNA\n0\n128\n0\n0\n0\n0\n4\n2010\nNormal\n139000\n\n\n337\n70\n7700\nReg\nAllPub\nInside\nGtl\nMitchel\nDuplex\n2Story\n5\n2\n1985\n1986\nPConc\n1216\n1216\n0\nY\n1216\n1216\n2432\n4\n2\n5\n4\n2\nTA\n10\n0\nAttchd\n616\n200\n0\n0\n0\n0\n2\n2010\nNormal\n159000\n\n\n393\n60\n9000\nReg\nAllPub\nFR2\nGtl\nNAmes\nDuplex\n2Story\n5\n5\n1974\n1974\nCBlock\n896\n896\n0\nY\n896\n896\n1792\n2\n2\n3\n4\n2\nTA\n8\n0\nNA\n0\n32\n45\n0\n0\n0\n9\n2009\nNormal\n136000\n\n\n590\nNA\n13774\nIR1\nAllPub\nInside\nGtl\nNWAmes\n1Fam\n2Story\n7\n7\n1977\n1992\nPConc\n476\n908\n432\nY\n1316\n972\n2288\n1\n2\n2\n4\n1\nGd\n8\n2\nAttchd\n520\n321\n72\n0\n0\n156\n11\n2009\nNormal\n230000\n\n\n667\n81\n9671\nReg\nAllPub\nCorner\nGtl\nNAmes\nDuplex\n2Story\n6\n5\n1969\n1969\nCBlock\n1248\n1248\n0\nY\n1248\n1296\n2544\n2\n2\n3\n6\n2\nTA\n12\n0\nAttchd\n907\n0\n0\n0\n0\n0\n8\n2009\nNormal\n190000\n\n\n670\n91\n11643\nReg\nAllPub\nInside\nGtl\nNAmes\nDuplex\n2Story\n5\n5\n1969\n1969\nCBlock\n748\n1248\n500\nY\n1338\n1296\n2634\n2\n2\n3\n6\n2\nTA\n12\n0\nDetchd\n968\n0\n0\n0\n0\n0\n8\n2009\nNormal\n200000\n\n\n809\n64\n7018\nReg\nAllPub\nInside\nGtl\nSawyerW\nDuplex\nSFoyer\n5\n5\n1979\n1979\nCBlock\n0\n1086\n1086\nY\n1224\n0\n1224\n0\n2\n1\n2\n2\nTA\n6\n2\nDetchd\n528\n120\n0\n0\n0\n0\n6\n2009\nAlloca\n153337\n\n\n814\n64\n7040\nReg\nAllPub\nInside\nGtl\nSawyerW\nDuplex\nSFoyer\n5\n5\n1979\n1979\nCBlock\n0\n1094\n1094\nY\n1229\n0\n1229\n0\n2\n1\n2\n2\nGd\n6\n2\nDetchd\n672\n120\n0\n0\n0\n0\n6\n2009\nAlloca\n148325\n\n\n816\nNA\n11855\nReg\nAllPub\nInside\nGtl\nSawyerW\nDuplex\n2Story\n7\n5\n2000\n2000\nPConc\n348\n1168\n820\nY\n1168\n1619\n2787\n4\n2\n5\n6\n2\nTA\n8\n2\nBuiltIn\n820\n312\n0\n0\n0\n0\n10\n2009\nNormal\n269500\n\n\n\n\n    # scroll_box(width = \"750px\", height = \"300px\")\n\n\n\n3.2.2 Display the structure of the dataset\n\n# str(ames_data)\nlibrary(skimr)\nlibrary(gt)\n\names_data |&gt; \n  skimr::skim() |&gt;\n  gt::gt()\n\n\n\n\n\n\n\nskim_type\nskim_variable\nn_missing\ncomplete_rate\ncharacter.min\ncharacter.max\ncharacter.empty\ncharacter.n_unique\ncharacter.whitespace\nnumeric.mean\nnumeric.sd\nnumeric.p0\nnumeric.p25\nnumeric.p50\nnumeric.p75\nnumeric.p100\nnumeric.hist\n\n\n\n\ncharacter\nLot.Shape\n0\n1.0000000\n3\n3\n0\n4\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n\n\ncharacter\nUtilities\n0\n1.0000000\n6\n6\n0\n3\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n\n\ncharacter\nLot.Config\n0\n1.0000000\n3\n7\n0\n5\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n\n\ncharacter\nLand.Slope\n0\n1.0000000\n3\n3\n0\n3\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n\n\ncharacter\nNeighborhood\n0\n1.0000000\n5\n7\n0\n28\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n\n\ncharacter\nBldg.Type\n0\n1.0000000\n4\n6\n0\n5\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n\n\ncharacter\nHouse.Style\n0\n1.0000000\n4\n6\n0\n8\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n\n\ncharacter\nFoundation\n0\n1.0000000\n4\n6\n0\n6\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n\n\ncharacter\nCentral.Air\n0\n1.0000000\n1\n1\n0\n2\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n\n\ncharacter\nKitchen.Qual\n0\n1.0000000\n2\n2\n0\n5\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n\n\ncharacter\nGarage.Type\n157\n0.9464164\n6\n7\n0\n6\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n\n\ncharacter\nSale.Condition\n0\n1.0000000\n6\n7\n0\n6\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n\n\nnumeric\nOrder\n0\n1.0000000\nNA\nNA\nNA\nNA\nNA\n1.465500e+03\n8.459625e+02\n1\n733.25\n1465.5\n2197.75\n2930\n▇▇▇▇▇\n\n\nnumeric\nLot.Frontage\n490\n0.8327645\nNA\nNA\nNA\nNA\nNA\n6.922459e+01\n2.336533e+01\n21\n58.00\n68.0\n80.00\n313\n▇▃▁▁▁\n\n\nnumeric\nLot.Area\n0\n1.0000000\nNA\nNA\nNA\nNA\nNA\n1.014792e+04\n7.880018e+03\n1300\n7440.25\n9436.5\n11555.25\n215245\n▇▁▁▁▁\n\n\nnumeric\nOverall.Qual\n0\n1.0000000\nNA\nNA\nNA\nNA\nNA\n6.094881e+00\n1.411026e+00\n1\n5.00\n6.0\n7.00\n10\n▁▂▇▅▁\n\n\nnumeric\nOverall.Cond\n0\n1.0000000\nNA\nNA\nNA\nNA\nNA\n5.563140e+00\n1.111537e+00\n1\n5.00\n5.0\n6.00\n9\n▁▁▇▅▁\n\n\nnumeric\nYear.Built\n0\n1.0000000\nNA\nNA\nNA\nNA\nNA\n1.971356e+03\n3.024536e+01\n1872\n1954.00\n1973.0\n2001.00\n2010\n▁▂▃▆▇\n\n\nnumeric\nYear.Remod.Add\n0\n1.0000000\nNA\nNA\nNA\nNA\nNA\n1.984267e+03\n2.086029e+01\n1950\n1965.00\n1993.0\n2004.00\n2010\n▅▂▂▃▇\n\n\nnumeric\nBsmt.Unf.SF\n1\n0.9996587\nNA\nNA\nNA\nNA\nNA\n5.592625e+02\n4.394942e+02\n0\n219.00\n466.0\n802.00\n2336\n▇▅▂▁▁\n\n\nnumeric\nTotal.Bsmt.SF\n1\n0.9996587\nNA\nNA\nNA\nNA\nNA\n1.051615e+03\n4.406151e+02\n0\n793.00\n990.0\n1302.00\n6110\n▇▃▁▁▁\n\n\nnumeric\nBaseLivArea\n0\n1.0000000\nNA\nNA\nNA\nNA\nNA\n4.921840e+02\n4.773283e+02\n0\n0.00\n459.5\n808.00\n5644\n▇▁▁▁▁\n\n\nnumeric\nX1st.Flr.SF\n0\n1.0000000\nNA\nNA\nNA\nNA\nNA\n1.159558e+03\n3.918909e+02\n334\n876.25\n1084.0\n1384.00\n5095\n▇▃▁▁▁\n\n\nnumeric\nX2nd.Flr.SF\n0\n1.0000000\nNA\nNA\nNA\nNA\nNA\n3.354560e+02\n4.283957e+02\n0\n0.00\n0.0\n703.75\n2065\n▇▃▂▁▁\n\n\nnumeric\nGr.Liv.Area\n0\n1.0000000\nNA\nNA\nNA\nNA\nNA\n1.499690e+03\n5.055089e+02\n334\n1126.00\n1442.0\n1742.75\n5642\n▇▇▁▁▁\n\n\nnumeric\nFull.Bath\n0\n1.0000000\nNA\nNA\nNA\nNA\nNA\n1.566553e+00\n5.529406e-01\n0\n1.00\n2.0\n2.00\n4\n▁▇▇▁▁\n\n\nnumeric\nHalf.Bath\n0\n1.0000000\nNA\nNA\nNA\nNA\nNA\n3.795222e-01\n5.026293e-01\n0\n0.00\n0.0\n1.00\n2\n▇▁▅▁▁\n\n\nnumeric\nBathrooms\n0\n1.0000000\nNA\nNA\nNA\nNA\nNA\n1.756314e+00\n6.428715e-01\n0\n1.00\n2.0\n2.50\n5\n▆▇▅▁▁\n\n\nnumeric\nBedroom.AbvGr\n0\n1.0000000\nNA\nNA\nNA\nNA\nNA\n2.854266e+00\n8.277311e-01\n0\n2.00\n3.0\n3.00\n8\n▁▇▂▁▁\n\n\nnumeric\nKitchen.AbvGr\n0\n1.0000000\nNA\nNA\nNA\nNA\nNA\n1.044369e+00\n2.140762e-01\n0\n1.00\n1.0\n1.00\n3\n▁▇▁▁▁\n\n\nnumeric\nTotRms.AbvGrd\n0\n1.0000000\nNA\nNA\nNA\nNA\nNA\n6.443003e+00\n1.572964e+00\n2\n5.00\n6.0\n7.00\n15\n▁▇▂▁▁\n\n\nnumeric\nFireplaces\n0\n1.0000000\nNA\nNA\nNA\nNA\nNA\n5.993174e-01\n6.479209e-01\n0\n0.00\n1.0\n1.00\n4\n▇▇▁▁▁\n\n\nnumeric\nGarage.Area\n1\n0.9996587\nNA\nNA\nNA\nNA\nNA\n4.728197e+02\n2.150465e+02\n0\n320.00\n480.0\n576.00\n1488\n▃▇▃▁▁\n\n\nnumeric\nWood.Deck.SF\n0\n1.0000000\nNA\nNA\nNA\nNA\nNA\n9.375188e+01\n1.263616e+02\n0\n0.00\n0.0\n168.00\n1424\n▇▁▁▁▁\n\n\nnumeric\nOpen.Porch.SF\n0\n1.0000000\nNA\nNA\nNA\nNA\nNA\n4.753345e+01\n6.748340e+01\n0\n0.00\n27.0\n70.00\n742\n▇▁▁▁▁\n\n\nnumeric\nEnclosed.Porch\n0\n1.0000000\nNA\nNA\nNA\nNA\nNA\n2.301160e+01\n6.413906e+01\n0\n0.00\n0.0\n0.00\n1012\n▇▁▁▁▁\n\n\nnumeric\nX3Ssn.Porch\n0\n1.0000000\nNA\nNA\nNA\nNA\nNA\n2.592491e+00\n2.514133e+01\n0\n0.00\n0.0\n0.00\n508\n▇▁▁▁▁\n\n\nnumeric\nScreen.Porch\n0\n1.0000000\nNA\nNA\nNA\nNA\nNA\n1.600205e+01\n5.608737e+01\n0\n0.00\n0.0\n0.00\n576\n▇▁▁▁▁\n\n\nnumeric\nMo.Sold\n0\n1.0000000\nNA\nNA\nNA\nNA\nNA\n6.216041e+00\n2.714492e+00\n1\n4.00\n6.0\n8.00\n12\n▅▆▇▃▃\n\n\nnumeric\nYr.Sold\n0\n1.0000000\nNA\nNA\nNA\nNA\nNA\n2.007790e+03\n1.316613e+00\n2006\n2007.00\n2008.0\n2009.00\n2010\n▇▇▇▇▃\n\n\nnumeric\nSalePrice\n0\n1.0000000\nNA\nNA\nNA\nNA\nNA\n1.807961e+05\n7.988669e+04\n12789\n129500.00\n160000.0\n213500.00\n755000\n▇▇▁▁▁\n\n\n\n\n\n\n\n\n\n3.2.3 Display summary statistics for the dataset\n\n# Install and load the required library if not already done\nlibrary(gt)\n\nsummary(ames_data)\n\n#&gt;      Order         Lot.Frontage       Lot.Area       Lot.Shape        \n#&gt;  Min.   :   1.0   Min.   : 21.00   Min.   :  1300   Length:2930       \n#&gt;  1st Qu.: 733.2   1st Qu.: 58.00   1st Qu.:  7440   Class :character  \n#&gt;  Median :1465.5   Median : 68.00   Median :  9436   Mode  :character  \n#&gt;  Mean   :1465.5   Mean   : 69.22   Mean   : 10148                     \n#&gt;  3rd Qu.:2197.8   3rd Qu.: 80.00   3rd Qu.: 11555                     \n#&gt;  Max.   :2930.0   Max.   :313.00   Max.   :215245                     \n#&gt;                   NA's   :490                                         \n#&gt;   Utilities          Lot.Config         Land.Slope        Neighborhood      \n#&gt;  Length:2930        Length:2930        Length:2930        Length:2930       \n#&gt;  Class :character   Class :character   Class :character   Class :character  \n#&gt;  Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n#&gt;                                                                             \n#&gt;                                                                             \n#&gt;                                                                             \n#&gt;                                                                             \n#&gt;   Bldg.Type         House.Style         Overall.Qual     Overall.Cond  \n#&gt;  Length:2930        Length:2930        Min.   : 1.000   Min.   :1.000  \n#&gt;  Class :character   Class :character   1st Qu.: 5.000   1st Qu.:5.000  \n#&gt;  Mode  :character   Mode  :character   Median : 6.000   Median :5.000  \n#&gt;                                        Mean   : 6.095   Mean   :5.563  \n#&gt;                                        3rd Qu.: 7.000   3rd Qu.:6.000  \n#&gt;                                        Max.   :10.000   Max.   :9.000  \n#&gt;                                                                        \n#&gt;    Year.Built   Year.Remod.Add  Foundation         Bsmt.Unf.SF    \n#&gt;  Min.   :1872   Min.   :1950   Length:2930        Min.   :   0.0  \n#&gt;  1st Qu.:1954   1st Qu.:1965   Class :character   1st Qu.: 219.0  \n#&gt;  Median :1973   Median :1993   Mode  :character   Median : 466.0  \n#&gt;  Mean   :1971   Mean   :1984                      Mean   : 559.3  \n#&gt;  3rd Qu.:2001   3rd Qu.:2004                      3rd Qu.: 802.0  \n#&gt;  Max.   :2010   Max.   :2010                      Max.   :2336.0  \n#&gt;                                                   NA's   :1       \n#&gt;  Total.Bsmt.SF   BaseLivArea     Central.Air         X1st.Flr.SF    \n#&gt;  Min.   :   0   Min.   :   0.0   Length:2930        Min.   : 334.0  \n#&gt;  1st Qu.: 793   1st Qu.:   0.0   Class :character   1st Qu.: 876.2  \n#&gt;  Median : 990   Median : 459.5   Mode  :character   Median :1084.0  \n#&gt;  Mean   :1052   Mean   : 492.2                      Mean   :1159.6  \n#&gt;  3rd Qu.:1302   3rd Qu.: 808.0                      3rd Qu.:1384.0  \n#&gt;  Max.   :6110   Max.   :5644.0                      Max.   :5095.0  \n#&gt;  NA's   :1                                                          \n#&gt;   X2nd.Flr.SF      Gr.Liv.Area     Full.Bath       Half.Bath     \n#&gt;  Min.   :   0.0   Min.   : 334   Min.   :0.000   Min.   :0.0000  \n#&gt;  1st Qu.:   0.0   1st Qu.:1126   1st Qu.:1.000   1st Qu.:0.0000  \n#&gt;  Median :   0.0   Median :1442   Median :2.000   Median :0.0000  \n#&gt;  Mean   : 335.5   Mean   :1500   Mean   :1.567   Mean   :0.3795  \n#&gt;  3rd Qu.: 703.8   3rd Qu.:1743   3rd Qu.:2.000   3rd Qu.:1.0000  \n#&gt;  Max.   :2065.0   Max.   :5642   Max.   :4.000   Max.   :2.0000  \n#&gt;                                                                  \n#&gt;    Bathrooms     Bedroom.AbvGr   Kitchen.AbvGr   Kitchen.Qual      \n#&gt;  Min.   :0.000   Min.   :0.000   Min.   :0.000   Length:2930       \n#&gt;  1st Qu.:1.000   1st Qu.:2.000   1st Qu.:1.000   Class :character  \n#&gt;  Median :2.000   Median :3.000   Median :1.000   Mode  :character  \n#&gt;  Mean   :1.756   Mean   :2.854   Mean   :1.044                     \n#&gt;  3rd Qu.:2.500   3rd Qu.:3.000   3rd Qu.:1.000                     \n#&gt;  Max.   :5.000   Max.   :8.000   Max.   :3.000                     \n#&gt;                                                                    \n#&gt;  TotRms.AbvGrd      Fireplaces     Garage.Type         Garage.Area    \n#&gt;  Min.   : 2.000   Min.   :0.0000   Length:2930        Min.   :   0.0  \n#&gt;  1st Qu.: 5.000   1st Qu.:0.0000   Class :character   1st Qu.: 320.0  \n#&gt;  Median : 6.000   Median :1.0000   Mode  :character   Median : 480.0  \n#&gt;  Mean   : 6.443   Mean   :0.5993                      Mean   : 472.8  \n#&gt;  3rd Qu.: 7.000   3rd Qu.:1.0000                      3rd Qu.: 576.0  \n#&gt;  Max.   :15.000   Max.   :4.0000                      Max.   :1488.0  \n#&gt;                                                       NA's   :1       \n#&gt;   Wood.Deck.SF     Open.Porch.SF    Enclosed.Porch     X3Ssn.Porch     \n#&gt;  Min.   :   0.00   Min.   :  0.00   Min.   :   0.00   Min.   :  0.000  \n#&gt;  1st Qu.:   0.00   1st Qu.:  0.00   1st Qu.:   0.00   1st Qu.:  0.000  \n#&gt;  Median :   0.00   Median : 27.00   Median :   0.00   Median :  0.000  \n#&gt;  Mean   :  93.75   Mean   : 47.53   Mean   :  23.01   Mean   :  2.592  \n#&gt;  3rd Qu.: 168.00   3rd Qu.: 70.00   3rd Qu.:   0.00   3rd Qu.:  0.000  \n#&gt;  Max.   :1424.00   Max.   :742.00   Max.   :1012.00   Max.   :508.000  \n#&gt;                                                                        \n#&gt;   Screen.Porch    Mo.Sold          Yr.Sold     Sale.Condition    \n#&gt;  Min.   :  0   Min.   : 1.000   Min.   :2006   Length:2930       \n#&gt;  1st Qu.:  0   1st Qu.: 4.000   1st Qu.:2007   Class :character  \n#&gt;  Median :  0   Median : 6.000   Median :2008   Mode  :character  \n#&gt;  Mean   : 16   Mean   : 6.216   Mean   :2008                     \n#&gt;  3rd Qu.:  0   3rd Qu.: 8.000   3rd Qu.:2009                     \n#&gt;  Max.   :576   Max.   :12.000   Max.   :2010                     \n#&gt;                                                                  \n#&gt;    SalePrice     \n#&gt;  Min.   : 12789  \n#&gt;  1st Qu.:129500  \n#&gt;  Median :160000  \n#&gt;  Mean   :180796  \n#&gt;  3rd Qu.:213500  \n#&gt;  Max.   :755000  \n#&gt;"
  },
  {
    "objectID": "M2/M2LN1.html#histogram-of-saleprice",
    "href": "M2/M2LN1.html#histogram-of-saleprice",
    "title": "Multiple Linear Regression",
    "section": "3.3 Histogram of SalePrice",
    "text": "3.3 Histogram of SalePrice\nTo understand the distribution of our target variable, SalePrice, we’ll visualize it using a histogram.\n\n# Plotting a histogram for SalePrice\nggplot(data = ames_data, aes(x = SalePrice)) +\n  geom_histogram(fill = '#336699', color = \"black\", bins = 50) +\n  labs(title = \"Histogram of SalePrice\", x = \"SalePrice\", y = \"Frequency\") +\n  theme_minimal()"
  },
  {
    "objectID": "M2/M2LN1.html#correlation-analysis",
    "href": "M2/M2LN1.html#correlation-analysis",
    "title": "Multiple Linear Regression",
    "section": "3.4 Correlation Analysis",
    "text": "3.4 Correlation Analysis\n\n3.4.1 Correlation with respect to SalePrice\nFirst, let’s identify how the continuous variables in our dataset correlate with SalePrice.\n\n# Calculating correlations of continuous variables with SalePrice\ncontinuous_vars &lt;- ames_data %&gt;% select_if(is.numeric)\ncorrelations &lt;- cor(continuous_vars)\nsaleprice_correlations &lt;- correlations['SalePrice',]\nsaleprice_correlations_df &lt;- data.frame(Variable = names(saleprice_correlations), \n                                        Correlation = saleprice_correlations) %&gt;%\n  arrange(desc(Correlation))\n\n# Plotting these correlations\nggplot(data = saleprice_correlations_df, aes(x = reorder(Variable, Correlation), y = Correlation)) +\n  geom_bar(stat = \"identity\") +\n  coord_flip() +\n  labs(title = \"Correlation of Continuous Variables with SalePrice\", x = \"\", y = \"Correlation\") +\n  theme_minimal()\n\n#&gt; Warning: Removed 4 rows containing missing values or values outside the scale range\n#&gt; (`geom_bar()`).\n\n\n\n\n\n\n\n\n\n\n\n3.4.2 Correlation among Continuous Variables\nUnderstanding how continuous variables correlate with each other can provide insights into potential multicollinearity and relationships between variables.\n\n# Remove columns with zero variance or too many NAs\nfiltered_continuous_vars &lt;- continuous_vars %&gt;% \n  select_if(function(x) var(x, na.rm = TRUE) &gt; 0 & mean(is.na(x)) &lt; 0.5)\n\n# Recalculate correlations\nfixed_correlations &lt;- cor(filtered_continuous_vars, use = \"complete.obs\")\n\n# Replace NA with 0 in correlation matrix\nfixed_correlations[is.na(fixed_correlations)] &lt;- 0\n\n# Plotting correlations among continuous variables\ncorrplot(fixed_correlations, method = \"color\", order = \"hclust\", addCoef.col = \"black\", tl.cex = 0.75, tl.srt = 45, type= 'lower',number.cex= 0.60)"
  },
  {
    "objectID": "M2/M2LN1.html#handling-missing-values",
    "href": "M2/M2LN1.html#handling-missing-values",
    "title": "Multiple Linear Regression",
    "section": "4.1 Handling Missing Values",
    "text": "4.1 Handling Missing Values\n\n# List columns with missing values\nmissing_cols &lt;- colnames(ames_data)[colSums(is.na(ames_data)) &gt; 0]\n\nFor simplicity, we’ll impute missing values with the median for numeric columns and the mode for categorical columns\n\nfor (col in missing_cols) {\n  if (is.numeric(ames_data[[col]])) {\n    ames_data[[col]][is.na(ames_data[[col]])] &lt;- median(ames_data[[col]], na.rm = TRUE)\n  } else {\n    mode_val &lt;- as.character(names(sort(table(ames_data[[col]]), decreasing = TRUE)[1]))\n    ames_data[[col]][is.na(ames_data[[col]])] &lt;- mode_val\n  }\n}"
  },
  {
    "objectID": "M2/M2LN1.html#feature-scaling---normalize-numeric-features",
    "href": "M2/M2LN1.html#feature-scaling---normalize-numeric-features",
    "title": "Multiple Linear Regression",
    "section": "4.2 Feature Scaling - Normalize numeric features",
    "text": "4.2 Feature Scaling - Normalize numeric features\n\n# Not this time\n# numeric_cols &lt;- sapply(ames_data, is.numeric)\n# ames_data[numeric_cols] &lt;- lapply(ames_data[numeric_cols], scale)"
  },
  {
    "objectID": "M2/M2LN1.html#encoding-categorical-variables",
    "href": "M2/M2LN1.html#encoding-categorical-variables",
    "title": "Multiple Linear Regression",
    "section": "4.3 Encoding Categorical Variables",
    "text": "4.3 Encoding Categorical Variables\n\n# Not Needed for Now\n# ames_data &lt;- model.matrix(~ . - 1, data = ames_data)"
  },
  {
    "objectID": "M2/M2LN1.html#feature-engineering",
    "href": "M2/M2LN1.html#feature-engineering",
    "title": "Multiple Linear Regression",
    "section": "4.4 Feature Engineering",
    "text": "4.4 Feature Engineering\nWe won’t perform feature engineering here for simplicity, but this is where you’d create or modify features based on domain knowledge or insights from EDA."
  },
  {
    "objectID": "M2/M2LN1.html#simple-linear-regression-model",
    "href": "M2/M2LN1.html#simple-linear-regression-model",
    "title": "Multiple Linear Regression",
    "section": "6.1 Simple Linear Regression Model",
    "text": "6.1 Simple Linear Regression Model\nFitting a simple linear model between SalePrice and Gr.Liv.Area can be achieved using R’s lm() function.\nHere’s how you can create and summarize such a model:\n\noptions(scipen=999)\n# Fit the linear model on the training data\nlm_model &lt;- lm(SalePrice ~ Gr.Liv.Area, data = train_data)\n\n# Summarize the model\n# stargazer::stargazer(lm_model, type = \"html\", title = \"Simple Linear Model\", ci=TRUE, single.row = FALSE, no.space = FALSE, align = TRUE, digits=5, font.size = \"small\",  report = \"vc*stp\")\nsummary(lm_model)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = SalePrice ~ Gr.Liv.Area, data = train_data)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -477601  -28912   -2320   21280  335224 \n#&gt; \n#&gt; Coefficients:\n#&gt;              Estimate Std. Error t value             Pr(&gt;|t|)    \n#&gt; (Intercept) 15969.885   3852.872   4.145            0.0000354 ***\n#&gt; Gr.Liv.Area   110.179      2.438  45.199 &lt; 0.0000000000000002 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 55870 on 2049 degrees of freedom\n#&gt; Multiple R-squared:  0.4993, Adjusted R-squared:  0.499 \n#&gt; F-statistic:  2043 on 1 and 2049 DF,  p-value: &lt; 0.00000000000000022\n\n\nThe model above tells you that for one unit increase of Gr.Liv.Area Sale Price increases by 15969.8854154 + 110.1791899= 16080.0646053 indicated by the equation SalePrice = 15969.8854154 + 110.1791899 \\times Gr.Liv.Area."
  },
  {
    "objectID": "M2/M2LN1.html#multiple-linear-regression-model",
    "href": "M2/M2LN1.html#multiple-linear-regression-model",
    "title": "Multiple Linear Regression",
    "section": "6.2 Multiple Linear Regression Model",
    "text": "6.2 Multiple Linear Regression Model\nLet’s run a multiple linear regression model using all available predictors in the train_data to predict SalePrice.\nHere’s how you can create and summarize such a model:\n\n# Fit the multiple linear regression model on the training data using all predictors\nfull_lm_model &lt;- lm(SalePrice ~ ., data = train_data)\n\n# Summarize the model\nstargazer::stargazer(full_lm_model, type = \"html\", title = \"Full Linear Model\", ci=TRUE, single.row = T, no.space = FALSE, align = TRUE, digits=5, font.size = \"small\",  report = \"vc*stp\")\n\n\nFull Linear Model\n\n\n\n\n\n\n\n\n\nDependent variable:\n\n\n\n\n\n\n\n\n\n\n\n\nSalePrice\n\n\n\n\n\n\n\n\nOrder\n\n\n4.61917 (-12.05823, 21.29657)\n\n\n\n\n\n\nt = 0.54286\n\n\n\n\n\n\np = 0.58730\n\n\n\n\n\n\n\n\n\n\nLot.Frontage\n\n\n-95.08760** (-177.84030, -12.33486)\n\n\n\n\n\n\nt = -2.25211\n\n\n\n\n\n\np = 0.02443\n\n\n\n\n\n\n\n\n\n\nLot.Area\n\n\n0.53936*** (0.34036, 0.73837)\n\n\n\n\n\n\nt = 5.31221\n\n\n\n\n\n\np = 0.0000002\n\n\n\n\n\n\n\n\n\n\nLot.ShapeIR2\n\n\n9,703.43300** (1,053.18600, 18,353.68000)\n\n\n\n\n\n\nt = 2.19859\n\n\n\n\n\n\np = 0.02803\n\n\n\n\n\n\n\n\n\n\nLot.ShapeIR3\n\n\n-27,454.21000*** (-43,011.15000, -11,897.27000)\n\n\n\n\n\n\nt = -3.45886\n\n\n\n\n\n\np = 0.00056\n\n\n\n\n\n\n\n\n\n\nLot.ShapeReg\n\n\n1,889.03000 (-1,219.37300, 4,997.43400)\n\n\n\n\n\n\nt = 1.19110\n\n\n\n\n\n\np = 0.23376\n\n\n\n\n\n\n\n\n\n\nUtilitiesNoSewr\n\n\n-4,265.43600 (-44,714.14000, 36,183.27000)\n\n\n\n\n\n\nt = -0.20668\n\n\n\n\n\n\np = 0.83628\n\n\n\n\n\n\n\n\n\n\nLot.ConfigCulDSac\n\n\n8,537.96900** (2,024.38900, 15,051.55000)\n\n\n\n\n\n\nt = 2.56911\n\n\n\n\n\n\np = 0.01027\n\n\n\n\n\n\n\n\n\n\nLot.ConfigFR2\n\n\n-4,781.72300 (-12,971.42000, 3,407.97300)\n\n\n\n\n\n\nt = -1.14437\n\n\n\n\n\n\np = 0.25262\n\n\n\n\n\n\n\n\n\n\nLot.ConfigFR3\n\n\n2,133.61500 (-15,215.00000, 19,482.23000)\n\n\n\n\n\n\nt = 0.24105\n\n\n\n\n\n\np = 0.80955\n\n\n\n\n\n\n\n\n\n\nLot.ConfigInside\n\n\n1,494.17000 (-2,029.32400, 5,017.66400)\n\n\n\n\n\n\nt = 0.83114\n\n\n\n\n\n\np = 0.40600\n\n\n\n\n\n\n\n\n\n\nLand.SlopeMod\n\n\n11,062.63000*** (4,526.68100, 17,598.58000)\n\n\n\n\n\n\nt = 3.31740\n\n\n\n\n\n\np = 0.00093\n\n\n\n\n\n\n\n\n\n\nLand.SlopeSev\n\n\n-8,812.87300 (-26,974.91000, 9,349.16300)\n\n\n\n\n\n\nt = -0.95104\n\n\n\n\n\n\np = 0.34170\n\n\n\n\n\n\n\n\n\n\nNeighborhoodBlueste\n\n\n-710.49220 (-27,308.48000, 25,887.49000)\n\n\n\n\n\n\nt = -0.05236\n\n\n\n\n\n\np = 0.95826\n\n\n\n\n\n\n\n\n\n\nNeighborhoodBrDale\n\n\n3,728.84400 (-16,239.42000, 23,697.11000)\n\n\n\n\n\n\nt = 0.36600\n\n\n\n\n\n\np = 0.71441\n\n\n\n\n\n\n\n\n\n\nNeighborhoodBrkSide\n\n\n-13,863.09000 (-31,410.40000, 3,684.21300)\n\n\n\n\n\n\nt = -1.54845\n\n\n\n\n\n\np = 0.12168\n\n\n\n\n\n\n\n\n\n\nNeighborhoodClearCr\n\n\n-14,493.15000 (-33,763.86000, 4,777.56000)\n\n\n\n\n\n\nt = -1.47405\n\n\n\n\n\n\np = 0.14063\n\n\n\n\n\n\n\n\n\n\nNeighborhoodCollgCr\n\n\n-13,063.47000 (-29,258.25000, 3,131.30000)\n\n\n\n\n\n\nt = -1.58100\n\n\n\n\n\n\np = 0.11404\n\n\n\n\n\n\n\n\n\n\nNeighborhoodCrawfor\n\n\n6,462.82800 (-11,264.91000, 24,190.57000)\n\n\n\n\n\n\nt = 0.71452\n\n\n\n\n\n\np = 0.47499\n\n\n\n\n\n\n\n\n\n\nNeighborhoodEdwards\n\n\n-27,054.07000*** (-43,879.12000, -10,229.03000)\n\n\n\n\n\n\nt = -3.15155\n\n\n\n\n\n\np = 0.00165\n\n\n\n\n\n\n\n\n\n\nNeighborhoodGilbert\n\n\n-18,456.61000** (-34,129.62000, -2,783.61200)\n\n\n\n\n\n\nt = -2.30806\n\n\n\n\n\n\np = 0.02110\n\n\n\n\n\n\n\n\n\n\nNeighborhoodGreens\n\n\n16,971.38000 (-9,295.00100, 43,237.76000)\n\n\n\n\n\n\nt = 1.26638\n\n\n\n\n\n\np = 0.20553\n\n\n\n\n\n\n\n\n\n\nNeighborhoodGrnHill\n\n\n133,832.70000*** (75,826.81000, 191,838.50000)\n\n\n\n\n\n\nt = 4.52208\n\n\n\n\n\n\np = 0.00001\n\n\n\n\n\n\n\n\n\n\nNeighborhoodIDOTRR\n\n\n-20,440.44000** (-39,059.21000, -1,821.67300)\n\n\n\n\n\n\nt = -2.15173\n\n\n\n\n\n\np = 0.03155\n\n\n\n\n\n\n\n\n\n\nNeighborhoodLandmrk\n\n\n6,702.62500 (-51,973.81000, 65,379.06000)\n\n\n\n\n\n\nt = 0.22389\n\n\n\n\n\n\np = 0.82287\n\n\n\n\n\n\n\n\n\n\nNeighborhoodMeadowV\n\n\n-3,716.85500 (-23,404.00000, 15,970.29000)\n\n\n\n\n\n\nt = -0.37003\n\n\n\n\n\n\np = 0.71140\n\n\n\n\n\n\n\n\n\n\nNeighborhoodMitchel\n\n\n-18,937.37000** (-36,763.47000, -1,111.27000)\n\n\n\n\n\n\nt = -2.08215\n\n\n\n\n\n\np = 0.03746\n\n\n\n\n\n\n\n\n\n\nNeighborhoodNAmes\n\n\n-16,121.85000** (-31,760.05000, -483.64530)\n\n\n\n\n\n\nt = -2.02058\n\n\n\n\n\n\np = 0.04346\n\n\n\n\n\n\n\n\n\n\nNeighborhoodNoRidge\n\n\n40,872.70000*** (23,658.26000, 58,087.14000)\n\n\n\n\n\n\nt = 4.65359\n\n\n\n\n\n\np = 0.000004\n\n\n\n\n\n\n\n\n\n\nNeighborhoodNPkVill\n\n\n2,299.06900 (-19,268.72000, 23,866.86000)\n\n\n\n\n\n\nt = 0.20893\n\n\n\n\n\n\np = 0.83453\n\n\n\n\n\n\n\n\n\n\nNeighborhoodNridgHt\n\n\n36,664.38000*** (21,663.44000, 51,665.32000)\n\n\n\n\n\n\nt = 4.79042\n\n\n\n\n\n\np = 0.000002\n\n\n\n\n\n\n\n\n\n\nNeighborhoodNWAmes\n\n\n-18,966.09000** (-34,931.51000, -3,000.68100)\n\n\n\n\n\n\nt = -2.32834\n\n\n\n\n\n\np = 0.02000\n\n\n\n\n\n\n\n\n\n\nNeighborhoodOldTown\n\n\n-20,682.09000** (-37,682.38000, -3,681.79900)\n\n\n\n\n\n\nt = -2.38444\n\n\n\n\n\n\np = 0.01721\n\n\n\n\n\n\n\n\n\n\nNeighborhoodSawyer\n\n\n-17,915.49000** (-34,431.13000, -1,399.86000)\n\n\n\n\n\n\nt = -2.12609\n\n\n\n\n\n\np = 0.03363\n\n\n\n\n\n\n\n\n\n\nNeighborhoodSawyerW\n\n\n-17,652.24000** (-33,555.59000, -1,748.87900)\n\n\n\n\n\n\nt = -2.17550\n\n\n\n\n\n\np = 0.02972\n\n\n\n\n\n\n\n\n\n\nNeighborhoodSomerst\n\n\n8,538.23000 (-6,296.94600, 23,373.41000)\n\n\n\n\n\n\nt = 1.12804\n\n\n\n\n\n\np = 0.25945\n\n\n\n\n\n\n\n\n\n\nNeighborhoodStoneBr\n\n\n48,478.99000*** (31,964.51000, 64,993.48000)\n\n\n\n\n\n\nt = 5.75356\n\n\n\n\n\n\np = 0.00000\n\n\n\n\n\n\n\n\n\n\nNeighborhoodSWISU\n\n\n-19,674.16000** (-39,302.01000, -46.30389)\n\n\n\n\n\n\nt = -1.96459\n\n\n\n\n\n\np = 0.04961\n\n\n\n\n\n\n\n\n\n\nNeighborhoodTimber\n\n\n-2,105.89400 (-20,421.87000, 16,210.09000)\n\n\n\n\n\n\nt = -0.22535\n\n\n\n\n\n\np = 0.82174\n\n\n\n\n\n\n\n\n\n\nNeighborhoodVeenker\n\n\n2,179.58100 (-17,309.48000, 21,668.64000)\n\n\n\n\n\n\nt = 0.21919\n\n\n\n\n\n\np = 0.82653\n\n\n\n\n\n\n\n\n\n\nBldg.Type2fmCon\n\n\n-6,896.65700 (-17,014.84000, 3,221.52400)\n\n\n\n\n\n\nt = -1.33593\n\n\n\n\n\n\np = 0.18173\n\n\n\n\n\n\n\n\n\n\nBldg.TypeDuplex\n\n\n-11.75693 (-12,266.83000, 12,243.32000)\n\n\n\n\n\n\nt = -0.00188\n\n\n\n\n\n\np = 0.99850\n\n\n\n\n\n\n\n\n\n\nBldg.TypeTwnhs\n\n\n-41,073.04000*** (-51,866.13000, -30,279.95000)\n\n\n\n\n\n\nt = -7.45863\n\n\n\n\n\n\np = 0.00000\n\n\n\n\n\n\n\n\n\n\nBldg.TypeTwnhsE\n\n\n-29,786.06000*** (-36,684.70000, -22,887.42000)\n\n\n\n\n\n\nt = -8.46248\n\n\n\n\n\n\np = 0.00000\n\n\n\n\n\n\n\n\n\n\nHouse.Style1.5Unf\n\n\n6,206.55100 (-10,207.87000, 22,620.97000)\n\n\n\n\n\n\nt = 0.74109\n\n\n\n\n\n\np = 0.45873\n\n\n\n\n\n\n\n\n\n\nHouse.Style1Story\n\n\n8,663.58800** (1,493.23100, 15,833.94000)\n\n\n\n\n\n\nt = 2.36813\n\n\n\n\n\n\np = 0.01798\n\n\n\n\n\n\n\n\n\n\nHouse.Style2.5Fin\n\n\n-16,788.65000 (-44,887.53000, 11,310.23000)\n\n\n\n\n\n\nt = -1.17105\n\n\n\n\n\n\np = 0.24173\n\n\n\n\n\n\n\n\n\n\nHouse.Style2.5Unf\n\n\n-571.31310 (-16,207.44000, 15,064.81000)\n\n\n\n\n\n\nt = -0.07161\n\n\n\n\n\n\np = 0.94292\n\n\n\n\n\n\n\n\n\n\nHouse.Style2Story\n\n\n-7,381.70000** (-13,470.43000, -1,292.97100)\n\n\n\n\n\n\nt = -2.37617\n\n\n\n\n\n\np = 0.01759\n\n\n\n\n\n\n\n\n\n\nHouse.StyleSFoyer\n\n\n8,663.96200 (-1,846.15800, 19,174.08000)\n\n\n\n\n\n\nt = 1.61569\n\n\n\n\n\n\np = 0.10633\n\n\n\n\n\n\n\n\n\n\nHouse.StyleSLvl\n\n\n1,382.75600 (-7,339.72100, 10,105.23000)\n\n\n\n\n\n\nt = 0.31071\n\n\n\n\n\n\np = 0.75606\n\n\n\n\n\n\n\n\n\n\nOverall.Qual\n\n\n11,535.13000*** (9,748.80900, 13,321.45000)\n\n\n\n\n\n\nt = 12.65643\n\n\n\n\n\n\np = 0.00000\n\n\n\n\n\n\n\n\n\n\nOverall.Cond\n\n\n5,122.06300*** (3,640.09500, 6,604.03200)\n\n\n\n\n\n\nt = 6.77414\n\n\n\n\n\n\np = 0.00000\n\n\n\n\n\n\n\n\n\n\nYear.Built\n\n\n364.55260*** (236.31640, 492.78870)\n\n\n\n\n\n\nt = 5.57183\n\n\n\n\n\n\np = 0.0000001\n\n\n\n\n\n\n\n\n\n\nYear.Remod.Add\n\n\n83.40910 (-17.11190, 183.93010)\n\n\n\n\n\n\nt = 1.62632\n\n\n\n\n\n\np = 0.10405\n\n\n\n\n\n\n\n\n\n\nFoundationCBlock\n\n\n-1,416.79500 (-7,247.69000, 4,414.10000)\n\n\n\n\n\n\nt = -0.47623\n\n\n\n\n\n\np = 0.63397\n\n\n\n\n\n\n\n\n\n\nFoundationPConc\n\n\n4,860.30800 (-1,620.57400, 11,341.19000)\n\n\n\n\n\n\nt = 1.46987\n\n\n\n\n\n\np = 0.14176\n\n\n\n\n\n\n\n\n\n\nFoundationSlab\n\n\n-2,454.59600 (-16,302.93000, 11,393.74000)\n\n\n\n\n\n\nt = -0.34740\n\n\n\n\n\n\np = 0.72833\n\n\n\n\n\n\n\n\n\n\nFoundationStone\n\n\n9,785.99200 (-9,763.33900, 29,335.32000)\n\n\n\n\n\n\nt = 0.98112\n\n\n\n\n\n\np = 0.32666\n\n\n\n\n\n\n\n\n\n\nFoundationWood\n\n\n-13,077.21000 (-43,087.81000, 16,933.39000)\n\n\n\n\n\n\nt = -0.85406\n\n\n\n\n\n\np = 0.39318\n\n\n\n\n\n\n\n\n\n\nBsmt.Unf.SF\n\n\n20.08809 (-92.88957, 133.06580)\n\n\n\n\n\n\nt = 0.34849\n\n\n\n\n\n\np = 0.72751\n\n\n\n\n\n\n\n\n\n\nTotal.Bsmt.SF\n\n\n-14.90117 (-127.87620, 98.07386)\n\n\n\n\n\n\nt = -0.25852\n\n\n\n\n\n\np = 0.79604\n\n\n\n\n\n\n\n\n\n\nBaseLivArea\n\n\n37.94264 (-74.94773, 150.83300)\n\n\n\n\n\n\nt = 0.65875\n\n\n\n\n\n\np = 0.51014\n\n\n\n\n\n\n\n\n\n\nCentral.AirY\n\n\n-2,331.77700 (-8,722.74500, 4,059.19000)\n\n\n\n\n\n\nt = -0.71510\n\n\n\n\n\n\np = 0.47464\n\n\n\n\n\n\n\n\n\n\nX1st.Flr.SF\n\n\n11.16909 (-21.56201, 43.90020)\n\n\n\n\n\n\nt = 0.66881\n\n\n\n\n\n\np = 0.50370\n\n\n\n\n\n\n\n\n\n\nX2nd.Flr.SF\n\n\n21.20470 (-10.27377, 52.68317)\n\n\n\n\n\n\nt = 1.32028\n\n\n\n\n\n\np = 0.18690\n\n\n\n\n\n\n\n\n\n\nGr.Liv.Area\n\n\n27.46222* (-4.73022, 59.65466)\n\n\n\n\n\n\nt = 1.67198\n\n\n\n\n\n\np = 0.09469\n\n\n\n\n\n\n\n\n\n\nFull.Bath\n\n\n6,683.69600*** (2,746.96700, 10,620.43000)\n\n\n\n\n\n\nt = 3.32759\n\n\n\n\n\n\np = 0.00090\n\n\n\n\n\n\n\n\n\n\nHalf.Bath\n\n\n2,363.51700 (-1,456.97200, 6,184.00600)\n\n\n\n\n\n\nt = 1.21252\n\n\n\n\n\n\np = 0.22547\n\n\n\n\n\n\n\n\n\n\nBathrooms\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBedroom.AbvGr\n\n\n-2,775.97400** (-5,249.07300, -302.87490)\n\n\n\n\n\n\nt = -2.20000\n\n\n\n\n\n\np = 0.02793\n\n\n\n\n\n\n\n\n\n\nKitchen.AbvGr\n\n\n-13,051.86000** (-24,242.05000, -1,861.68000)\n\n\n\n\n\n\nt = -2.28604\n\n\n\n\n\n\np = 0.02236\n\n\n\n\n\n\n\n\n\n\nKitchen.QualFa\n\n\n-35,430.56000*** (-46,768.31000, -24,092.82000)\n\n\n\n\n\n\nt = -6.12490\n\n\n\n\n\n\np = 0.00000\n\n\n\n\n\n\n\n\n\n\nKitchen.QualGd\n\n\n-37,934.88000*** (-44,089.20000, -31,780.56000)\n\n\n\n\n\n\nt = -12.08111\n\n\n\n\n\n\np = 0.00000\n\n\n\n\n\n\n\n\n\n\nKitchen.QualTA\n\n\n-39,483.22000*** (-46,580.57000, -32,385.87000)\n\n\n\n\n\n\nt = -10.90346\n\n\n\n\n\n\np = 0.00000\n\n\n\n\n\n\n\n\n\n\nTotRms.AbvGrd\n\n\n1,553.69400* (-174.07630, 3,281.46500)\n\n\n\n\n\n\nt = 1.76249\n\n\n\n\n\n\np = 0.07815\n\n\n\n\n\n\n\n\n\n\nFireplaces\n\n\n5,243.89500*** (2,730.50000, 7,757.29000)\n\n\n\n\n\n\nt = 4.08923\n\n\n\n\n\n\np = 0.00005\n\n\n\n\n\n\n\n\n\n\nGarage.TypeAttchd\n\n\n10,760.05000 (-4,364.42100, 25,884.51000)\n\n\n\n\n\n\nt = 1.39438\n\n\n\n\n\n\np = 0.16337\n\n\n\n\n\n\n\n\n\n\nGarage.TypeBasment\n\n\n15,279.79000 (-4,558.76000, 35,118.34000)\n\n\n\n\n\n\nt = 1.50958\n\n\n\n\n\n\np = 0.13132\n\n\n\n\n\n\n\n\n\n\nGarage.TypeBuiltIn\n\n\n15,600.90000* (-697.97820, 31,899.77000)\n\n\n\n\n\n\nt = 1.87603\n\n\n\n\n\n\np = 0.06080\n\n\n\n\n\n\n\n\n\n\nGarage.TypeCarPort\n\n\n5,377.45300 (-18,086.58000, 28,841.49000)\n\n\n\n\n\n\nt = 0.44918\n\n\n\n\n\n\np = 0.65336\n\n\n\n\n\n\n\n\n\n\nGarage.TypeDetchd\n\n\n8,604.57100 (-6,408.82300, 23,617.96000)\n\n\n\n\n\n\nt = 1.12331\n\n\n\n\n\n\np = 0.26145\n\n\n\n\n\n\n\n\n\n\nGarage.Area\n\n\n25.00584*** (16.00345, 34.00823)\n\n\n\n\n\n\nt = 5.44417\n\n\n\n\n\n\np = 0.0000001\n\n\n\n\n\n\n\n\n\n\nWood.Deck.SF\n\n\n4.67919 (-6.46395, 15.82234)\n\n\n\n\n\n\nt = 0.82302\n\n\n\n\n\n\np = 0.41060\n\n\n\n\n\n\n\n\n\n\nOpen.Porch.SF\n\n\n-4.84744 (-26.26057, 16.56569)\n\n\n\n\n\n\nt = -0.44369\n\n\n\n\n\n\np = 0.65732\n\n\n\n\n\n\n\n\n\n\nEnclosed.Porch\n\n\n11.40326 (-9.74494, 32.55147)\n\n\n\n\n\n\nt = 1.05683\n\n\n\n\n\n\np = 0.29073\n\n\n\n\n\n\n\n\n\n\nX3Ssn.Porch\n\n\n40.87324 (-17.08306, 98.82953)\n\n\n\n\n\n\nt = 1.38225\n\n\n\n\n\n\np = 0.16706\n\n\n\n\n\n\n\n\n\n\nScreen.Porch\n\n\n60.57027*** (37.69270, 83.44783)\n\n\n\n\n\n\nt = 5.18917\n\n\n\n\n\n\np = 0.0000003\n\n\n\n\n\n\n\n\n\n\nMo.Sold\n\n\n-340.01420 (-809.94220, 129.91380)\n\n\n\n\n\n\nt = -1.41812\n\n\n\n\n\n\np = 0.15632\n\n\n\n\n\n\n\n\n\n\nYr.Sold\n\n\n2,352.76300 (-8,161.50600, 12,867.03000)\n\n\n\n\n\n\nt = 0.43858\n\n\n\n\n\n\np = 0.66102\n\n\n\n\n\n\n\n\n\n\nSale.ConditionAdjLand\n\n\n3,075.75500 (-19,059.80000, 25,211.31000)\n\n\n\n\n\n\nt = 0.27234\n\n\n\n\n\n\np = 0.78540\n\n\n\n\n\n\n\n\n\n\nSale.ConditionAlloca\n\n\n3,523.68300 (-11,356.82000, 18,404.18000)\n\n\n\n\n\n\nt = 0.46412\n\n\n\n\n\n\np = 0.64262\n\n\n\n\n\n\n\n\n\n\nSale.ConditionFamily\n\n\n6,487.67400 (-5,044.99900, 18,020.35000)\n\n\n\n\n\n\nt = 1.10257\n\n\n\n\n\n\np = 0.27035\n\n\n\n\n\n\n\n\n\n\nSale.ConditionNormal\n\n\n7,880.08300*** (2,538.89900, 13,221.27000)\n\n\n\n\n\n\nt = 2.89162\n\n\n\n\n\n\np = 0.00388\n\n\n\n\n\n\n\n\n\n\nSale.ConditionPartial\n\n\n21,144.76000*** (13,743.88000, 28,545.65000)\n\n\n\n\n\n\nt = 5.59973\n\n\n\n\n\n\np = 0.0000001\n\n\n\n\n\n\n\n\n\n\nConstant\n\n\n-5,597,142.00000 (-26,756,346.00000, 15,562,063.00000)\n\n\n\n\n\n\nt = -0.51846\n\n\n\n\n\n\np = 0.60420\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservations\n\n\n2,051\n\n\n\n\nR2\n\n\n0.87716\n\n\n\n\nAdjusted R2\n\n\n0.87126\n\n\n\n\nResidual Std. Error\n\n\n28,321.30000 (df = 1956)\n\n\n\n\nF Statistic\n\n\n148.59050*** (df = 94; 1956)\n\n\n\n\n\n\n\n\nNote:\n\n\np&lt;0.1; p&lt;0.05; p&lt;0.01\n\n\n\n\n\n6.2.1 Regression Diagnostic\nOnce a linear regression model is fitted, there are four primary assumptions that we should check:\n\nLinearity: The relationship between the predictors and the response variable should be linear.\nIndependence: The residuals should be independent, especially in time series data.\nHomoscedasticity (Constant Variance): The variance of the residuals should be constant across all levels of the independent variables.\nNormality: The residuals should be approximately normally distributed. We commonly use diagnostic plots to diagnose potential violations of these assumptions in R. Here’s a breakdown of these plots and their descriptions:\n\n\n6.2.1.1 Residual vs. Fitted (or Predicted) Values:\nThis plot helps check the assumptions of linearity and equal variance (homoscedasticity).\nDescription: A horizontal band around the 0 reference line indicates that the relationship is linear and the variances are equal. Patterns or trends suggest violations.\n\nplot(full_lm_model, which=1)\n\n\n\n\n\n\n\n\n\n\n6.2.1.2 Normal Q-Q Plot:\nThis plot checks the assumption of normality of the residuals.\nDescription: If the residuals are normally distributed, they should fall on a roughly straight line at a 45-degree angle. Deviations from this line indicate departures from normality.\n\nplot(full_lm_model, which=2)\n\n#&gt; Warning: not plotting observations with leverage one:\n#&gt;   94, 541, 1048\n\n\n\n\n\n\n\n\n\n\n\n6.2.1.3 Scale-Location (or Spread-Location) Plot:\nThis plot helps check the assumption of equal variance (homoscedasticity).\nDescription: A horizontal band with equally spread points indicates equal variances. A funnel shape (either narrow at the bottom or top) suggests that the variances change with the fitted values, violating the assumption.\n\nplot(full_lm_model, which=3)\n\n#&gt; Warning: not plotting observations with leverage one:\n#&gt;   94, 541, 1048\n\n\n\n\n\n\n\n\n\n\n\n6.2.1.4 Residuals vs. Leverage:\nThis plot helps identify influential case observations that have an undue influence on the regression equation.\nDescription: Points that stand out, especially those in the plot’s top right or bottom right, are influential for the regression equation. The Cook’s distance lines can help identify significant observations.\n\nplot(full_lm_model, which=5)\n\n#&gt; Warning: not plotting observations with leverage one:\n#&gt;   94, 541, 1048\n\n\n\n\n\n\n\n\n\nRemember, no real-world data will perfectly meet all these assumptions. The key is to identify major deviations that could bias the regression results. If any of these assumptions appear to be violated, further investigation and potentially other modeling approaches or transformations might be necessary.\n\n\n6.2.1.5 Cook’s Distance\nCook’s Distance is a measure used in regression analysis to identify influential data points. An influential data point is an observation or set of observations that notably affects the regression equation. Such points can exert undue leverage on the estimated regression coefficients, potentially skewing the model.\nConcept: Cook’s Distance combines the leverage (how extreme the input data is) and the residuals (how extreme the output is) into a single measure.\nThe measure quantifies how much all the fitted values would change if we excluded a particular observation from the dataset.\nCalculation: It is computed for each observation and represents the scaled change in the fitted values when the observation is left out of the regression. Mathematically, it’s a function of each observation’s residual and leverage.\nInterpretation: A common rule of thumb is that any observation with a Cook’s Distance more significant than one might be influential. However, this threshold might be too strict in practice, especially for larger datasets.\nAnother common practice is to look for points whose Cook’s Distance exceeds four times the mean of all Cook’s Distance values.\nA large Cook’s Distance value indicates that the observation strongly influences the regression coefficients. Removing this observation would significantly change the estimated regression line.\nIt’s crucial not to automatically exclude data points based on Cook’s Distance alone. If an observation has a high Cook’s Distance, one should investigate the reasons for its influence. It could result from data entry or measurement errors or represent a legitimate, interesting outlier.\n\nplot(full_lm_model, which=4)"
  },
  {
    "objectID": "M2/M2LN1.html#variable-selection-techniques-in-multiple-regression",
    "href": "M2/M2LN1.html#variable-selection-techniques-in-multiple-regression",
    "title": "Multiple Linear Regression",
    "section": "6.3 Variable Selection Techniques in Multiple Regression",
    "text": "6.3 Variable Selection Techniques in Multiple Regression\n\n6.3.1 Forward Selection:\n\nStarting Point: Begins with no predictors in the model.\nProcedure: In each step, the predictor that results in the lowest residual sum of squares (RSS) when added to the model is included.\nStopping Point: Continues until a pre-specified stopping rule is met, like a certain number of variables, or until adding predictors no longer improves the model by a significant amount.\nAdvantages: Computationally efficient compared to best subset selection, especially when the number of predictors is large.\n\n\n# Load necessary library\nlibrary(MASS)\n\n# Fit the base model (with only the intercept)\nbase_model &lt;- lm(SalePrice ~ 1, data=train_data)\n\n# Perform forward selection\nforward_selected_model &lt;- step(base_model, \n                               scope=list(lower=~1, \n                                          upper=~Order + Lot.Frontage + Lot.Area + Lot.Shape + Utilities + \n                                                  Lot.Config + Land.Slope + Neighborhood + Bldg.Type + House.Style + Overall.Qual + Overall.Cond + Year.Built + Year.Remod.Add + Foundation + Bsmt.Unf.SF + Total.Bsmt.SF + BaseLivArea + \n                                                  Central.Air + X1st.Flr.SF + X2nd.Flr.SF + Gr.Liv.Area + Full.Bath + Half.Bath + Bathrooms + Bedroom.AbvGr + Kitchen.AbvGr + TotRms.AbvGrd + Fireplaces + Garage.Type + \n                                                  Garage.Area + Wood.Deck.SF + Open.Porch.SF + Enclosed.Porch + \n                                                  X3Ssn.Porch + Screen.Porch + Mo.Sold + Yr.Sold + Sale.Condition),\n                               direction=\"forward\",\n                               trace=0)  # trace=1 provides a step-by-step output\n\n# View the final model\nstargazer::stargazer(forward_selected_model, type = \"html\", out = \"regression.html\" ,title = \"Simple Linear Model\", ci=TRUE, single.row = TRUE, no.space = FALSE, align = TRUE, digits=5, font.size = \"small\",  report = \"vc*stp\")\n\n\nSimple Linear Model\n\n\n\n\n\n\n\n\n\nDependent variable:\n\n\n\n\n\n\n\n\n\n\n\n\nSalePrice\n\n\n\n\n\n\n\n\nOverall.Qual\n\n\n13,479.37000*** (11,692.66000, 15,266.07000)\n\n\n\n\n\n\nt = 14.78649\n\n\n\n\n\n\np = 0.00000\n\n\n\n\n\n\n\n\n\n\nGr.Liv.Area\n\n\n41.52258*** (33.27860, 49.76656)\n\n\n\n\n\n\nt = 9.87178\n\n\n\n\n\n\np = 0.00000\n\n\n\n\n\n\n\n\n\n\nNeighborhoodBlueste\n\n\n2,843.10700 (-23,729.50000, 29,415.71000)\n\n\n\n\n\n\nt = 0.20970\n\n\n\n\n\n\np = 0.83393\n\n\n\n\n\n\n\n\n\n\nNeighborhoodBrDale\n\n\n8,739.89200 (-11,680.53000, 29,160.31000)\n\n\n\n\n\n\nt = 0.83886\n\n\n\n\n\n\np = 0.40165\n\n\n\n\n\n\n\n\n\n\nNeighborhoodBrkSide\n\n\n-11,472.78000 (-29,118.76000, 6,173.19300)\n\n\n\n\n\n\nt = -1.27430\n\n\n\n\n\n\np = 0.20271\n\n\n\n\n\n\n\n\n\n\nNeighborhoodClearCr\n\n\n-13,620.00000 (-32,801.76000, 5,561.75800)\n\n\n\n\n\n\nt = -1.39167\n\n\n\n\n\n\np = 0.16418\n\n\n\n\n\n\n\n\n\n\nNeighborhoodCollgCr\n\n\n-11,981.53000 (-27,428.29000, 3,465.23400)\n\n\n\n\n\n\nt = -1.52028\n\n\n\n\n\n\np = 0.12861\n\n\n\n\n\n\n\n\n\n\nNeighborhoodCrawfor\n\n\n8,512.60900 (-8,324.81200, 25,350.03000)\n\n\n\n\n\n\nt = 0.99091\n\n\n\n\n\n\np = 0.32185\n\n\n\n\n\n\n\n\n\n\nNeighborhoodEdwards\n\n\n-22,691.78000*** (-38,931.64000, -6,451.92000)\n\n\n\n\n\n\nt = -2.73864\n\n\n\n\n\n\np = 0.00623\n\n\n\n\n\n\n\n\n\n\nNeighborhoodGilbert\n\n\n-20,599.96000** (-36,717.68000, -4,482.23400)\n\n\n\n\n\n\nt = -2.50502\n\n\n\n\n\n\np = 0.01233\n\n\n\n\n\n\n\n\n\n\nNeighborhoodGreens\n\n\n15,846.29000 (-11,110.37000, 42,802.95000)\n\n\n\n\n\n\nt = 1.15215\n\n\n\n\n\n\np = 0.24940\n\n\n\n\n\n\n\n\n\n\nNeighborhoodGrnHill\n\n\n129,888.20000*** (70,614.59000, 189,161.80000)\n\n\n\n\n\n\nt = 4.29493\n\n\n\n\n\n\np = 0.00002\n\n\n\n\n\n\n\n\n\n\nNeighborhoodIDOTRR\n\n\n-15,758.82000* (-33,892.39000, 2,374.76400)\n\n\n\n\n\n\nt = -1.70329\n\n\n\n\n\n\np = 0.08868\n\n\n\n\n\n\n\n\n\n\nNeighborhoodLandmrk\n\n\n10,907.48000 (-49,333.66000, 71,148.62000)\n\n\n\n\n\n\nt = 0.35488\n\n\n\n\n\n\np = 0.72272\n\n\n\n\n\n\n\n\n\n\nNeighborhoodMeadowV\n\n\n6,726.82500 (-11,876.50000, 25,330.15000)\n\n\n\n\n\n\nt = 0.70871\n\n\n\n\n\n\np = 0.47859\n\n\n\n\n\n\n\n\n\n\nNeighborhoodMitchel\n\n\n-17,512.17000** (-33,927.43000, -1,096.90400)\n\n\n\n\n\n\nt = -2.09093\n\n\n\n\n\n\np = 0.03667\n\n\n\n\n\n\n\n\n\n\nNeighborhoodNAmes\n\n\n-14,891.41000* (-30,827.83000, 1,045.00900)\n\n\n\n\n\n\nt = -1.83144\n\n\n\n\n\n\np = 0.06719\n\n\n\n\n\n\n\n\n\n\nNeighborhoodNoRidge\n\n\n36,220.40000*** (18,513.70000, 53,927.10000)\n\n\n\n\n\n\nt = 4.00926\n\n\n\n\n\n\np = 0.00007\n\n\n\n\n\n\n\n\n\n\nNeighborhoodNPkVill\n\n\n4,549.64400 (-17,547.67000, 26,646.96000)\n\n\n\n\n\n\nt = 0.40354\n\n\n\n\n\n\np = 0.68660\n\n\n\n\n\n\n\n\n\n\nNeighborhoodNridgHt\n\n\n48,342.12000*** (33,032.92000, 63,651.32000)\n\n\n\n\n\n\nt = 6.18901\n\n\n\n\n\n\np = 0.00000\n\n\n\n\n\n\n\n\n\n\nNeighborhoodNWAmes\n\n\n-20,007.26000** (-36,442.10000, -3,572.42800)\n\n\n\n\n\n\nt = -2.38600\n\n\n\n\n\n\np = 0.01713\n\n\n\n\n\n\n\n\n\n\nNeighborhoodOldTown\n\n\n-17,281.65000** (-34,403.30000, -159.98980)\n\n\n\n\n\n\nt = -1.97828\n\n\n\n\n\n\np = 0.04804\n\n\n\n\n\n\n\n\n\n\nNeighborhoodSawyer\n\n\n-15,950.72000* (-32,518.69000, 617.25640)\n\n\n\n\n\n\nt = -1.88694\n\n\n\n\n\n\np = 0.05932\n\n\n\n\n\n\n\n\n\n\nNeighborhoodSawyerW\n\n\n-19,437.82000** (-35,604.88000, -3,270.75400)\n\n\n\n\n\n\nt = -2.35648\n\n\n\n\n\n\np = 0.01855\n\n\n\n\n\n\n\n\n\n\nNeighborhoodSomerst\n\n\n8,589.75300 (-6,587.08300, 23,766.59000)\n\n\n\n\n\n\nt = 1.10930\n\n\n\n\n\n\np = 0.26744\n\n\n\n\n\n\n\n\n\n\nNeighborhoodStoneBr\n\n\n53,246.43000*** (36,270.27000, 70,222.60000)\n\n\n\n\n\n\nt = 6.14751\n\n\n\n\n\n\np = 0.00000\n\n\n\n\n\n\n\n\n\n\nNeighborhoodSWISU\n\n\n-16,388.01000* (-35,511.23000, 2,735.21600)\n\n\n\n\n\n\nt = -1.67963\n\n\n\n\n\n\np = 0.09319\n\n\n\n\n\n\n\n\n\n\nNeighborhoodTimber\n\n\n-11.38951 (-17,011.67000, 16,988.89000)\n\n\n\n\n\n\nt = -0.00131\n\n\n\n\n\n\np = 0.99896\n\n\n\n\n\n\n\n\n\n\nNeighborhoodVeenker\n\n\n3,344.23400 (-16,698.45000, 23,386.92000)\n\n\n\n\n\n\nt = 0.32703\n\n\n\n\n\n\np = 0.74368\n\n\n\n\n\n\n\n\n\n\nBaseLivArea\n\n\n25.57887*** (19.13377, 32.02396)\n\n\n\n\n\n\nt = 7.77857\n\n\n\n\n\n\np = 0.00000\n\n\n\n\n\n\n\n\n\n\nBldg.Type2fmCon\n\n\n-5,936.95600 (-16,252.66000, 4,378.75100)\n\n\n\n\n\n\nt = -1.12801\n\n\n\n\n\n\np = 0.25946\n\n\n\n\n\n\n\n\n\n\nBldg.TypeDuplex\n\n\n-2,557.69000 (-15,094.53000, 9,979.15300)\n\n\n\n\n\n\nt = -0.39986\n\n\n\n\n\n\np = 0.68931\n\n\n\n\n\n\n\n\n\n\nBldg.TypeTwnhs\n\n\n-45,079.30000*** (-56,046.87000, -34,111.73000)\n\n\n\n\n\n\nt = -8.05591\n\n\n\n\n\n\np = 0.00000\n\n\n\n\n\n\n\n\n\n\nBldg.TypeTwnhsE\n\n\n-32,478.51000*** (-39,499.60000, -25,457.43000)\n\n\n\n\n\n\nt = -9.06650\n\n\n\n\n\n\np = 0.00000\n\n\n\n\n\n\n\n\n\n\nYear.Built\n\n\n372.81780*** (248.85920, 496.77640)\n\n\n\n\n\n\nt = 5.89478\n\n\n\n\n\n\np = 0.00000\n\n\n\n\n\n\n\n\n\n\nSale.ConditionAdjLand\n\n\n3,798.87300 (-18,793.65000, 26,391.39000)\n\n\n\n\n\n\nt = 0.32956\n\n\n\n\n\n\np = 0.74177\n\n\n\n\n\n\n\n\n\n\nSale.ConditionAlloca\n\n\n1,605.97800 (-13,556.25000, 16,768.21000)\n\n\n\n\n\n\nt = 0.20760\n\n\n\n\n\n\np = 0.83557\n\n\n\n\n\n\n\n\n\n\nSale.ConditionFamily\n\n\n6,843.60600 (-5,023.50300, 18,710.71000)\n\n\n\n\n\n\nt = 1.13029\n\n\n\n\n\n\np = 0.25850\n\n\n\n\n\n\n\n\n\n\nSale.ConditionNormal\n\n\n6,388.35500** (937.03400, 11,839.68000)\n\n\n\n\n\n\nt = 2.29686\n\n\n\n\n\n\np = 0.02174\n\n\n\n\n\n\n\n\n\n\nSale.ConditionPartial\n\n\n23,969.80000*** (16,429.00000, 31,510.59000)\n\n\n\n\n\n\nt = 6.23010\n\n\n\n\n\n\np = 0.00000\n\n\n\n\n\n\n\n\n\n\nOverall.Cond\n\n\n5,168.43100*** (3,703.83200, 6,633.03100)\n\n\n\n\n\n\nt = 6.91652\n\n\n\n\n\n\np = 0.00000\n\n\n\n\n\n\n\n\n\n\nLot.Area\n\n\n0.52338*** (0.31905, 0.72772)\n\n\n\n\n\n\nt = 5.02035\n\n\n\n\n\n\np = 0.000001\n\n\n\n\n\n\n\n\n\n\nScreen.Porch\n\n\n59.51841*** (36.20029, 82.83654)\n\n\n\n\n\n\nt = 5.00272\n\n\n\n\n\n\np = 0.000001\n\n\n\n\n\n\n\n\n\n\nGarage.Area\n\n\n21.44998*** (12.96982, 29.93013)\n\n\n\n\n\n\nt = 4.95759\n\n\n\n\n\n\np = 0.000001\n\n\n\n\n\n\n\n\n\n\nHouse.Style1.5Unf\n\n\n10,496.06000 (-6,278.54600, 27,270.67000)\n\n\n\n\n\n\nt = 1.22637\n\n\n\n\n\n\np = 0.22021\n\n\n\n\n\n\n\n\n\n\nHouse.Style1Story\n\n\n11,751.13000*** (4,880.87600, 18,621.38000)\n\n\n\n\n\n\nt = 3.35239\n\n\n\n\n\n\np = 0.00082\n\n\n\n\n\n\n\n\n\n\nHouse.Style2.5Fin\n\n\n-27,978.63000** (-55,129.02000, -828.24650)\n\n\n\n\n\n\nt = -2.01975\n\n\n\n\n\n\np = 0.04355\n\n\n\n\n\n\n\n\n\n\nHouse.Style2.5Unf\n\n\n-5,474.84900 (-21,321.87000, 10,372.17000)\n\n\n\n\n\n\nt = -0.67713\n\n\n\n\n\n\np = 0.49841\n\n\n\n\n\n\n\n\n\n\nHouse.Style2Story\n\n\n-7,494.88700** (-13,589.77000, -1,400.00100)\n\n\n\n\n\n\nt = -2.41017\n\n\n\n\n\n\np = 0.01604\n\n\n\n\n\n\n\n\n\n\nHouse.StyleSFoyer\n\n\n13,090.54000** (2,591.15400, 23,589.93000)\n\n\n\n\n\n\nt = 2.44367\n\n\n\n\n\n\np = 0.01463\n\n\n\n\n\n\n\n\n\n\nHouse.StyleSLvl\n\n\n3,742.10200 (-4,796.90700, 12,281.11000)\n\n\n\n\n\n\nt = 0.85893\n\n\n\n\n\n\np = 0.39049\n\n\n\n\n\n\n\n\n\n\nLot.ShapeIR2\n\n\n8,123.22900* (-802.94190, 17,049.40000)\n\n\n\n\n\n\nt = 1.78366\n\n\n\n\n\n\np = 0.07464\n\n\n\n\n\n\n\n\n\n\nLot.ShapeIR3\n\n\n-29,048.06000*** (-45,007.06000, -13,089.06000)\n\n\n\n\n\n\nt = -3.56746\n\n\n\n\n\n\np = 0.00037\n\n\n\n\n\n\n\n\n\n\nLot.ShapeReg\n\n\n1,528.94500 (-1,664.16800, 4,722.05800)\n\n\n\n\n\n\nt = 0.93848\n\n\n\n\n\n\np = 0.34812\n\n\n\n\n\n\n\n\n\n\nFireplaces\n\n\n5,202.51400*** (2,643.28700, 7,761.74000)\n\n\n\n\n\n\nt = 3.98431\n\n\n\n\n\n\np = 0.00008\n\n\n\n\n\n\n\n\n\n\nBathrooms\n\n\n5,996.61700*** (2,018.21700, 9,975.01700)\n\n\n\n\n\n\nt = 2.95424\n\n\n\n\n\n\np = 0.00318\n\n\n\n\n\n\n\n\n\n\nLot.Frontage\n\n\n-84.44456* (-168.94340, 0.05431)\n\n\n\n\n\n\nt = -1.95870\n\n\n\n\n\n\np = 0.05029\n\n\n\n\n\n\n\n\n\n\nYear.Remod.Add\n\n\n97.99938* (-2.04115, 198.03990)\n\n\n\n\n\n\nt = 1.91997\n\n\n\n\n\n\np = 0.05501\n\n\n\n\n\n\n\n\n\n\nLand.SlopeMod\n\n\n11,074.44000*** (4,382.30600, 17,766.56000)\n\n\n\n\n\n\nt = 3.24344\n\n\n\n\n\n\np = 0.00121\n\n\n\n\n\n\n\n\n\n\nLand.SlopeSev\n\n\n-5,074.33200 (-23,705.70000, 13,557.03000)\n\n\n\n\n\n\nt = -0.53380\n\n\n\n\n\n\np = 0.59354\n\n\n\n\n\n\n\n\n\n\nBedroom.AbvGr\n\n\n-3,945.51400*** (-6,436.26200, -1,454.76600)\n\n\n\n\n\n\nt = -3.10472\n\n\n\n\n\n\np = 0.00194\n\n\n\n\n\n\n\n\n\n\nTotRms.AbvGrd\n\n\n2,363.26400*** (586.93740, 4,139.59100)\n\n\n\n\n\n\nt = 2.60758\n\n\n\n\n\n\np = 0.00919\n\n\n\n\n\n\n\n\n\n\nKitchen.AbvGr\n\n\n-13,944.52000** (-25,444.97000, -2,444.08200)\n\n\n\n\n\n\nt = -2.37650\n\n\n\n\n\n\np = 0.01758\n\n\n\n\n\n\n\n\n\n\nFoundationCBlock\n\n\n-2,626.30700 (-8,581.08400, 3,328.47000)\n\n\n\n\n\n\nt = -0.86443\n\n\n\n\n\n\np = 0.38746\n\n\n\n\n\n\n\n\n\n\nFoundationPConc\n\n\n4,503.15500 (-2,144.87500, 11,151.18000)\n\n\n\n\n\n\nt = 1.32761\n\n\n\n\n\n\np = 0.18446\n\n\n\n\n\n\n\n\n\n\nFoundationSlab\n\n\n1,685.56400 (-12,309.34000, 15,680.47000)\n\n\n\n\n\n\nt = 0.23606\n\n\n\n\n\n\np = 0.81342\n\n\n\n\n\n\n\n\n\n\nFoundationStone\n\n\n8,073.04400 (-12,024.60000, 28,170.69000)\n\n\n\n\n\n\nt = 0.78730\n\n\n\n\n\n\np = 0.43121\n\n\n\n\n\n\n\n\n\n\nFoundationWood\n\n\n-15,500.73000 (-45,764.57000, 14,763.11000)\n\n\n\n\n\n\nt = -1.00387\n\n\n\n\n\n\np = 0.31557\n\n\n\n\n\n\n\n\n\n\nX2nd.Flr.SF\n\n\n12.70646** (2.11361, 23.29932)\n\n\n\n\n\n\nt = 2.35104\n\n\n\n\n\n\np = 0.01882\n\n\n\n\n\n\n\n\n\n\nLot.ConfigCulDSac\n\n\n8,242.40000** (1,526.96600, 14,957.83000)\n\n\n\n\n\n\nt = 2.40562\n\n\n\n\n\n\np = 0.01624\n\n\n\n\n\n\n\n\n\n\nLot.ConfigFR2\n\n\n-4,743.18900 (-13,107.54000, 3,621.16500)\n\n\n\n\n\n\nt = -1.11144\n\n\n\n\n\n\np = 0.26652\n\n\n\n\n\n\n\n\n\n\nLot.ConfigFR3\n\n\n-1,202.19600 (-18,367.77000, 15,963.38000)\n\n\n\n\n\n\nt = -0.13727\n\n\n\n\n\n\np = 0.89084\n\n\n\n\n\n\n\n\n\n\nLot.ConfigInside\n\n\n1,917.46000 (-1,705.27200, 5,540.19100)\n\n\n\n\n\n\nt = 1.03738\n\n\n\n\n\n\np = 0.29969\n\n\n\n\n\n\n\n\n\n\nX3Ssn.Porch\n\n\n49.63295 (-10.06617, 109.33210)\n\n\n\n\n\n\nt = 1.62948\n\n\n\n\n\n\np = 0.10337\n\n\n\n\n\n\n\n\n\n\nBsmt.Unf.SF\n\n\n5.39633 (-1.24957, 12.04224)\n\n\n\n\n\n\nt = 1.59145\n\n\n\n\n\n\np = 0.11167\n\n\n\n\n\n\n\n\n\n\nConstant\n\n\n-960,652.70000*** (-1,231,564.00000, -689,741.90000)\n\n\n\n\n\n\nt = -6.95005\n\n\n\n\n\n\np = 0.00000\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservations\n\n\n2,051\n\n\n\n\nR2\n\n\n0.86704\n\n\n\n\nAdjusted R2\n\n\n0.86200\n\n\n\n\nResidual Std. Error\n\n\n29,322.53000 (df = 1975)\n\n\n\n\nF Statistic\n\n\n171.72850*** (df = 75; 1975)\n\n\n\n\n\n\n\n\nNote:\n\n\np&lt;0.1; p&lt;0.05; p&lt;0.01\n\n\n\n\n\n\n6.3.2 Backward Elimination:\n\nStarting Point: Begins with all predictors in the model.\nProcedure: In each step, the predictor that is least significant (i.e., has the highest p-value) and does not contribute significantly to the model fit is removed.\nStopping Point: Continues until a stopping rule is met, often when all remaining predictors are significant at a specified alpha level.\nAdvantages: Like forward selection, it’s more computationally efficient than best subset selection.\n\n\n# Load necessary library\nlibrary(MASS)\n\n# Fit the full model (with all predictors)\nfull_model &lt;- lm(SalePrice ~ Order + Lot.Frontage + Lot.Area + Lot.Shape + Utilities + \n                 Lot.Config + Land.Slope + Neighborhood + Bldg.Type + House.Style + \n                 Overall.Qual + Overall.Cond + Year.Built + Year.Remod.Add + \n                 Foundation + Bsmt.Unf.SF + Total.Bsmt.SF + BaseLivArea + \n                 Central.Air + X1st.Flr.SF + X2nd.Flr.SF + Gr.Liv.Area + Full.Bath + \n                 Half.Bath + Bathrooms + Bedroom.AbvGr + Kitchen.AbvGr + \n                 TotRms.AbvGrd + Fireplaces + Garage.Type + \n                 Garage.Area + Wood.Deck.SF + Open.Porch.SF + Enclosed.Porch + \n                 X3Ssn.Porch + Screen.Porch + Mo.Sold + Yr.Sold + Sale.Condition, \n                 data=train_data)\n\n# Perform backward selection\nbackward_selected_model &lt;- step(full_model, \n                               direction=\"backward\",\n                               trace=0)  # trace=1 provides a step-by-step output\n\n# View the final model\nstargazer::stargazer(backward_selected_model, type = \"html\", out = \"regression.html\" ,title = \"Simple Linear Model\", ci=TRUE, single.row = TRUE, no.space = FALSE, align = TRUE, digits=5, font.size = \"small\",  report = \"vc*stp\")\n\n\nSimple Linear Model\n\n\n\n\n\n\n\n\n\nDependent variable:\n\n\n\n\n\n\n\n\n\n\n\n\nSalePrice\n\n\n\n\n\n\n\n\nLot.Frontage\n\n\n-84.42088* (-168.94220, 0.10045)\n\n\n\n\n\n\nt = -1.95763\n\n\n\n\n\n\np = 0.05042\n\n\n\n\n\n\n\n\n\n\nLot.Area\n\n\n0.52307*** (0.31859, 0.72755)\n\n\n\n\n\n\nt = 5.01379\n\n\n\n\n\n\np = 0.000001\n\n\n\n\n\n\n\n\n\n\nLot.ShapeIR2\n\n\n8,117.05100* (-812.18100, 17,046.28000)\n\n\n\n\n\n\nt = 1.78169\n\n\n\n\n\n\np = 0.07496\n\n\n\n\n\n\n\n\n\n\nLot.ShapeIR3\n\n\n-29,053.66000*** (-45,017.04000, -13,090.28000)\n\n\n\n\n\n\nt = -3.56717\n\n\n\n\n\n\np = 0.00037\n\n\n\n\n\n\n\n\n\n\nLot.ShapeReg\n\n\n1,530.75000 (-1,663.36000, 4,724.86000)\n\n\n\n\n\n\nt = 0.93930\n\n\n\n\n\n\np = 0.34770\n\n\n\n\n\n\n\n\n\n\nLot.ConfigCulDSac\n\n\n8,251.54900** (1,532.03200, 14,971.07000)\n\n\n\n\n\n\nt = 2.40683\n\n\n\n\n\n\np = 0.01619\n\n\n\n\n\n\n\n\n\n\nLot.ConfigFR2\n\n\n-4,731.23600 (-13,100.98000, 3,638.50300)\n\n\n\n\n\n\nt = -1.10793\n\n\n\n\n\n\np = 0.26803\n\n\n\n\n\n\n\n\n\n\nLot.ConfigFR3\n\n\n-1,200.73600 (-18,370.64000, 15,969.16000)\n\n\n\n\n\n\nt = -0.13707\n\n\n\n\n\n\np = 0.89100\n\n\n\n\n\n\n\n\n\n\nLot.ConfigInside\n\n\n1,915.98800 (-1,707.76700, 5,539.74300)\n\n\n\n\n\n\nt = 1.03629\n\n\n\n\n\n\np = 0.30020\n\n\n\n\n\n\n\n\n\n\nLand.SlopeMod\n\n\n11,087.45000*** (4,388.77000, 17,786.12000)\n\n\n\n\n\n\nt = 3.24407\n\n\n\n\n\n\np = 0.00120\n\n\n\n\n\n\n\n\n\n\nLand.SlopeSev\n\n\n-5,028.89200 (-23,686.26000, 13,628.47000)\n\n\n\n\n\n\nt = -0.52829\n\n\n\n\n\n\np = 0.59736\n\n\n\n\n\n\n\n\n\n\nNeighborhoodBlueste\n\n\n2,819.96000 (-23,763.19000, 29,403.11000)\n\n\n\n\n\n\nt = 0.20791\n\n\n\n\n\n\np = 0.83532\n\n\n\n\n\n\n\n\n\n\nNeighborhoodBrDale\n\n\n8,823.58100 (-11,667.90000, 29,315.06000)\n\n\n\n\n\n\nt = 0.84396\n\n\n\n\n\n\np = 0.39880\n\n\n\n\n\n\n\n\n\n\nNeighborhoodBrkSide\n\n\n-11,468.41000 (-29,119.02000, 6,182.19700)\n\n\n\n\n\n\nt = -1.27348\n\n\n\n\n\n\np = 0.20300\n\n\n\n\n\n\n\n\n\n\nNeighborhoodClearCr\n\n\n-13,632.73000 (-32,820.92000, 5,555.46800)\n\n\n\n\n\n\nt = -1.39250\n\n\n\n\n\n\np = 0.16393\n\n\n\n\n\n\n\n\n\n\nNeighborhoodCollgCr\n\n\n-11,971.54000 (-27,423.42000, 3,480.33600)\n\n\n\n\n\n\nt = -1.51851\n\n\n\n\n\n\np = 0.12905\n\n\n\n\n\n\n\n\n\n\nNeighborhoodCrawfor\n\n\n8,524.80200 (-8,318.54200, 25,368.14000)\n\n\n\n\n\n\nt = 0.99198\n\n\n\n\n\n\np = 0.32133\n\n\n\n\n\n\n\n\n\n\nNeighborhoodEdwards\n\n\n-22,681.15000*** (-38,926.42000, -6,435.87600)\n\n\n\n\n\n\nt = -2.73644\n\n\n\n\n\n\np = 0.00627\n\n\n\n\n\n\n\n\n\n\nNeighborhoodGilbert\n\n\n-20,581.13000** (-36,707.13000, -4,455.13000)\n\n\n\n\n\n\nt = -2.50144\n\n\n\n\n\n\np = 0.01245\n\n\n\n\n\n\n\n\n\n\nNeighborhoodGreens\n\n\n15,836.51000 (-11,127.59000, 42,800.60000)\n\n\n\n\n\n\nt = 1.15112\n\n\n\n\n\n\np = 0.24983\n\n\n\n\n\n\n\n\n\n\nNeighborhoodGrnHill\n\n\n130,061.10000*** (70,675.59000, 189,446.60000)\n\n\n\n\n\n\nt = 4.29255\n\n\n\n\n\n\np = 0.00002\n\n\n\n\n\n\n\n\n\n\nNeighborhoodIDOTRR\n\n\n-15,760.57000* (-33,898.73000, 2,377.58600)\n\n\n\n\n\n\nt = -1.70305\n\n\n\n\n\n\np = 0.08872\n\n\n\n\n\n\n\n\n\n\nNeighborhoodLandmrk\n\n\n10,970.53000 (-49,298.42000, 71,239.48000)\n\n\n\n\n\n\nt = 0.35676\n\n\n\n\n\n\np = 0.72131\n\n\n\n\n\n\n\n\n\n\nNeighborhoodMeadowV\n\n\n6,785.24800 (-11,858.04000, 25,428.54000)\n\n\n\n\n\n\nt = 0.71333\n\n\n\n\n\n\np = 0.47573\n\n\n\n\n\n\n\n\n\n\nNeighborhoodMitchel\n\n\n-17,505.57000** (-33,925.46000, -1,085.68400)\n\n\n\n\n\n\nt = -2.08956\n\n\n\n\n\n\np = 0.03679\n\n\n\n\n\n\n\n\n\n\nNeighborhoodNAmes\n\n\n-14,862.30000* (-30,812.96000, 1,088.35000)\n\n\n\n\n\n\nt = -1.82623\n\n\n\n\n\n\np = 0.06797\n\n\n\n\n\n\n\n\n\n\nNeighborhoodNoRidge\n\n\n36,241.03000*** (18,525.26000, 53,956.79000)\n\n\n\n\n\n\nt = 4.00949\n\n\n\n\n\n\np = 0.00007\n\n\n\n\n\n\n\n\n\n\nNeighborhoodNPkVill\n\n\n4,562.31700 (-17,541.94000, 26,666.57000)\n\n\n\n\n\n\nt = 0.40454\n\n\n\n\n\n\np = 0.68587\n\n\n\n\n\n\n\n\n\n\nNeighborhoodNridgHt\n\n\n48,350.85000*** (33,036.85000, 63,664.84000)\n\n\n\n\n\n\nt = 6.18819\n\n\n\n\n\n\np = 0.00000\n\n\n\n\n\n\n\n\n\n\nNeighborhoodNWAmes\n\n\n-19,989.76000** (-36,432.31000, -3,547.22000)\n\n\n\n\n\n\nt = -2.38280\n\n\n\n\n\n\np = 0.01728\n\n\n\n\n\n\n\n\n\n\nNeighborhoodOldTown\n\n\n-17,286.82000** (-34,413.07000, -160.56650)\n\n\n\n\n\n\nt = -1.97834\n\n\n\n\n\n\np = 0.04803\n\n\n\n\n\n\n\n\n\n\nNeighborhoodSawyer\n\n\n-15,924.98000* (-32,504.81000, 654.83900)\n\n\n\n\n\n\nt = -1.88255\n\n\n\n\n\n\np = 0.05991\n\n\n\n\n\n\n\n\n\n\nNeighborhoodSawyerW\n\n\n-19,407.73000** (-35,589.62000, -3,225.83900)\n\n\n\n\n\n\nt = -2.35068\n\n\n\n\n\n\np = 0.01884\n\n\n\n\n\n\n\n\n\n\nNeighborhoodSomerst\n\n\n8,604.93300 (-6,578.63100, 23,788.50000)\n\n\n\n\n\n\nt = 1.11076\n\n\n\n\n\n\np = 0.26681\n\n\n\n\n\n\n\n\n\n\nNeighborhoodStoneBr\n\n\n53,257.01000*** (36,275.32000, 70,238.71000)\n\n\n\n\n\n\nt = 6.14673\n\n\n\n\n\n\np = 0.00000\n\n\n\n\n\n\n\n\n\n\nNeighborhoodSWISU\n\n\n-16,399.20000* (-35,528.48000, 2,730.08000)\n\n\n\n\n\n\nt = -1.68024\n\n\n\n\n\n\np = 0.09307\n\n\n\n\n\n\n\n\n\n\nNeighborhoodTimber\n\n\n-12.97331 (-17,017.55000, 16,991.60000)\n\n\n\n\n\n\nt = -0.00150\n\n\n\n\n\n\np = 0.99881\n\n\n\n\n\n\n\n\n\n\nNeighborhoodVeenker\n\n\n3,409.32900 (-16,679.05000, 23,497.71000)\n\n\n\n\n\n\nt = 0.33264\n\n\n\n\n\n\np = 0.73945\n\n\n\n\n\n\n\n\n\n\nBldg.Type2fmCon\n\n\n-5,963.46800 (-16,294.87000, 4,367.93800)\n\n\n\n\n\n\nt = -1.13133\n\n\n\n\n\n\np = 0.25806\n\n\n\n\n\n\n\n\n\n\nBldg.TypeDuplex\n\n\n-2,540.91000 (-15,085.22000, 10,003.40000)\n\n\n\n\n\n\nt = -0.39700\n\n\n\n\n\n\np = 0.69142\n\n\n\n\n\n\n\n\n\n\nBldg.TypeTwnhs\n\n\n-45,105.03000*** (-56,086.96000, -34,123.09000)\n\n\n\n\n\n\nt = -8.04997\n\n\n\n\n\n\np = 0.00000\n\n\n\n\n\n\n\n\n\n\nBldg.TypeTwnhsE\n\n\n-32,507.15000*** (-39,552.44000, -25,461.85000)\n\n\n\n\n\n\nt = -9.04331\n\n\n\n\n\n\np = 0.00000\n\n\n\n\n\n\n\n\n\n\nHouse.Style1.5Unf\n\n\n10,473.11000 (-6,311.75700, 27,257.97000)\n\n\n\n\n\n\nt = 1.22294\n\n\n\n\n\n\np = 0.22150\n\n\n\n\n\n\n\n\n\n\nHouse.Style1Story\n\n\n11,722.86000*** (4,828.52700, 18,617.19000)\n\n\n\n\n\n\nt = 3.33265\n\n\n\n\n\n\np = 0.00088\n\n\n\n\n\n\n\n\n\n\nHouse.Style2.5Fin\n\n\n-27,978.77000** (-55,135.97000, -821.58150)\n\n\n\n\n\n\nt = -2.01926\n\n\n\n\n\n\np = 0.04360\n\n\n\n\n\n\n\n\n\n\nHouse.Style2.5Unf\n\n\n-5,404.63300 (-21,315.42000, 10,506.16000)\n\n\n\n\n\n\nt = -0.66577\n\n\n\n\n\n\np = 0.50564\n\n\n\n\n\n\n\n\n\n\nHouse.Style2Story\n\n\n-7,450.43500** (-13,608.96000, -1,291.90800)\n\n\n\n\n\n\nt = -2.37112\n\n\n\n\n\n\np = 0.01783\n\n\n\n\n\n\n\n\n\n\nHouse.StyleSFoyer\n\n\n13,046.92000** (2,510.04300, 23,583.79000)\n\n\n\n\n\n\nt = 2.42686\n\n\n\n\n\n\np = 0.01532\n\n\n\n\n\n\n\n\n\n\nHouse.StyleSLvl\n\n\n3,711.62500 (-4,850.44600, 12,273.70000)\n\n\n\n\n\n\nt = 0.84964\n\n\n\n\n\n\np = 0.39564\n\n\n\n\n\n\n\n\n\n\nOverall.Qual\n\n\n13,476.23000*** (11,688.02000, 15,264.44000)\n\n\n\n\n\n\nt = 14.77061\n\n\n\n\n\n\np = 0.00000\n\n\n\n\n\n\n\n\n\n\nOverall.Cond\n\n\n5,166.65000*** (3,701.26600, 6,632.03400)\n\n\n\n\n\n\nt = 6.91044\n\n\n\n\n\n\np = 0.00000\n\n\n\n\n\n\n\n\n\n\nYear.Built\n\n\n373.42820*** (248.86100, 497.99550)\n\n\n\n\n\n\nt = 5.87559\n\n\n\n\n\n\np = 0.00000\n\n\n\n\n\n\n\n\n\n\nYear.Remod.Add\n\n\n97.81441* (-2.31705, 197.94590)\n\n\n\n\n\n\nt = 1.91461\n\n\n\n\n\n\np = 0.05569\n\n\n\n\n\n\n\n\n\n\nFoundationCBlock\n\n\n-2,616.14400 (-8,575.75300, 3,343.46500)\n\n\n\n\n\n\nt = -0.86038\n\n\n\n\n\n\np = 0.38969\n\n\n\n\n\n\n\n\n\n\nFoundationPConc\n\n\n4,500.01300 (-2,149.97000, 11,150.00000)\n\n\n\n\n\n\nt = 1.32630\n\n\n\n\n\n\np = 0.18490\n\n\n\n\n\n\n\n\n\n\nFoundationSlab\n\n\n1,620.10900 (-12,437.13000, 15,677.35000)\n\n\n\n\n\n\nt = 0.22589\n\n\n\n\n\n\np = 0.82132\n\n\n\n\n\n\n\n\n\n\nFoundationStone\n\n\n8,033.56600 (-12,084.04000, 28,151.17000)\n\n\n\n\n\n\nt = 0.78267\n\n\n\n\n\n\np = 0.43392\n\n\n\n\n\n\n\n\n\n\nFoundationWood\n\n\n-15,525.36000 (-45,800.65000, 14,749.93000)\n\n\n\n\n\n\nt = -1.00508\n\n\n\n\n\n\np = 0.31499\n\n\n\n\n\n\n\n\n\n\nBsmt.Unf.SF\n\n\n5.37722 (-1.28092, 12.03537)\n\n\n\n\n\n\nt = 1.58290\n\n\n\n\n\n\np = 0.11361\n\n\n\n\n\n\n\n\n\n\nBaseLivArea\n\n\n25.56636*** (19.11498, 32.01775)\n\n\n\n\n\n\nt = 7.76719\n\n\n\n\n\n\np = 0.00000\n\n\n\n\n\n\n\n\n\n\nX2nd.Flr.SF\n\n\n12.75196** (2.11889, 23.38504)\n\n\n\n\n\n\nt = 2.35053\n\n\n\n\n\n\np = 0.01885\n\n\n\n\n\n\n\n\n\n\nGr.Liv.Area\n\n\n41.53372*** (33.28478, 49.78267)\n\n\n\n\n\n\nt = 9.86849\n\n\n\n\n\n\np = 0.00000\n\n\n\n\n\n\n\n\n\n\nFull.Bath\n\n\n6,028.74500*** (1,999.69500, 10,057.79000)\n\n\n\n\n\n\nt = 2.93273\n\n\n\n\n\n\np = 0.00340\n\n\n\n\n\n\n\n\n\n\nHalf.Bath\n\n\n2,826.39400 (-1,090.75800, 6,743.54700)\n\n\n\n\n\n\nt = 1.41420\n\n\n\n\n\n\np = 0.15747\n\n\n\n\n\n\n\n\n\n\nBedroom.AbvGr\n\n\n-3,959.60400*** (-6,466.27700, -1,452.93000)\n\n\n\n\n\n\nt = -3.09601\n\n\n\n\n\n\np = 0.00199\n\n\n\n\n\n\n\n\n\n\nKitchen.AbvGr\n\n\n-13,962.13000** (-25,470.64000, -2,453.61500)\n\n\n\n\n\n\nt = -2.37783\n\n\n\n\n\n\np = 0.01751\n\n\n\n\n\n\n\n\n\n\nTotRms.AbvGrd\n\n\n2,363.35600*** (586.58330, 4,140.12900)\n\n\n\n\n\n\nt = 2.60703\n\n\n\n\n\n\np = 0.00921\n\n\n\n\n\n\n\n\n\n\nFireplaces\n\n\n5,213.14800*** (2,644.78400, 7,781.51300)\n\n\n\n\n\n\nt = 3.97825\n\n\n\n\n\n\np = 0.00008\n\n\n\n\n\n\n\n\n\n\nGarage.Area\n\n\n21.43800*** (12.95246, 29.92354)\n\n\n\n\n\n\nt = 4.95168\n\n\n\n\n\n\np = 0.000001\n\n\n\n\n\n\n\n\n\n\nX3Ssn.Porch\n\n\n49.54326 (-10.19677, 109.28330)\n\n\n\n\n\n\nt = 1.62543\n\n\n\n\n\n\np = 0.10424\n\n\n\n\n\n\n\n\n\n\nScreen.Porch\n\n\n59.53482*** (36.20862, 82.86101)\n\n\n\n\n\n\nt = 5.00236\n\n\n\n\n\n\np = 0.000001\n\n\n\n\n\n\n\n\n\n\nSale.ConditionAdjLand\n\n\n3,777.04400 (-18,825.20000, 26,379.29000)\n\n\n\n\n\n\nt = 0.32753\n\n\n\n\n\n\np = 0.74331\n\n\n\n\n\n\n\n\n\n\nSale.ConditionAlloca\n\n\n1,632.42900 (-13,542.48000, 16,807.34000)\n\n\n\n\n\n\nt = 0.21084\n\n\n\n\n\n\np = 0.83304\n\n\n\n\n\n\n\n\n\n\nSale.ConditionFamily\n\n\n6,853.62800 (-5,018.08700, 18,725.34000)\n\n\n\n\n\n\nt = 1.13150\n\n\n\n\n\n\np = 0.25799\n\n\n\n\n\n\n\n\n\n\nSale.ConditionNormal\n\n\n6,389.47000** (936.73780, 11,842.20000)\n\n\n\n\n\n\nt = 2.29667\n\n\n\n\n\n\np = 0.02175\n\n\n\n\n\n\n\n\n\n\nSale.ConditionPartial\n\n\n23,977.05000*** (16,433.02000, 31,521.08000)\n\n\n\n\n\n\nt = 6.22932\n\n\n\n\n\n\np = 0.00000\n\n\n\n\n\n\n\n\n\n\nConstant\n\n\n-961,415.00000*** (-1,232,806.00000, -690,023.50000)\n\n\n\n\n\n\nt = -6.94325\n\n\n\n\n\n\np = 0.00000\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservations\n\n\n2,051\n\n\n\n\nR2\n\n\n0.86705\n\n\n\n\nAdjusted R2\n\n\n0.86193\n\n\n\n\nResidual Std. Error\n\n\n29,329.89000 (df = 1974)\n\n\n\n\nF Statistic\n\n\n169.38410*** (df = 76; 1974)\n\n\n\n\n\n\n\n\nNote:\n\n\np&lt;0.1; p&lt;0.05; p&lt;0.01\n\n\n\n\n\n\n6.3.3 Best Subset Selection:\n\nProcedure: Considers all possible combinations of predictors and fits a model for each combination.\nSelection Criteria: The “best” model is selected based on a criterion like RSS, Akaike information criterion (AIC), Bayesian information criterion (BIC), or adjusted R-squared.\nAdvantages: Can find the optimal model based on the selected criterion.\nDisadvantages: Computationally intensive, especially as the number of predictors grows. For example, with p predictors, there are 2^p possible models to evaluate. For this reason, it’s often not feasible for datasets with many predictors. For this dataset, I am keeping the maximum number of variables in the model to be 34, seven variables less than the entire dataset. Adjusting this number in the code below will make selecting max variables in the model easy.\n\n\n# Load necessary libraries\nlibrary(leaps)\nlibrary(tidyverse)\n\n# Perform best subset selection\n# best_subsets &lt;- regsubsets(SalePrice ~ Order + Lot.Frontage + Lot.Area + Lot.Shape + Utilities + Lot.Config + Land.Slope + Neighborhood + Bldg.Type + House.Style + \n#                            Overall.Qual + Overall.Cond + Year.Built + Year.Remod.Add + Foundation + Bsmt.Unf.SF + Total.Bsmt.SF + BaseLivArea + Central.Air + X1st.Flr.SF + X2nd.Flr.SF + Gr.Liv.Area + Full.Bath + \n#                            Half.Bath + Bathrooms + Bedroom.AbvGr + Kitchen.AbvGr + \n#        TotRms.AbvGrd + Fireplaces + Garage.Type + Garage.Area + Wood.Deck.SF + Open.Porch.SF + Enclosed.Porch + X3Ssn.Porch + Screen.Porch + Mo.Sold + Yr.Sold + Sale.Condition, \n#                            data=train_data, nvmax=ncol(train_data)-7,really.big=T)\n\n# # Extracting the summary\n# best_subsets_summary &lt;- summary(best_subsets)\n\n# # Displaying the best model for each number of predictors based on RSS (or adjust for other criteria)\n# data.frame(\n#   predictors = 1:(ncol(train_set)-1),\n#   adjr2 = best_subsets_summary$adjr2,\n#   rss = best_subsets_summary$rss,\n#   cp = best_subsets_summary$cp,\n#   bic = best_subsets_summary$bic\n# ) %&gt;% \n#   arrange(desc(adjr2)) %&gt;% \n#   head(1)\n\n# # Identify the best model size based on highest adjusted R-squared\n# best_model_size &lt;- which.min(best_subsets_summary$bic)\n\n# # Extract the variables included in the best model\n# best_model_vars &lt;- names(which(summary_results$which[best_model_size, ]))\n\n# # Construct the formula\n# best_formula &lt;- as.formula(paste(\"y ~\", paste(best_model_vars[-1], collapse = \" + \")))\n\n# print(best_formula)\n\nIn practice, the choice of method depends on: - The number of predictors (with many predictors, the best subset becomes computationally infeasible). - The primary goal (prediction accuracy vs. interpretability). - Computational resources.\nWhile best subset selection can find the most optimal model, forward and backward selection are often preferred due to their computational efficiency and the ability to produce more straightforward, more interpretable models.\nWe need to consider a selection criterion to compare the best models from forward, backward, and best subset selection methods. The AIC (Akaike Information Criterion) is a commonly used criterion that penalizes the addition of unnecessary predictors to a model. A lower AIC suggests a better-fitting model. Another criterion you could use is the adjusted R^2, which adjusts R^2 based on the number of predictors in the model. A higher adjusted R^2 suggests a better-fitting model.\nLet’s Extract the best models from all the procedures.\n\nlibrary(MASS)\nlibrary(leaps)\n\n# Forward Selection\nforward_aic &lt;- AIC(forward_selected_model)\n\n# Backward Selection\nbackward_aic &lt;- AIC(backward_selected_model)\n\n# Best Subset Selection\n\n# best_model_size &lt;- which.min(best_subset_summary$cp) # Replace cp with bic or adjr2 as needed\n# best_formula &lt;- as.formula(best_subsets$call[[2]][[2]][[best_model_size]])\n# best_subset_selected_model &lt;- lm(best_formula, data=train_data)\n# best_subset_aic &lt;- AIC(best_subset_selected_model)\n\n# Comparing AIC values to identify the best model\n# aic_values &lt;- c(Forward=forward_aic, Backward=backward_aic, BestSubset=best_subset_aic)\naic_values &lt;- c(Forward=forward_aic, Backward=backward_aic)\nbest_method &lt;- names(which.min(aic_values))\n\nThe best model selection method based on AIC is Forward"
  },
  {
    "objectID": "M2/M2LN1.html#visualizations",
    "href": "M2/M2LN1.html#visualizations",
    "title": "Multiple Linear Regression",
    "section": "7.1 Visualizations",
    "text": "7.1 Visualizations\n\nlibrary(ggplot2)\n\n# Plotting actual vs. predicted values\np &lt;- ggplot(comparison, aes(x=Actual, y=Predicted)) +\n  geom_point(aes(color = abs(Actual - Predicted)), size = 3, alpha = 0.7) +  # Color points by residual magnitude\n  geom_abline(intercept=0, slope=1, linetype=\"dashed\", color=\"red\") +        # Line of perfect prediction\n  scale_color_viridis_c(option = \"E\", direction = -1) + \n  labs(\n    title = \"Actual vs Predicted SalePrice\",\n    x = \"Actual SalePrice\",\n    y = \"Predicted SalePrice\",\n    color = \"Residual Magnitude\"\n  ) +\n  theme_minimal()\np\n\n\n\n\n\n\n\n# full_lm_model &lt;- lm(cnt ~ .-causal-registerd, data = train_data)"
  },
  {
    "objectID": "M2/M2LN1.html#causal",
    "href": "M2/M2LN1.html#causal",
    "title": "Multiple Linear Regression",
    "section": "8.1 Causal",
    "text": "8.1 Causal\n\n\\begin{align}\nln(y) &= \\beta_{0}+\\beta_{1}x_{1}+\\beta_{2}x_{2} \\implies y= e^{\\beta_{0}+\\beta_{1}x_{1}+\\beta_{2}x_{2}}\\\\\n\\sqrt{y} &=\\beta_{0}+\\beta_{1}x_{1}+\\beta_{2}x_{2}\\implies y = (\\beta_{0}+\\beta_{1}x_{1}+\\beta_{2}x_{2})^2== b_0^2+b_1^2+2*b1b2\\\\\n\\sqrt[3]{y} &=\\beta_{0}+\\beta_{1}x_{1}+\\beta_{2}x_{2}\\\\\ncnt &= 161.807 +85.5765 *temp + 314.3430 *atemp - 275.1803 *hum+ 43.000* windspeed\\\\\nlog(cnt) &= 1.9205 +    0.043330139 *temp + 1.287265532 *atemp - 0.979846625 *hum+ * windspeed\\\\\nthen\\; my\\; Y\\; is\n\\end{align}\n\nIntercept 1.92058028 temp 0.043330139 atemp 1.287265532 hum -0.979846625 windspeed 0.246232091"
  },
  {
    "objectID": "M2/M2LN2.html",
    "href": "M2/M2LN2.html",
    "title": "Multiple Linear Regression",
    "section": "",
    "text": "library(gdata)\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(corrplot)\nlibrary(kableExtra)\nlibrary(flextable)\nlibrary(tidyverse)\nlibrary(stringr)\nlibrary(lubridate)\nlibrary(scales)\nlibrary(graphics)\nlibrary(caret)\nlibrary(psych)\nlibrary(ggcorrplot)\nlibrary(PerformanceAnalytics)"
  },
  {
    "objectID": "M2/M2LN2.html#using-standard-psych-package",
    "href": "M2/M2LN2.html#using-standard-psych-package",
    "title": "Multiple Linear Regression",
    "section": "3.1 Using Standard Psych Package",
    "text": "3.1 Using Standard Psych Package\n\nlibrary(psych)\npairs.panels(redDF)\n\n\n\n\nPairs plot of red wine dataset with psych"
  },
  {
    "objectID": "M2/M2LN2.html#using-ggalley-package",
    "href": "M2/M2LN2.html#using-ggalley-package",
    "title": "Multiple Linear Regression",
    "section": "3.2 Using GGalley Package",
    "text": "3.2 Using GGalley Package\n\nlibrary(GGally)\nggpairs(redDF, columns = c(\"fixed.acidity\", \"volatile.acidity\", \"citric.acid\", \"residual.sugar\", \"chlorides\", \"free.sulfur.dioxide\", \"total.sulfur.dioxide\", \"density\", \"pH\", \"sulphates\", \"alcohol\"),\n        aes(color = as.factor(quality), alpha = 0.5),\n        upper = list(continuous = wrap(\"cor\", size = 2.5)))+ scale_colour_brewer(palette = \"Set3\",type = 'div',direction = 1)\n\n\n\n\nPairs plot of red wine dataset with GGally"
  },
  {
    "objectID": "M2/M2LN2.html#correlation-matrix-with-ggcorrplot-package",
    "href": "M2/M2LN2.html#correlation-matrix-with-ggcorrplot-package",
    "title": "Multiple Linear Regression",
    "section": "3.3 Correlation Matrix with GGcorrplot Package",
    "text": "3.3 Correlation Matrix with GGcorrplot Package\n\nggcorrplot(redDF %&gt;% cor(),\n  hc.order = TRUE, type = \"lower\",\n  lab = TRUE,\n  digits = 2,\n  ggtheme = ggplot2::theme_light(),\n)\n\n\n\n\nCorrelation plot of red wine dataset"
  },
  {
    "objectID": "M2/M2LN2.html#correlation-matrix-with-base-package",
    "href": "M2/M2LN2.html#correlation-matrix-with-base-package",
    "title": "Multiple Linear Regression",
    "section": "3.4 Correlation Matrix with base Package",
    "text": "3.4 Correlation Matrix with base Package\n\nchart.Correlation(redDF, hist = T)\n\n\n\n\nCorrelation plot of red wine dataset basic"
  },
  {
    "objectID": "M2/M2LN2.html#target-variable-distribution",
    "href": "M2/M2LN2.html#target-variable-distribution",
    "title": "Multiple Linear Regression",
    "section": "3.5 Target variable distribution",
    "text": "3.5 Target variable distribution\n\nsummary(redDF$quality)\n\n#&gt;    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n#&gt;   3.000   5.000   6.000   5.636   6.000   8.000\n\n\n\nfeqtab &lt;- as_flextable(table(redDF$quality))\nfeqtab\nFrequency table of qualityVar1CountPercent3100.6%4533.3%568142.6%663839.9%719912.4%8181.1%Total1,599100.0%\n\nThe dependent variable seems ordinal; hence, linear regression is unsuitable for this problem.\n\n3.5.1 Correlation Values\nStrong correlation values &gt;0.60 between some variables. We’ll verify this again in the assumptions section."
  },
  {
    "objectID": "M2/M2LN2.html#data-preparation",
    "href": "M2/M2LN2.html#data-preparation",
    "title": "Multiple Linear Regression",
    "section": "3.6 Data Preparation",
    "text": "3.6 Data Preparation\n\n3.6.1 Checking for Missing Values\n\nredDF %&gt;% is.na() %&gt;% colSums()\n\n#&gt;        fixed.acidity     volatile.acidity          citric.acid \n#&gt;                    0                    0                    0 \n#&gt;       residual.sugar            chlorides  free.sulfur.dioxide \n#&gt;                    0                    0                    0 \n#&gt; total.sulfur.dioxide              density                   pH \n#&gt;                    0                    0                    0 \n#&gt;            sulphates              alcohol              quality \n#&gt;                    0                    0                    0\n\n\nI am using the naniar package to check for missing values and plot them.\n\n# Load the required libraries\nlibrary(naniar)\n\n# Create a missing value plot\nvis_miss(redDF)\n\n\n\n\nMissing value plot of red wine dataset\n\n\n\n\n\n\n3.6.2 Checking for Outliers\nLet’s perform an outlier analysis using the boxplot function. This will output the outlier numbers and will provide the boxplot for each variable.\n\n# Specify the variable for which you want to find outliers\nvariable_of_interest &lt;- redDF$fixed.acidity\n\n# Calculate the boxplot statistics\nboxplot_stats &lt;- boxplot.stats(variable_of_interest)\n\n# Get the indexes of outliers\noutlier_indexes &lt;- which(variable_of_interest %in% boxplot_stats$out)\n\nHere are the outlier indexes: 206, 207, 244, 245, 265, 295, 329, 339, 340, 348, 354, 360, 364, 365, 367, 375, 382, 392, 395, 410, 430, 441, 443, 447, 471, 473, 510, 511, 517, 539, 545, 549, 555, 556, 558, 560, 561, 565, 566, 597, 600, 602, 604, 612, 653, 681, 812, 815, 1225\n\n# Load the required libraries\nlibrary(reshape2)\n\nmelted_data &lt;- reshape2::melt(redDF, id.vars = 'quality')\n\n# Create a grouped box plot\nggplot(melted_data, aes(x = variable, y = value)) +\n  geom_boxplot(aes(fill = as.factor(quality))) +\n  labs(title = \"Grouped Box Plot of Variables vs. Quality\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n  xlab(\"Variable\")\n\n\n\n\nOutlier plot of red wine dataset\n\n\n\n\n\n\n3.6.3 Train/test Split\n\nset.seed(1)\nsampleSize &lt;- round(nrow(redDF)*0.8)\nidx &lt;- sample(seq_len(sampleSize), size = sampleSize)\n\nX.train_red &lt;- redDF[idx,]\nX.test_red &lt;- redDF[-idx,]\n# X.test_red.y &lt;- X.test_red\n# X.test_red &lt;- subset(X.test_red, select = -c(quality) )\n\nrownames(X.train_red) &lt;- NULL\nrownames(X.test_red) &lt;- NULL"
  },
  {
    "objectID": "M2/M2LN2.html#building-the-initial-model",
    "href": "M2/M2LN2.html#building-the-initial-model",
    "title": "Multiple Linear Regression",
    "section": "4.1 Building the Initial Model",
    "text": "4.1 Building the Initial Model\nWe won’t consider ‘residual sugar’ for our analysis.\n\nmodel_red1 &lt;- lm(quality ~ fixed.acidity + volatile.acidity + citric.acid + chlorides + free.sulfur.dioxide + \n                   total.sulfur.dioxide + density + pH + sulphates + alcohol, \n                 data = X.train_red)\nstargazer::stargazer(model_red1, type = \"html\", out = \"regression.html\" ,title = \"Simple Linear Model\", ci=TRUE, single.row = FALSE, no.space = FALSE, align = TRUE, digits=3, font.size = \"small\",  report = \"vc*stp\")\n\n\nSimple Linear Model\n\n\n\n\n\n\n\n\n\nDependent variable:\n\n\n\n\n\n\n\n\n\n\n\n\nquality\n\n\n\n\n\n\n\n\nfixed.acidity\n\n\n0.015\n\n\n\n\n\n\n(-0.037, 0.068)\n\n\n\n\n\n\nt = 0.574\n\n\n\n\n\n\np = 0.567\n\n\n\n\n\n\n\n\n\n\nvolatile.acidity\n\n\n-1.057***\n\n\n\n\n\n\n(-1.323, -0.790)\n\n\n\n\n\n\nt = -7.780\n\n\n\n\n\n\np = 0.000\n\n\n\n\n\n\n\n\n\n\ncitric.acid\n\n\n-0.177\n\n\n\n\n\n\n(-0.502, 0.147)\n\n\n\n\n\n\nt = -1.070\n\n\n\n\n\n\np = 0.285\n\n\n\n\n\n\n\n\n\n\nchlorides\n\n\n-1.779***\n\n\n\n\n\n\n(-2.686, -0.872)\n\n\n\n\n\n\nt = -3.845\n\n\n\n\n\n\np = 0.0002\n\n\n\n\n\n\n\n\n\n\nfree.sulfur.dioxide\n\n\n0.003\n\n\n\n\n\n\n(-0.001, 0.008)\n\n\n\n\n\n\nt = 1.368\n\n\n\n\n\n\np = 0.172\n\n\n\n\n\n\n\n\n\n\ntotal.sulfur.dioxide\n\n\n-0.004***\n\n\n\n\n\n\n(-0.005, -0.002)\n\n\n\n\n\n\nt = -4.444\n\n\n\n\n\n\np = 0.00001\n\n\n\n\n\n\n\n\n\n\ndensity\n\n\n-11.025\n\n\n\n\n\n\n(-49.319, 27.269)\n\n\n\n\n\n\nt = -0.564\n\n\n\n\n\n\np = 0.573\n\n\n\n\n\n\n\n\n\n\npH\n\n\n-0.383*\n\n\n\n\n\n\n(-0.777, 0.010)\n\n\n\n\n\n\nt = -1.908\n\n\n\n\n\n\np = 0.057\n\n\n\n\n\n\n\n\n\n\nsulphates\n\n\n0.794***\n\n\n\n\n\n\n(0.556, 1.033)\n\n\n\n\n\n\nt = 6.527\n\n\n\n\n\n\np = 0.000\n\n\n\n\n\n\n\n\n\n\nalcohol\n\n\n0.292***\n\n\n\n\n\n\n(0.244, 0.341)\n\n\n\n\n\n\nt = 11.878\n\n\n\n\n\n\np = 0.000\n\n\n\n\n\n\n\n\n\n\nConstant\n\n\n15.096\n\n\n\n\n\n\n(-22.377, 52.569)\n\n\n\n\n\n\nt = 0.790\n\n\n\n\n\n\np = 0.430\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservations\n\n\n1,279\n\n\n\n\nR2\n\n\n0.369\n\n\n\n\nAdjusted R2\n\n\n0.364\n\n\n\n\nResidual Std. Error\n\n\n0.648 (df = 1268)\n\n\n\n\nF Statistic\n\n\n74.295*** (df = 10; 1268)\n\n\n\n\n\n\n\n\nNote:\n\n\np&lt;0.1; p&lt;0.05; p&lt;0.01"
  },
  {
    "objectID": "M2/M2LN2.html#model-assumptions",
    "href": "M2/M2LN2.html#model-assumptions",
    "title": "Multiple Linear Regression",
    "section": "4.2 Model Assumptions",
    "text": "4.2 Model Assumptions\n\n4.2.1 Checking Normality of Residuals\n\nCheckNormal &lt;- function(model) {\n  hist(model$residuals, breaks = 30)\n  shaptest &lt;- shapiro.test(model$residuals)\n  print(shaptest)\n  if (shaptest$p.value &lt;= 0.05) {\n    print(\"H0 rejected: the residuals are NOT distributed normally\")\n  } else {\n    print(\"H0 failed to reject: the residuals ARE distributed normally\")\n  }\n}\nCheckNormal(model = model_red1)\n\n\n\n\n\n\n\n\n#&gt; \n#&gt;  Shapiro-Wilk normality test\n#&gt; \n#&gt; data:  model$residuals\n#&gt; W = 0.9897, p-value = 7.95e-08\n#&gt; \n#&gt; [1] \"H0 rejected: the residuals are NOT distributed normally\"\n\n\n\n\n4.2.2 Checking Homoscedasticity\n\nlibrary(lmtest)\nCheckHomos &lt;- function(model){\n  plot(model$fitted.values, model$residuals)\n  abline(h = 0, col = \"red\")\n  BP &lt;- bptest(model)\n  print(BP)\n  if (BP$p.value &lt;= 0.05) {\n    print(\"H0 rejected: Error variance spreads INCONSTANTLY/generating patterns (Heteroscedasticity)\")\n  } else {\n    print(\"H0 failed to reject: Error variance spreads CONSTANTLY (Homoscedasticity)\")\n  }\n}\nCheckHomos(model = model_red1)\n\n\n\n\n\n\n\n\n#&gt; \n#&gt;  studentized Breusch-Pagan test\n#&gt; \n#&gt; data:  model\n#&gt; BP = 56.615, df = 10, p-value = 1.575e-08\n#&gt; \n#&gt; [1] \"H0 rejected: Error variance spreads INCONSTANTLY/generating patterns (Heteroscedasticity)\"\n\n\n\n\n4.2.3 Checking Multicollinearity\n\nlibrary(car)\nvif(model_red1) %&gt;% kbl()\n\n\n\n\n\nx\n\n\n\n\nfixed.acidity\n6.935469\n\n\nvolatile.acidity\n1.779712\n\n\ncitric.acid\n3.229450\n\n\nchlorides\n1.497186\n\n\nfree.sulfur.dioxide\n1.996028\n\n\ntotal.sulfur.dioxide\n2.312040\n\n\ndensity\n4.168414\n\n\npH\n2.962262\n\n\nsulphates\n1.368089\n\n\nalcohol\n2.218354"
  },
  {
    "objectID": "M2/M2LN2.html#model-improvements",
    "href": "M2/M2LN2.html#model-improvements",
    "title": "Multiple Linear Regression",
    "section": "4.3 Model Improvements",
    "text": "4.3 Model Improvements\n\n4.3.1 Outlier Diagnosis\n\npar(mfrow=c(2,2))\nlapply(c(1,2,4,5), \n       function(x) plot(model_red1, \n                        which = x,\n                        cook.levels = c(0.05, 0.1))) %&gt;% invisible()\n\n\n\n\n\n\n\n\n\n\n4.3.2 Removing Influential Observations and Model Rerun\n\nto.rm &lt;- c(78,202,245,274,1161)\nX.train_red &lt;- X.train_red[-to.rm,]\nrownames(X.train_red) &lt;- NULL\nmodel_red2 &lt;- lm(quality ~ fixed.acidity + volatile.acidity + citric.acid + chlorides + \n                   free.sulfur.dioxide + total.sulfur.dioxide + density + pH + sulphates + alcohol, \n                 data = X.train_red)\n\nstargazer::stargazer(model_red1,model_red2, type = \"html\" ,title = \"Regression Models for Red Wine Dataset\", ci=TRUE, single.row = FALSE, no.space = FALSE, align = TRUE, digits=5, font.size = \"small\",  report = \"vc*stp\")\n\n\nRegression Models for Red Wine Dataset\n\n\n\n\n\n\n\n\n\nDependent variable:\n\n\n\n\n\n\n\n\n\n\n\n\nquality\n\n\n\n\n\n\n(1)\n\n\n(2)\n\n\n\n\n\n\n\n\nfixed.acidity\n\n\n0.01547\n\n\n0.02520\n\n\n\n\n\n\n(-0.03738, 0.06832)\n\n\n(-0.02735, 0.07775)\n\n\n\n\n\n\nt = 0.57368\n\n\nt = 0.93974\n\n\n\n\n\n\np = 0.56629\n\n\np = 0.34753\n\n\n\n\n\n\n\n\n\n\n\n\nvolatile.acidity\n\n\n-1.05662***\n\n\n-1.03840***\n\n\n\n\n\n\n(-1.32279, -0.79045)\n\n\n(-1.29974, -0.77706)\n\n\n\n\n\n\nt = -7.78041\n\n\nt = -7.78777\n\n\n\n\n\n\np = 0.00000\n\n\np = 0.00000\n\n\n\n\n\n\n\n\n\n\n\n\ncitric.acid\n\n\n-0.17735\n\n\n-0.20137\n\n\n\n\n\n\n(-0.50207, 0.14737)\n\n\n(-0.52188, 0.11914)\n\n\n\n\n\n\nt = -1.07045\n\n\nt = -1.23139\n\n\n\n\n\n\np = 0.28463\n\n\np = 0.21841\n\n\n\n\n\n\n\n\n\n\n\n\nchlorides\n\n\n-1.77905***\n\n\n-1.49611***\n\n\n\n\n\n\n(-2.68588, -0.87222)\n\n\n(-2.40605, -0.58617)\n\n\n\n\n\n\nt = -3.84511\n\n\nt = -3.22253\n\n\n\n\n\n\np = 0.00013\n\n\np = 0.00131\n\n\n\n\n\n\n\n\n\n\n\n\nfree.sulfur.dioxide\n\n\n0.00339\n\n\n0.00391\n\n\n\n\n\n\n(-0.00147, 0.00825)\n\n\n(-0.00088, 0.00870)\n\n\n\n\n\n\nt = 1.36756\n\n\nt = 1.59961\n\n\n\n\n\n\np = 0.17170\n\n\np = 0.10994\n\n\n\n\n\n\n\n\n\n\n\n\ntotal.sulfur.dioxide\n\n\n-0.00364***\n\n\n-0.00355***\n\n\n\n\n\n\n(-0.00525, -0.00204)\n\n\n(-0.00514, -0.00196)\n\n\n\n\n\n\nt = -4.44442\n\n\nt = -4.38488\n\n\n\n\n\n\np = 0.00001\n\n\np = 0.00002\n\n\n\n\n\n\n\n\n\n\n\n\ndensity\n\n\n-11.02496\n\n\n-14.88229\n\n\n\n\n\n\n(-49.31898, 27.26907)\n\n\n(-52.51200, 22.74741)\n\n\n\n\n\n\nt = -0.56428\n\n\nt = -0.77515\n\n\n\n\n\n\np = 0.57267\n\n\np = 0.43840\n\n\n\n\n\n\n\n\n\n\n\n\npH\n\n\n-0.38348*\n\n\n-0.38371*\n\n\n\n\n\n\n(-0.77738, 0.01041)\n\n\n(-0.77262, 0.00521)\n\n\n\n\n\n\nt = -1.90814\n\n\nt = -1.93370\n\n\n\n\n\n\np = 0.05660\n\n\np = 0.05338\n\n\n\n\n\n\n\n\n\n\n\n\nsulphates\n\n\n0.79450***\n\n\n0.89072***\n\n\n\n\n\n\n(0.55593, 1.03307)\n\n\n(0.64894, 1.13249)\n\n\n\n\n\n\nt = 6.52710\n\n\nt = 7.22053\n\n\n\n\n\n\np = 0.00000\n\n\np = 0.00000\n\n\n\n\n\n\n\n\n\n\n\n\nalcohol\n\n\n0.29243***\n\n\n0.29981***\n\n\n\n\n\n\n(0.24418, 0.34069)\n\n\n(0.25229, 0.34733)\n\n\n\n\n\n\nt = 11.87815\n\n\nt = 12.36589\n\n\n\n\n\n\np = 0.00000\n\n\np = 0.00000\n\n\n\n\n\n\n\n\n\n\n\n\nConstant\n\n\n15.09573\n\n\n18.68649\n\n\n\n\n\n\n(-22.37738, 52.56883)\n\n\n(-18.12650, 55.49948)\n\n\n\n\n\n\nt = 0.78956\n\n\nt = 0.99489\n\n\n\n\n\n\np = 0.42994\n\n\np = 0.31999\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservations\n\n\n1,279\n\n\n1,274\n\n\n\n\nR2\n\n\n0.36945\n\n\n0.38754\n\n\n\n\nAdjusted R2\n\n\n0.36448\n\n\n0.38269\n\n\n\n\nResidual Std. Error\n\n\n0.64763 (df = 1268)\n\n\n0.63437 (df = 1263)\n\n\n\n\nF Statistic\n\n\n74.29508*** (df = 10; 1268)\n\n\n79.91719*** (df = 10; 1263)\n\n\n\n\n\n\n\n\nNote:\n\n\np&lt;0.1; p&lt;0.05; p&lt;0.01\n\n\n\n\n\n\n4.3.3 Model Comparison\n\nad.r.sq1 &lt;- summary(model_red1)$adj.r.squared\nad.r.sq2 &lt;- summary(model_red2)$adj.r.squared\n\nAdjusted R-squared for 1st and the second models are 0.3644797 and 0.3826897, respectively. The difference between both is 1.821%."
  },
  {
    "objectID": "M2/M2LN2.html#use-stepwise-algorithm-forward-backward-and-step-wise",
    "href": "M2/M2LN2.html#use-stepwise-algorithm-forward-backward-and-step-wise",
    "title": "Multiple Linear Regression",
    "section": "5.1 Use stepwise algorithm: Forward, Backward and Step-wise",
    "text": "5.1 Use stepwise algorithm: Forward, Backward and Step-wise\nFirst, let’s define the start and stop thresholds for the algorithm. We will also use the regsubset function from the leaps package to perform the stepwise regression.\n\nmodel_redAlc &lt;- lm(quality ~ alcohol, data = X.train_red)\nmodel_redAll &lt;- lm(quality ~ ., data = X.train_red)\n\n\n5.1.1 Backward Approach\n\n5.1.1.1 Variable Selection Sequence\nThe variable selection dataframe below will show which variables were forced in and/or forced out for the backward approach.\n\nOLS.regback &lt;- leaps::regsubsets(quality ~ ., X.train_red,\n    method = \"backward\", nvmax = 11)\nOLSregbacksum &lt;- summary(OLS.regback)\nVarselect &lt;- data.frame(Forcein = OLSregbacksum$obj$force.in,\n    Forceout = OLSregbacksum$obj$force.out)\n\nVarselect %&gt;%\n    kbl() %&gt;%\n    kable_styling(bootstrap_options = \"striped\", full_width = F,\n        position = \"center\", font_size = 9)\n\n\n\n\n\nForcein\nForceout\n\n\n\n\n\nTRUE\nFALSE\n\n\nfixed.acidity\nFALSE\nFALSE\n\n\nvolatile.acidity\nFALSE\nFALSE\n\n\ncitric.acid\nFALSE\nFALSE\n\n\nresidual.sugar\nFALSE\nFALSE\n\n\nchlorides\nFALSE\nFALSE\n\n\nfree.sulfur.dioxide\nFALSE\nFALSE\n\n\ntotal.sulfur.dioxide\nFALSE\nFALSE\n\n\ndensity\nFALSE\nFALSE\n\n\npH\nFALSE\nFALSE\n\n\nsulphates\nFALSE\nFALSE\n\n\nalcohol\nFALSE\nFALSE\n\n\n\n\n\n\n\n5.1.1.2 Model Output Matrix\nWe also need to see the variables included in each model. The table below will show that model 1 only includes alcohol while model 2 includes volatile.acidity and alcohol.\n\nexhselect &lt;- data.frame(OLSregbacksum$outmat)\nexhselect %&gt;%\n    kbl() %&gt;%\n    kable_styling(bootstrap_options = \"striped\", full_width = F,\n        position = \"center\", font_size = 9)\n\n\n\n\n\nfixed.acidity\nvolatile.acidity\ncitric.acid\nresidual.sugar\nchlorides\nfree.sulfur.dioxide\ntotal.sulfur.dioxide\ndensity\npH\nsulphates\nalcohol\n\n\n\n\n1 ( 1 )\n\n\n\n\n\n\n\n\n\n\n*\n\n\n2 ( 1 )\n\n*\n\n\n\n\n\n\n\n\n*\n\n\n3 ( 1 )\n\n*\n\n\n\n\n\n\n\n*\n*\n\n\n4 ( 1 )\n\n*\n\n\n\n\n*\n\n\n*\n*\n\n\n5 ( 1 )\n\n*\n\n\n*\n\n*\n\n\n*\n*\n\n\n6 ( 1 )\n\n*\n\n\n*\n\n*\n\n*\n*\n*\n\n\n7 ( 1 )\n\n*\n\n\n*\n*\n*\n\n*\n*\n*\n\n\n8 ( 1 )\n\n*\n\n\n*\n*\n*\n*\n*\n*\n*\n\n\n9 ( 1 )\n\n*\n\n*\n*\n*\n*\n*\n*\n*\n*\n\n\n10 ( 1 )\n*\n*\n\n*\n*\n*\n*\n*\n*\n*\n*\n\n\n11 ( 1 )\n*\n*\n*\n*\n*\n*\n*\n*\n*\n*\n*\n\n\n\n\n\nNow, let’s look at the detailed model measurement metrics, including The R^2, Adjusted-R^2, Mellow’s Cp, AIC, and BIC. These can be directly extracted from the OLS regression summary we have created in the first step.\n\n\n5.1.1.3 R^2\n\nrsqmat &lt;- data.frame(t(OLSregbacksum$rsq))\nrsqmat %&gt;%\n    kbl() %&gt;%\n    kable_styling(bootstrap_options = \"striped\", full_width = F,\n        position = \"center\", font_size = 9)\n\n\n\nX1\nX2\nX3\nX4\nX5\nX6\nX7\nX8\nX9\nX10\nX11\n\n\n\n\n0.2596942\n0.3406592\n0.3608397\n0.3743383\n0.3799897\n0.3847493\n0.3865018\n0.3866865\n0.3871627\n0.3876856\n0.3884823\n\n\n\n\n\n\n5.1.1.4 Adjusted R^2\n\nadjr2mat &lt;- data.frame(t(OLSregbacksum$adjr2))\nadjr2mat %&gt;%\n    kbl() %&gt;%\n    kable_styling(bootstrap_options = \"striped\", full_width = F,\n        position = \"center\", font_size = 9)\n\n\n\nX1\nX2\nX3\nX4\nX5\nX6\nX7\nX8\nX9\nX10\nX11\n\n\n\n\n0.2591122\n0.3396217\n0.3593299\n0.3723662\n0.3775448\n0.3818357\n0.3831096\n0.3828078\n0.3827992\n0.3828375\n0.3831521\n\n\n\n\n\n\n5.1.1.5 Mellow’s Cp\n\ncpmat &lt;- data.frame(t(OLSregbacksum$cp))\ncpmat %&gt;%\n    kbl() %&gt;%\n    kable_styling(bootstrap_options = \"striped\", full_width = F,\n        position = \"center\", font_size = 9)\n\n\n\nX1\nX2\nX3\nX4\nX5\nX6\nX7\nX8\nX9\nX10\nX11\n\n\n\n\n257.7822\n92.69342\n53.04641\n27.18921\n17.52635\n9.703904\n8.087153\n9.706003\n10.7232\n11.64424\n12\n\n\n\n\n\n\n5.1.1.6 Bayesian Information Criterion (BIC)\n\nbicmat &lt;- data.frame(t(OLSregbacksum$bic))\nbicmat %&gt;%\n    kbl() %&gt;%\n    kable_styling(bootstrap_options = \"striped\", full_width = F,\n        position = \"center\", font_size = 9)\n\n\n\nX1\nX2\nX3\nX4\nX5\nX6\nX7\nX8\nX9\nX10\nX11\n\n\n\n\n-368.7818\n-509.19\n-541.6428\n-561.6869\n-566.0969\n-568.7647\n-565.249\n-558.4827\n-552.3224\n-546.2598\n-540.7687\n\n\n\n\n\n\n5.1.1.7 Combining the Model Output Matrices\n\n# Combine the four data frames into one\ncombined_df &lt;- data.frame(\n  R2 = unlist(rsqmat),\n  Adj_R2 = unlist(adjr2mat),\n  Mellow_Cp = unlist(cpmat),\n  BIC = unlist(bicmat)\n)\n\n# Create a kable table with all the values\nkable(combined_df, format = \"html\", col.names = c(\"R-sq.\", \"Adj R-sq.\", \"Mellow's Cp\", \"BIC\")) %&gt;%\n  kable_styling(bootstrap_options = \"striped\", full_width = F, position = \"center\", font_size = 9)\n\n\n\n\n\nR-sq.\nAdj R-sq.\nMellow's Cp\nBIC\n\n\n\n\nX1\n0.2596942\n0.2591122\n257.782198\n-368.7818\n\n\nX2\n0.3406592\n0.3396217\n92.693417\n-509.1900\n\n\nX3\n0.3608397\n0.3593299\n53.046411\n-541.6428\n\n\nX4\n0.3743383\n0.3723662\n27.189213\n-561.6869\n\n\nX5\n0.3799897\n0.3775448\n17.526348\n-566.0969\n\n\nX6\n0.3847493\n0.3818357\n9.703904\n-568.7647\n\n\nX7\n0.3865018\n0.3831096\n8.087153\n-565.2490\n\n\nX8\n0.3866865\n0.3828078\n9.706003\n-558.4827\n\n\nX9\n0.3871627\n0.3827992\n10.723197\n-552.3224\n\n\nX10\n0.3876856\n0.3828375\n11.644237\n-546.2598\n\n\nX11\n0.3884823\n0.3831521\n12.000000\n-540.7687\n\n\n\n\n\n\n\n5.1.1.8 Diagnostic plots for the Backward Selection\n\npar(mfrow = c(2, 2))\nplot(OLSregbacksum$rss, xlab = \"Number of Variables\\n(a)\", ylab = \"RSS\",\n    type = \"l\", lwd = 1.5, cex.main = 1.15, cex.lab = 1, cex.axis = 1.05,\n    font.axis = 2, font.lab = 2, main = \"Number of Variables Vs. RSS\",\n    panel.first = grid(nx = NULL, ny = NULL, col = \"gray\", lty = 2))\n\nplot(OLSregbacksum$adjr2, xlab = \"Number of Variables\\n(b)\",\n    ylab = \"Adjusted RSq\", type = \"l\", lwd = 1.5, main = \"Number of Variables Vs. Adjusted R2\",\n    cex.main = 1.15, cex.lab = 1, cex.axis = 1.05, font.axis = 2,\n    font.lab = 2, panel.first = grid(nx = NULL, ny = NULL, col = \"gray\",\n        lty = 2))\npoints(6, OLSregbacksum$adjr2[6], col = \"#336699\", cex = 2, pch = 20)\n\nplot(OLSregbacksum$cp, xlab = \"Number of Variables\\n(c)\", ylab = \"Cp\",\n    type = \"l\", lwd = 1.5, cex.main = 1.15, cex.lab = 1, cex.axis = 1.05,\n    font.axis = 2, font.lab = 2, main = \"Number of Variables Vs. Mellow's Cp\",\n    panel.first = grid(nx = NULL, ny = NULL, col = \"gray\", lty = 2))\npoints(6, OLSregbacksum$cp[6], col = \"#336699\", cex = 2, pch = 20)\n\nplot(OLSregbacksum$bic, xlab = \"Number of Variables\\n(d)\", ylab = \"BIC\",\n    type = \"l\", lwd = 1.5, cex.main = 1.15, cex.lab = 1, cex.axis = 1.05,\n    font.axis = 2, font.lab = 2, main = \"Number of Variables Vs. BIC\",\n    panel.first = grid(nx = NULL, ny = NULL, col = \"gray\", lty = 2))\npoints(6, OLSregbacksum$bic[6], col = \"#336699\", cex = 2, pch = 20)\n\n\n\n\nBackward Selection Diagnostic Plots\n\n\n\n\n\n\n5.1.1.9 Best Model from Backward Selection\n\n# Find the model with the lowest BIC value\nbest_model_index &lt;- which.min(OLSregbacksum$bic)\n\n# Get the best model\nbest_model &lt;- coef(OLS.regback, id = best_model_index)\n\n# Extract the coefficients from the best model and remove the intercept term from the coefficients\nbest_coefficients &lt;- round(unname(best_model)[-1], 4)\n\n# Get the variable names from your redDF dataframe\nvariable_names &lt;- names(best_model)[-1]\n\n# Extract the intercept coefficient separately\nintercept_coefficient &lt;- round(unname(best_model)[1], 4)\n\n# Define the named_coefficients variable\nnamed_coefficients &lt;- setNames(best_coefficients, variable_names)\n\n# Create the LaTeX equation\nequation &lt;- paste(\"y =\", intercept_coefficient, \"+\", paste(named_coefficients, variable_names, sep = \" * \", collapse = \" + \"), \"\")\n\n$y = 3.9765 + -0.9888 * volatile.acidity + -1.6884 * chlorides + -0.0029 * total.sulfur.dioxide + -0.392 * pH + 0.8807 * sulphates + 0.3083 * alcohol $\n\n\n\n5.1.2 Forward Approach\nFollowing the leaps::regsubsets function, we will use the forward approach by changing method = \"backward\" to method = \"forward\" to select the best model. Make sure to change all OLS.regback to OLS.regfwd and related variables.\nCaution: Running all three subset selection methods in one file will result in longer run times/knit times.\n\n\n5.1.3 Best Subset Approach\nFollowing the leaps::regsubsets function, we will use the best approach by changing method = \"backward\" to method = \"best\" to select the best model. Make sure to change all OLS.regback to OLS.regbest and related variables.\nCaution: Running all three subset selection methods in one file will result in longer run times/knit times."
  },
  {
    "objectID": "M2/M2LN2.html#prepare-performance-indicator-function",
    "href": "M2/M2LN2.html#prepare-performance-indicator-function",
    "title": "Multiple Linear Regression",
    "section": "6.1 Prepare performance indicator function",
    "text": "6.1 Prepare performance indicator function\n\n# library(MLmetrics)\n# indicator &lt;- function(model, y_pred, y_true) {\n#   adj.r.sq &lt;- summary(model)$adj.r.squared\n#   mse &lt;- MSE(y_pred, y_true)\n#   rmse &lt;- RMSE(y_pred, y_true)\n#   mae &lt;- MAE(y_pred, y_true)\n#   print(paste0(\"Adjusted R-squared: \", round(adj.r.sq, 4)))\n#   print(paste0(\"MSE: \", round(mse, 4)))\n#   print(paste0(\"RMSE: \", round(rmse, 4)))\n#   print(paste0(\"MAE: \", round(mae, 4)))\n# }\n# \n# indicator(model = model.both_red, y_pred = model.both_red$fitted.values, y_true = X.train_red$quality)\n\nbest_model_back &lt;-  lm(quality~ volatile.acidity + chlorides+ total.sulfur.dioxide+                 pH+            sulphates  +            alcohol, data=X.train_red)\nstargazer::stargazer(best_model_back, type = \"html\",title = \"Backward Selection Best Model\", ci=TRUE, single.row = TRUE, no.space = FALSE, align = TRUE, digits=4, font.size = \"small\",  report = \"vc*stp\")\n\n\nBackward Selection Best Model\n\n\n\n\n\n\n\n\n\nDependent variable:\n\n\n\n\n\n\n\n\n\n\n\n\nquality\n\n\n\n\n\n\n\n\nvolatile.acidity\n\n\n-0.9888*** (-1.2045, -0.7731)\n\n\n\n\n\n\nt = -8.9846\n\n\n\n\n\n\np = 0.0000\n\n\n\n\n\n\n\n\n\n\nchlorides\n\n\n-1.6884*** (-2.5485, -0.8283)\n\n\n\n\n\n\nt = -3.8474\n\n\n\n\n\n\np = 0.0002\n\n\n\n\n\n\n\n\n\n\ntotal.sulfur.dioxide\n\n\n-0.0029*** (-0.0040, -0.0019)\n\n\n\n\n\n\nt = -5.4365\n\n\n\n\n\n\np = 0.000000\n\n\n\n\n\n\n\n\n\n\npH\n\n\n-0.3920*** (-0.6374, -0.1466)\n\n\n\n\n\n\nt = -3.1307\n\n\n\n\n\n\np = 0.0018\n\n\n\n\n\n\n\n\n\n\nsulphates\n\n\n0.8807*** (0.6426, 1.1188)\n\n\n\n\n\n\nt = 7.2496\n\n\n\n\n\n\np = 0.0000\n\n\n\n\n\n\n\n\n\n\nalcohol\n\n\n0.3083*** (0.2733, 0.3433)\n\n\n\n\n\n\nt = 17.2681\n\n\n\n\n\n\np = 0.0000\n\n\n\n\n\n\n\n\n\n\nConstant\n\n\n3.9765*** (3.1272, 4.8257)\n\n\n\n\n\n\nt = 9.1773\n\n\n\n\n\n\np = 0.0000\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservations\n\n\n1,274\n\n\n\n\nR2\n\n\n0.3847\n\n\n\n\nAdjusted R2\n\n\n0.3818\n\n\n\n\nResidual Std. Error\n\n\n0.6348 (df = 1267)\n\n\n\n\nF Statistic\n\n\n132.0538*** (df = 6; 1267)\n\n\n\n\n\n\n\n\nNote:\n\n\np&lt;0.1; p&lt;0.05; p&lt;0.01\n\n\n\n\nWe compare these predictions from the training set to the test set.\n\n# metrics &lt;- function(y_pred, y_true){\n#   mse &lt;- MSE(y_pred, y_true)\n#   rmse &lt;- RMSE(y_pred, y_true)\n#   mae &lt;- MAE(y_pred, y_true)\n#   corPredAct &lt;- cor(y_pred, y_true)\n#   print(paste0(\"MSE: \", round(mse, 6)))\n#   print(paste0(\"RMSE: \", round(rmse, 6)))\n#   print(paste0(\"MAE: \", round(mae, 6)))\n#   print(paste0(\"Correlation: \", round(corPredAct, 6)))\n#   print(paste0(\"R^2 between y_pred & y_true: \", round(corPredAct^2, 6)))\n# }\n# \n# metrics(y_pred = model.both_red$fitted.values, y_true = X.train_red$quality)\n# \n# redPredict.both &lt;- predict(model.both_red, newdata = X.test_red)\n# metrics(y_pred = redPredict.both, y_true = X.test_red$quality)\n\n# Predict on the test data\npredictions &lt;- predict(best_model_back, newdata = X.test_red)\n\n\n6.1.1 Plot between Predicted vs. actual values in training set\n\n# redFitted.both &lt;- data.frame(qualityPred = model.both_red$fitted.values,\n#                              qualityAct = X.train_red$quality)\n# ggplot(redFitted.both, aes(x = qualityPred, y = qualityAct)) +\n#   geom_point(aes(color = as.factor(qualityAct)), show.legend = F) +\n#   geom_smooth(method = \"lm\", se = F) +\n#   labs(title = \"Predicted vs Actual Values Using Train Dataset\", x = \"Predicted quality\", y = \"Actual quality\")\n\n\n\n6.1.2 Plot between Predicted vs. actual values in test set\n\n# redPredict.bothDF &lt;- data.frame(qualityPred = redPredict.both, qualityAct = X.test_red$quality)\n# ggplot(redPredict.bothDF, aes(x = qualityPred, y = qualityAct)) +\n#   geom_point(aes(color = as.factor(qualityAct)), show.legend = F) +\n#   geom_smooth(method = \"lm\", se = F) +\n#   labs(title = \"Predicted vs Actual Values Using Test Dataset\", x = \"Predicted quality\", y = \"Actual quality\")\n# Add the predicted values to your test data (X.test_red)\n\nX.test_red$predicted_quality &lt;- predictions\n\n# Load the necessary libraries\nlibrary(ggplot2)\n\n# Create a scatterplot to visualize the predicted values vs. actual values\nggplot(X.test_red, aes(x = quality, y = predicted_quality)) +\n  geom_point() +\n  labs(title = \"Actual vs. Predicted Quality\",\n       x = \"Actual Quality\",\n       y = \"Predicted Quality\") +\n  geom_abline(intercept = 0, slope = 1, color = \"red\", linetype = \"dashed\") +\n  theme_minimal()"
  },
  {
    "objectID": "M2/M2LN2.html#causal",
    "href": "M2/M2LN2.html#causal",
    "title": "Multiple Linear Regression",
    "section": "7.1 Causal",
    "text": "7.1 Causal\n\n\\begin{align}\nln(y) &= \\beta_{0}+\\beta_{1}x_{1}+\\beta_{2}x_{2} \\implies y= e^{\\beta_{0}+\\beta_{1}x_{1}+\\beta_{2}x_{2}}\\\\\n\\sqrt{y} &=\\beta_{0}+\\beta_{1}x_{1}+\\beta_{2}x_{2}\\implies y = (\\beta_{0}+\\beta_{1}x_{1}+\\beta_{2}x_{2})^2== b_0^2+b_1^2+2*b1b2\\\\\n\\sqrt[3]{y} &=\\beta_{0}+\\beta_{1}x_{1}+\\beta_{2}x_{2}\\\\\ncnt &= 161.807 +85.5765 *temp + 314.3430 *atemp - 275.1803 *hum+ 43.000* windspeed\\\\\ncausal &= 161.807 +85.5765 *temp +  314.3430 *atemp - 275.1803 *hum+ 43.000* windspeed\\\\\nRegisterd &= 161.807 +85.5765 *temp +   314.3430 *atemp - 275.1803 *hum+ 43.000* windspeed\n\\end{align}\n\nlm1 = lm(BC_cnt~.-causal-registered-instant-cnt, data=train)"
  },
  {
    "objectID": "M1/M1LN2.html",
    "href": "M1/M1LN2.html",
    "title": "Data Partitioning and Feature Engineering",
    "section": "",
    "text": "Interaction terms enter the regression equation as the product of two constitutive terms, x_1 and x_2. For this product term x_1x_3, the regression equation adds a separate coefficient \\beta_{3}.\ny=\\beta_{0}+\\beta_{1}x_1+\\beta_{2}x_2+\\beta_{3}x_1x_2+\\epsilon"
  },
  {
    "objectID": "M1/M1LN2.html#specifying-an-interaction",
    "href": "M1/M1LN2.html#specifying-an-interaction",
    "title": "Data Partitioning and Feature Engineering",
    "section": "2.1 Specifying an interaction",
    "text": "2.1 Specifying an interaction\n\nAlthough the tutorial does not discuss this, in the prevalent case of using null hypothesis significance tests on interaction effects, interaction terms should be derived from theory.\nIn R, you specify an interaction term by putting an asterisk between the two constitutive terms: x_1 \\times x_2\n\nSee Brambor et al. (2006) for more details. What would it imply if your model only included \\beta_{3}x_{1}x_{2}? Omitting a coefficient is equivalent to setting \\beta_1=0 and \\beta_2=0. See for yourself: R will include the main effects regardless of specifications if an interaction term is present.\n\nmod.sim2 &lt;- lm(y ~ x1:x2, data = sim.dat)\nstargazer::stargazer(mod.sim2, type='html', summary=TRUE,report = \"vc*stp\",ci=TRUE)\n\n\n\n\n\n\n\n\n\nDependent variable:\n\n\n\n\n\n\n\n\n\n\n\n\ny\n\n\n\n\n\n\n\n\nx1:x2\n\n\n0.959***\n\n\n\n\n\n\n(0.270, 1.647)\n\n\n\n\n\n\nt = 2.729\n\n\n\n\n\n\np = 0.007\n\n\n\n\n\n\n\n\n\n\nConstant\n\n\n6.656***\n\n\n\n\n\n\n(5.268, 8.043)\n\n\n\n\n\n\nt = 9.404\n\n\n\n\n\n\np = 0.000\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservations\n\n\n200\n\n\n\n\nR2\n\n\n0.036\n\n\n\n\nAdjusted R2\n\n\n0.031\n\n\n\n\nResidual Std. Error\n\n\n9.995 (df = 198)\n\n\n\n\nF Statistic\n\n\n7.448*** (df = 1; 198)\n\n\n\n\n\n\n\n\nNote:\n\n\np&lt;0.1; p&lt;0.05; p&lt;0.01\n\n\n\n\n\nplot(x = sim.dat[sim.dat$x1 == 0, ]$x2, y = sim.dat[sim.dat$x1 == 0, ]$y, \n     pch = 19, col = rgb(red = 0, green = 0, blue = 1, alpha = 0.25),\n     xlab = \"x2\", ylab = \"y\")\npoints(x = sim.dat[sim.dat$x1 == 1, ]$x2, y = sim.dat[sim.dat$x1 == 1, ]$y, \n       col = rgb(red = 1, green = 0, blue = 0, alpha = 0.25), pch = 19)\nabline(a = coef(mod.sim2)[1], b = coef(mod.sim2)[2], lwd = 2)"
  },
  {
    "objectID": "M1/M1LN2.html#daintfun2",
    "href": "M1/M1LN2.html#daintfun2",
    "title": "Data Partitioning and Feature Engineering",
    "section": "8.1 DAintfun2()",
    "text": "8.1 DAintfun2()\nOne good option is Dave Armstrong’s DAintfun2() function, which is part of his “DAMisc” package. You need to first install the package, then load it, and then specify the function with at least the following arguments:\n\n# install.packages(\"DAMisc\")\nlibrary(DAMisc)\nDAintfun2(m3, varnames = c(\"thresh\", \"enp\"), \n                  rug = TRUE, hist = TRUE)\n\n\n\n\n\n\n\n\nDAintfun2() by default plots both the marginal effect of the first variable as well as that of the second variable. It also allows you to include an indicator of the actual distribution of the variables, via a histogram or a rug plot. With these supplementary plots, you can immediately see whether the estimated effect of a variable corresponds to real observations at that value of the moderating variable.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nset.seed(123)\nn.sample &lt;- 200\nx1 &lt;- rbinom(n.sample, size = 1, prob = 0.5)\nx2 &lt;- runif(n.sample, -5, 5)\na &lt;- 5\nb1 &lt;- 3\nb2 &lt;- 4\nb3 &lt;- -3\ne &lt;- rnorm(n.sample, 0, 5)\ny &lt;- a + b1 * x1 + b2 * x2 + e\nsim.dat &lt;- data.frame(y, x1, x2)\nhead(sim.dat)\n\n          y x1         x2\n1  5.543093  0 -2.6127397\n2 33.056422  1  4.6235894\n3  7.728904  0  1.0136573\n4 11.317159  1  0.1502973\n5  2.031234  1 -0.9742666\n6 17.828627  0  3.8024654"
  }
]